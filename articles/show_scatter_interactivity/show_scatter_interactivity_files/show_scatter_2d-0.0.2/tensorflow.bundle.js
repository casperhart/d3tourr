/*! For license information please see tensorflow.bundle.js.LICENSE.txt */
"use strict";(self.webpackChunk_name_=self.webpackChunk_name_||[]).push([[440],{4240:(e,t,n)=>{n.r(t),n.d(t,{MathBackendCPU:()=>i,shared:()=>r,version_cpu:()=>ht});var r={};n.r(r),n.d(r,{addImpl:()=>v,bincountImpl:()=>N,bincountReduceImpl:()=>T,ceilImpl:()=>$,concatImpl:()=>R,equalImpl:()=>C,expImpl:()=>z,expm1Impl:()=>L,floorImpl:()=>K,gatherNdImpl:()=>V,gatherV2Impl:()=>j,greaterEqualImpl:()=>X,greaterImpl:()=>Z,lessEqualImpl:()=>ae,lessImpl:()=>te,linSpaceImpl:()=>ie,logImpl:()=>le,maxImpl:()=>de,maximumImpl:()=>he,minimumImpl:()=>me,multiplyImpl:()=>ke,negImpl:()=>ve,notEqualImpl:()=>Se,prodImpl:()=>Fe,rangeImpl:()=>De,rsqrtImpl:()=>_e,sigmoidImpl:()=>Be,simpleAbsImpl:()=>l,sliceImpl:()=>We,sparseFillEmptyRowsImpl:()=>He,sparseReshapeImpl:()=>Ge,sparseSegmentReductionImpl:()=>Ke,sqrtImpl:()=>qe,squaredDifferenceImpl:()=>je,stridedSliceImpl:()=>Ye,stringNGramsImpl:()=>Qe,stringSplitImpl:()=>tt,stringToHashBucketFastImpl:()=>nt,subImpl:()=>rt,tileImpl:()=>it,topKImpl:()=>ct,transposeImpl:()=>Te,uniqueImpl:()=>dt});var a=n(356);function s(e,t){Array.isArray(e)||(e=[e]),e.forEach((e=>{null!=e&&a.util.assert("complex64"!==e.dtype,(()=>`${t} does not support complex64 tensors in the CPU backend.`))}))}const o=a.kernel_impls.whereImpl;class i extends a.KernelBackend{constructor(){super(),this.blockSize=48,this.firstUse=!0,this.data=new a.DataStorage(this,(0,a.engine)())}nextDataId(){return i.nextDataId++}write(e,t,n){this.firstUse&&(this.firstUse=!1,(0,a.env)().get("IS_NODE")&&a.backend_util.warn("\n============================\nHi there ðŸ‘‹. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\n============================"));const r={id:this.nextDataId()};return this.data.set(r,{values:e,dtype:n,refCount:1}),r}makeTensorInfo(e,t,n){let r;if("string"===t&&null!=n&&n.length>0&&a.util.isString(n[0])){const s=n.map((e=>a.util.encodeString(e)));r=this.write(s,e,t)}else r=this.write(n,e,t);return{dataId:r,shape:e,dtype:t}}refCount(e){return this.data.has(e)?this.data.get(e).refCount:0}incRef(e){this.data.get(e).refCount++}decRef(e){this.data.has(e)&&this.data.get(e).refCount--}move(e,t,n,r,a){this.data.set(e,{values:t,dtype:r,refCount:a})}numDataIds(){return this.data.numDataIds()}async read(e){return this.readSync(e)}readSync(e){const{dtype:t,complexTensorInfos:n}=this.data.get(e);if("complex64"===t){const e=this.readSync(n.real.dataId),t=this.readSync(n.imag.dataId);return a.backend_util.mergeRealAndImagArrays(e,t)}return this.data.get(e).values}bufferSync(e){const t=this.readSync(e.dataId);let n=t;if("string"===e.dtype)try{n=t.map((e=>a.util.decodeString(e)))}catch(e){throw new Error("Failed to decode encoded string bytes into utf-8")}return(0,a.buffer)(e.shape,e.dtype,n)}makeOutput(e,t,n){const r=this.write(e,t,n);return(0,a.engine)().makeTensorFromDataId(r,t,n,this)}disposeData(e,t=!1){if(this.data.has(e)){if(this.data.get(e).refCount--,!t&&this.data.get(e).refCount>0)return!1;const{complexTensorInfos:n}=this.data.get(e);null!=n&&(this.disposeData(n.real.dataId,!0),this.disposeData(n.imag.dataId,!0)),this.data.delete(e)}return!0}disposeIntermediateTensorInfo(e){this.disposeData(e.dataId)}async time(e){const t=a.util.now();return e(),{kernelMs:a.util.now()-t}}memory(){return{unreliable:!0,reasons:["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]}}where(e){s([e],"where");const t=this.readSync(e.dataId);return o(e.shape,t)}dispose(){}floatPrecision(){return 32}epsilon(){return super.epsilon()}}function l(e){const t=new Float32Array(e.length);for(let n=0;n<e.length;++n)t[n]=Math.abs(e[n]);return t}i.nextDataId=0;const u={kernelName:a.Abs,backendName:"cpu",kernelFunc:e=>{const{x:t}=e.inputs,n=e.backend;s(t,"abs");let r=new Float32Array(a.util.sizeFromShape(t.shape));return r=l(n.data.get(t.dataId).values),n.makeOutput(r,t.shape,t.dtype)}};function c(e){return(t,n,r,s,o)=>{const i=a.backend_util.assertAndGetBroadcastShape(t,n),l=i.length,u=a.util.computeStrides(i),c=a.util.sizeFromShape(i),d=a.util.getTypedArrayFromDType(o,c),h=t.length,p=n.length,f=a.util.computeStrides(t),m=a.util.computeStrides(n),g=a.backend_util.getBroadcastDims(t,i),b=a.backend_util.getBroadcastDims(n,i);if(g.length+b.length===0)for(let t=0;t<d.length;++t)d[t]=e(r[t%r.length],s[t%s.length]);else for(let t=0;t<d.length;++t){const n=a.util.indexToLoc(t,l,u),o=n.slice(-h);g.forEach((e=>o[e]=0));const i=a.util.locToIndex(o,h,f),c=n.slice(-p);b.forEach((e=>c[e]=0));const k=a.util.locToIndex(c,p,m);d[t]=e(r[i],s[k])}return[d,i]}}function d(e){const{inputs:t,backend:n}=e,{real:r,imag:a}=t,s=n.data.get(r.dataId).values,o=n.data.get(a.dataId).values,i=n.makeTensorInfo(r.shape,"complex64");return n.data.get(i.dataId).complexTensorInfos={real:n.makeTensorInfo(r.shape,"float32",s),imag:n.makeTensorInfo(a.shape,"float32",o)},i}const h={kernelName:a.Complex,backendName:"cpu",kernelFunc:d};function p(e,t,n="float32"){if("complex64"===n)return d({inputs:{real:p(e,t,"float32"),imag:p(e,t,"float32")},backend:e});const r=a.util.makeZerosTypedArray(a.util.sizeFromShape(t),n);return e.makeTensorInfo(t,n,r)}function f(e){const{inputs:t,backend:n}=e,{x:r}=t;return n.incRef(r.dataId),{dataId:r.dataId,shape:r.shape,dtype:r.dtype}}const m={kernelName:a.Identity,backendName:"cpu",kernelFunc:f};function g(e){const{inputs:t,backend:n}=e,{input:r}=t,a=n.data.get(r.dataId).complexTensorInfos.real,s=n.data.get(a.dataId).values;return n.makeTensorInfo(a.shape,a.dtype,s)}const b={kernelName:a.Real,backendName:"cpu",kernelFunc:g};function k(e){const{inputs:t,backend:n,attrs:r}=e,{x:s}=t,{dtype:o}=r;if("complex64"===o){if("complex64"===s.dtype)return f({inputs:{x:s},backend:n});const e=p(n,s.shape,s.dtype),t=k({inputs:{x:s},backend:n,attrs:{dtype:"float32"}}),r=d({inputs:{real:t,imag:e},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),r}if("complex64"===s.dtype){const e=g({inputs:{input:s},backend:n}),t=k({inputs:{x:e},backend:n,attrs:{dtype:o}});return n.disposeIntermediateTensorInfo(e),t}if(!a.util.hasEncodingLoss(s.dtype,o)){const e=f({inputs:{x:s},backend:n});return{dataId:e.dataId,shape:e.shape,dtype:o}}if("int32"===o){const e=n.data.get(s.dataId).values,t=Int32Array.from(e);return n.makeTensorInfo(s.shape,"int32",t)}if("bool"===o){const e=n.data.get(s.dataId).values,t=a.util.toTypedArray([0],s.dtype),[r,o]=c(((e,t)=>e!==t?1:0))(s.shape,[],e,t,"bool");return n.makeTensorInfo(o,"bool",r)}throw new Error(`Error in Cast: failed to cast ${s.dtype} to ${o}`)}const y={kernelName:a.Cast,backendName:"cpu",kernelFunc:k};function w(e,t,n,r){return null==n?({inputs:n,backend:o})=>{const{a:i,b:l}=n,u=o;s([i,l],e);const c=u.data.get(i.dataId).values,d=u.data.get(l.dataId).values,h="string"===i.dtype?a.backend_util.fromUint8ToStringArray(c):c,p="string"===i.dtype?a.backend_util.fromUint8ToStringArray(d):d,f=r||i.dtype,[m,g]=t(i.shape,l.shape,h,p,f);return u.makeTensorInfo(g,f,m)}:({inputs:e,backend:a})=>{const{a:s,b:o}=e,i=a;if("complex64"===s.dtype||"complex64"===o.dtype){const e=k({inputs:{x:s},backend:i,attrs:{dtype:"complex64"}}),t=i.data.get(e.dataId),r=t.complexTensorInfos.real,a=t.complexTensorInfos.imag,l=i.data.get(r.dataId).values,u=i.data.get(a.dataId).values,c=k({inputs:{x:o},backend:i,attrs:{dtype:"complex64"}}),h=i.data.get(c.dataId),p=h.complexTensorInfos.real,f=h.complexTensorInfos.imag,m=i.data.get(p.dataId).values,g=i.data.get(f.dataId).values,[b,y,w]=n(s.shape,o.shape,l,u,m,g),I=i.makeTensorInfo(w,"float32",b),v=i.makeTensorInfo(w,"float32",y),x=d({inputs:{real:I,imag:v},backend:i});return i.disposeIntermediateTensorInfo(e),i.disposeIntermediateTensorInfo(c),i.disposeIntermediateTensorInfo(I),i.disposeIntermediateTensorInfo(v),x}{const e=i.data.get(s.dataId).values,n=i.data.get(o.dataId).values,a=r||s.dtype,[l,u]=t(s.shape,o.shape,e,n,a);return i.makeTensorInfo(u,a,l)}}}function I(e){return(t,n,r,s,o,i)=>{const l=a.backend_util.assertAndGetBroadcastShape(t,n),u=a.util.sizeFromShape(l),c=l.length,d=a.util.computeStrides(l),h=a.util.getTypedArrayFromDType("float32",u),p=a.util.getTypedArrayFromDType("float32",u),f=a.backend_util.getBroadcastDims(t,l),m=a.backend_util.getBroadcastDims(n,l),g=a.backend_util.mergeRealAndImagArrays(r,s),b=a.backend_util.mergeRealAndImagArrays(o,i),k=t.length,y=a.util.computeStrides(t),w=n.length,I=a.util.computeStrides(n);if(f.length+m.length===0)for(let t=0;t<h.length;t++){const n=t%g.length,r=t%b.length,a=e(g[2*n],g[2*n+1],b[2*r],b[2*r+1]);h[t]=a.real,p[t]=a.imag}else for(let t=0;t<h.length;t++){const n=a.util.indexToLoc(t,c,d),r=n.slice(-k);f.forEach((e=>r[e]=0));const s=a.util.locToIndex(r,k,y),o=n.slice(-w);m.forEach((e=>o[e]=0));const i=a.util.locToIndex(o,w,I),l=e(g[2*s],g[2*s+1],b[2*i],b[2*i+1]);h[t]=l.real,p[t]=l.imag}return[h,p,l]}}const v=c(((e,t)=>e+t)),x=I(((e,t,n,r)=>({real:e+n,imag:t+r}))),S=w(a.Add,v,x),E={kernelName:a.Add,backendName:"cpu",kernelFunc:S};function N(e,t,n,r,s){const o=a.util.sizeFromShape(r),i=a.util.makeZerosTypedArray(s,n);for(let n=0;n<e.length;n++){const r=e[n];if(r<0)throw new Error("Input x must be non-negative!");r>=s||(i[r]+=o>0?t[n]:1)}return i}function T(e,t,n,r=!1){const s=e.shape[0],o=e.shape[1],i=(0,a.buffer)([s,n],t.dtype);for(let a=0;a<s;a++)for(let s=0;s<o;s++){const o=e.get(a,s);if(o<0)throw new Error("Input x must be non-negative!");o>=n||(r?i.set(1,a,o):t.size>0?i.set(i.get(a,o)+t.get(a,s),a,o):i.set(i.get(a,o)+1,a,o))}return i}function A(e){return(t,n,r)=>{const s=a.util.getTypedArrayFromDType(n,t.length);for(let n=0;n<t.length;++n)s[n]=e(t[n],r);return s}}function M(e,t,n){return({inputs:r,attrs:o,backend:i})=>{const{x:l}=r;if(s(l,e),"string"===l.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const u=i,c=u.data.get(l.dataId).values,d=a.util.sizeFromShape(l.shape),h=n||l.dtype,p=a.util.getArrayFromDType(h,d);for(let e=0;e<d;++e)p[e]=t(c[e],o);return u.makeTensorInfo(l.shape,h,p)}}function F(e,t,n){return({inputs:r,attrs:a,backend:o})=>{const{x:i}=r;if(s(i,e),"string"===i.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const l=o,u=l.data.get(i.dataId).values,c=n||i.dtype,d=t(u,c,a);return l.makeTensorInfo(i.shape,c,d)}}const $=A((e=>Math.ceil(e))),D=F(a.Ceil,$),_={kernelName:a.Ceil,backendName:"cpu",kernelFunc:D};function R(e,t,n,r){const s=a.util.getArrayFromDType(n,a.util.sizeFromShape(t));if(r&&"string"!==n){let t=0;e.forEach((e=>{const n=a.util.sizeFromShape(e.shape);s.set(e.vals,t),t+=n}))}else{let r=0;e.forEach((e=>{const o="string"===n?a.backend_util.fromUint8ToStringArray(e.vals):e.vals;let i=0;for(let n=0;n<e.shape[0];++n){const a=n*t[1]+r;for(let t=0;t<e.shape[1];++t)s[a+t]=o[i++]}r+=e.shape[1]}))}return s}const C=c(((e,t)=>e===t?1:0)),B=w(a.Equal,C,null,"bool"),P={kernelName:a.Equal,backendName:"cpu",kernelFunc:B},z=A((e=>Math.exp(e))),W=F(a.Exp,z,"float32"),O={kernelName:a.Exp,backendName:"cpu",kernelFunc:W},L=A((e=>Math.expm1(e))),H=F(a.Expm1,L),G={kernelName:a.Expm1,backendName:"cpu",kernelFunc:H},K=A((e=>Math.floor(e))),q=F(a.Floor,K),U={kernelName:a.Floor,backendName:"cpu",kernelFunc:q};function V(e,t,n,r,s,o,i,l,u){const c=(0,a.buffer)([r,o],n);for(let n=0;n<r;n++){const r=[];let a=0;for(let t=0;t<s;t++){const o=e[n*s+t];a+=o*i[t],r.push(o)}if(a<0||a>=u/o)throw new Error(`Invalid indices: ${r} does not index into ${l}`);for(let e=0;e<o;e++)c.values[n*o+e]=t.get(...t.indexToLoc(a*o+e))}return c}function j(e,t,n){const r=(0,a.buffer)(n,e.dtype);for(let n=0;n<r.size;++n){const a=r.indexToLoc(n).slice(),s=a[0],o=a[2],i=t.locToIndex([s,o]);a[2]=t.values[i];const l=e.locToIndex(a);0<=l&&l<e.values.length&&(r.values[n]=e.values[l])}return r}const Z=c(((e,t)=>e>t?1:0)),J=w(a.Greater,Z,null,"bool"),Y={kernelName:a.Greater,backendName:"cpu",kernelFunc:J},X=c(((e,t)=>e>=t?1:0)),Q=w(a.GreaterEqual,X,null,"bool"),ee={kernelName:a.GreaterEqual,backendName:"cpu",kernelFunc:Q},te=c(((e,t)=>e<t?1:0)),ne=w(a.Less,te,null,"bool"),re={kernelName:a.Less,backendName:"cpu",kernelFunc:ne},ae=c(((e,t)=>e<=t?1:0)),se=w(a.LessEqual,ae,null,"bool"),oe={kernelName:a.LessEqual,backendName:"cpu",kernelFunc:se};function ie(e,t,n){const r=(t-e)/(n-1),s=a.util.makeZerosTypedArray(n,"float32");s[0]=e;for(let e=1;e<s.length;e++)s[e]=s[e-1]+r;return s}const le=A((e=>Math.log(e))),ue=F(a.Log,le),ce={kernelName:a.Log,backendName:"cpu",kernelFunc:ue};function de(e,t,n,r){const s=a.util.getTypedArrayFromDType(r,a.util.sizeFromShape(n));for(let n=0;n<s.length;++n){const r=n*t;let a=e[r];for(let n=0;n<t;++n){const t=e[r+n];(Number.isNaN(t)||t>a)&&(a=t)}s[n]=a}return s}const he=c(((e,t)=>Math.max(e,t))),pe=w(a.Maximum,he),fe={kernelName:a.Maximum,backendName:"cpu",kernelFunc:pe},me=c(((e,t)=>Math.min(e,t))),ge=w(a.Minimum,me),be={kernelName:a.Minimum,backendName:"cpu",kernelFunc:ge},ke=c(((e,t)=>e*t)),ye=I(((e,t,n,r)=>({real:e*n-t*r,imag:e*r+t*n}))),we=w(a.Multiply,ke,ye),Ie={kernelName:a.Multiply,backendName:"cpu",kernelFunc:we};function ve(e,t,n){const r=a.util.createScalarValue(-1,n);return ke([],t,r,e,n)}const xe={kernelName:a.Neg,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{x:r}=t;s(r,"neg");const a=n.data.get(r.dataId).values,[o,i]=ve(a,r.shape,r.dtype);return n.makeTensorInfo(i,r.dtype,o)}},Se=c(((e,t)=>e!==t?1:0)),Ee=w(a.NotEqual,Se,null,"bool"),Ne={kernelName:a.NotEqual,backendName:"cpu",kernelFunc:Ee};function Te(e,t,n,r,s){const o=t.length,i=a.util.sizeFromShape(t),l=a.util.computeStrides(t),u=a.util.computeStrides(s),c=a.util.getTypedArrayFromDType(n,a.util.sizeFromShape(s));for(let t=0;t<i;++t){const n=a.util.indexToLoc(t,o,l),s=new Array(n.length);for(let e=0;e<s.length;e++)s[e]=n[r[e]];c[a.util.locToIndex(s,o,u)]=e[t]}return c}function Ae(e){const{inputs:t,attrs:n,backend:r}=e,{x:a}=t,{perm:o}=n;s(a,"transpose");const i=a.shape.length,l=new Array(i);for(let e=0;e<l.length;e++)l[e]=a.shape[o[e]];const u=Te(r.data.get(a.dataId).values,a.shape,a.dtype,o,l);return{dataId:r.write(u,l,a.dtype),shape:l,dtype:a.dtype}}const Me={kernelName:a.Transpose,backendName:"cpu",kernelFunc:Ae};function Fe(e,t,n,r){const[s,o]=a.backend_util.computeOutAndReduceShapes(e,r),i=(0,a.upcastType)(t,"int32"),l=a.util.makeZerosTypedArray(a.util.sizeFromShape(s),i),u=a.util.sizeFromShape(o);for(let e=0;e<l.length;++e){const t=e*u;let r=1;for(let e=0;e<u;++e)r*=n[t+e];l[e]=r}return{outVals:l,outShape:s,outDtype:i}}const $e={kernelName:a.Prod,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{axis:i,keepDims:l}=r;s(o,"prod");const u=o.shape.length,c=a.util.parseAxisParam(i,o.shape),d=a.backend_util.getAxesPermutation(c,u);let h=c,p=o;const f=[];null!=d&&(p=Ae({inputs:{x:o},backend:n,attrs:{perm:d}}),f.push(p),h=a.backend_util.getInnerMostAxes(h.length,u));const m=n.data.get(p.dataId).values,{outVals:g,outShape:b,outDtype:k}=Fe(p.shape,p.dtype,m,h);let y=b;return l&&(y=a.backend_util.expandShapeToKeepDim(b,c)),f.forEach((e=>n.disposeIntermediateTensorInfo(e))),n.makeTensorInfo(y,k,g)}};function De(e,t,n,r){if(e===t||e<t&&n<0||t<e&&n>1)return a.util.makeZerosTypedArray(0,r);const s=Math.abs(Math.ceil((t-e)/n)),o=a.util.makeZerosTypedArray(s,r);t<e&&1===n&&(n=-1),o[0]=e;for(let e=1;e<o.length;e++)o[e]=o[e-1]+n;return o}const _e=A((e=>1/Math.sqrt(e))),Re=F(a.Rsqrt,_e),Ce={kernelName:a.Rsqrt,backendName:"cpu",kernelFunc:Re},Be=A((e=>1/(1+Math.exp(-e)))),Pe=M(a.Sigmoid,(e=>1/(1+Math.exp(-e)))),ze={kernelName:a.Sigmoid,backendName:"cpu",kernelFunc:Pe};function We(e,t,n,r,s){const o=a.slice_util.isSliceContinous(r,t,n),i=a.util.sizeFromShape(n),l=a.util.computeStrides(r);if(o){const n=a.slice_util.computeFlatOffset(t,l);return"string"===s?e.slice(n,n+i):e.subarray(n,n+i)}const u="string"===s?a.backend_util.fromUint8ToStringArray(e):e,c=(0,a.buffer)(r,s,u),d=(0,a.buffer)(n,s);for(let e=0;e<d.size;++e){const n=d.indexToLoc(e),r=n.map(((e,n)=>e+t[n]));d.set(c.get(...r),...n)}return"string"===s?a.backend_util.fromStringArrayToUint8(d.values):d.values}function Oe(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{begin:i,size:l}=r;s(o,"slice");const[u,c]=a.slice_util.parseSliceParams(o,i,l);a.slice_util.assertParamsValid(o,u,c);const d=We(n.data.get(o.dataId).values,u,c,o.shape,o.dtype);return n.makeTensorInfo(c,o.dtype,d)}const Le={kernelName:a.Slice,backendName:"cpu",kernelFunc:Oe};function He(e,t,n,r,s,o,i){const l=t[0],u=o[0],c=new Array(u),d=new Array(l),h=t[1];if(0===u){if(0!==l)throw new Error(a.backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(l));return[a.util.getArrayFromDType(n,0),[0,h],a.util.getArrayFromDType(s,0),c,d]}let p=!0,f=0;const m=new Array(u).fill(0);for(let t=0;t<l;++t){const n=e[t*h];if(n<0)throw new Error(a.backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(t,n));if(n>=u)throw new Error(a.backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(t,n,u));++m[n],p=p&&n>=f,f=n}let g=!0;for(let e=0;e<u;++e){const t=0===m[e];c[e]=t,g=g&&!t,m[e]=Math.max(m[e],1),e>0&&(m[e]+=m[e-1])}if(g&&p){const t=e,n=r;for(let e=0;e<l;++e)d[e]=e;return[t,[l,h],n,c,d]}{const t=m[u-1],o=a.util.getArrayFromDType(n,t*h),p=a.util.getArrayFromDType(s,t),f=new Array(u).fill(0);for(let t=0;t<l;++t){const n=e[t*h],a=f[n],s=(0===n?0:m[n-1])+a;f[n]++;for(let n=0;n<h;++n)o[s*h+n]=e[t*h+n];p[s]=r[t],d[t]=s}for(let e=0;e<u;++e)if(0===f[e]){const t=0===e?0:m[e-1];o[t*h+0]=e;for(let e=1;e<h;++e)o[t*h+e]=0;p[t]=i}return[o,[t,h],p,c,d]}}function Ge(e,t,n,r,s){const o=a.util.sizeFromShape(r),i=t[0],l=s.length,u=[];let c=1,d=-1;for(let e=0;e<l;++e){const t=s[e];if(-1===t){if(-1!==d)throw new Error(a.backend_util.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(d,e));d=e,u.push(1)}else{if(t<0)throw new Error(a.backend_util.getSparseReshapeNegativeOutputDimErrorMessage(e,t));c*=t,u.push(t)}}if(-1!==d){if(c<=0)throw new Error(a.backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());const e=Math.trunc(o/c);if(c*e!==o)throw new Error(a.backend_util.getSparseReshapeInputOutputMultipleErrorMessage(r,u));u[d]=e}if(a.util.sizeFromShape(u)!==o)throw new Error(a.backend_util.getSparseReshapeInputOutputMismatchErrorMessage(r,u));const h=r.length,p=[];if(h>0){p[h-1]=1;for(let e=h-2;e>=0;--e)p[e]=p[e+1]*r[e+1]}const f=[];if(l>0){f[l-1]=1;for(let e=l-2;e>=0;--e)f[e]=f[e+1]*u[e+1]}const m=a.util.getArrayFromDType(n,i*l);for(let t=0;t<i;++t){let n=0;for(let r=0;r<h;++r)n+=e[t*h+r]*p[r];for(let e=0;e<l;++e)m[t*l+e]=Math.trunc(n/f[e]),n%=f[e]}return[m,[i,l],u]}function Ke(e,t,n,r,s,o=!1,i=0){const l=r.length,u=[t[0],e.length/t[0]],c=u[1],d=l>0?s[l-1]+1:0;if(d<0)throw new Error(a.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());const h=t.slice();h[0]=d;const p=h.reduce(((e,t)=>e*t),1),f=a.util.getArrayFromDType(n,p);if(0===l)return d>0&&f.fill(i),[f,h];if(d<=0)throw new Error(a.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());let m=0,g=1,b=0,k=s[m];for(;;){let t=0;if(g<l){if(t=s[g],k===t){++g;continue}if(k>=t)throw new Error(a.backend_util.getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage())}if(k<0||k>=d)throw new Error(a.backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(k,d));k>b&&f.fill(i,b*c,k*c);for(let t=m;t<g;++t){const n=r[t];if(n<0||n>=u[0])throw new Error(a.backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(t,r[t],u[0]));for(let t=0;t<c;t++)f[k*c+t]+=e[n*c+t]}if(o)for(let e=0;e<c;e++)f[k*c+e]/=g-m;if(m=g,++g,b=k+1,k=t,g>l)break}return b<d&&f.fill(i,b*c,d*c),[f,h]}const qe=A((e=>Math.sqrt(e))),Ue=M(a.Sqrt,(e=>Math.sqrt(e))),Ve={kernelName:a.Sqrt,backendName:"cpu",kernelFunc:Ue},je=c(((e,t)=>{const n=e-t;return n*n})),Ze=w(a.SquaredDifference,je),Je={kernelName:a.SquaredDifference,backendName:"cpu",kernelFunc:Ze};function Ye(e,t,n,r){const s=(0,a.buffer)(e,t.dtype);for(let e=0;e<s.size;e++){const a=s.indexToLoc(e),o=new Array(a.length);for(let e=0;e<o.length;e++)o[e]=a[e]*n[e]+r[e];s.set(t.get(...o),...a)}return s}class Xe{constructor(e,t,n,r,s,o){this.separator=a.util.encodeString(e),this.nGramWidths=t,this.leftPad=a.util.encodeString(n),this.rightPad=a.util.encodeString(r),this.padWidth=s,this.preserveShort=o}getPadWidth(e){return Math.min(this.padWidth<0?e-1:this.padWidth,e-1)}getNumNGrams(e,t){const n=this.getPadWidth(t);return Math.max(0,e+2*n-t+1)}createNGrams(e,t,n,r,a,s){for(let o=0;o<a;++o){const i=this.getPadWidth(s),l=Math.max(0,i-o),u=Math.max(0,i-(a-(o+1))),c=s-(l+u),d=t+(l>0?0:o-i);let h=0;h+=l*this.leftPad.length;for(let t=0;t<c;++t)h+=e[d+t].length;h+=u*this.rightPad.length,h+=(l+u+c-1)*this.separator.length,n[r+o]=new Uint8Array(h);const p=n[r+o];let f=0;const m=e=>e.forEach((e=>p[f++]=e));for(let e=0;e<l;++e)m(this.leftPad),m(this.separator);for(let t=0;t<c-1;++t)m(e[d+t]),m(this.separator);if(c>0){m(e[d+c-1]);for(let e=0;e<u;++e)m(this.separator),m(this.rightPad)}else{for(let e=0;e<u-1;++e)m(this.rightPad),m(this.separator);m(this.rightPad)}}}compute(e,t){const n=e.length,r=t.length;if(r>0){let e=t[0];if(0!==e)throw new Error(`First split value must be 0, got ${e}`);for(let a=1;a<r;++a){let r=t[a]>=e;if(r=r&&t[a]<=n,!r)throw new Error(`Invalid split value ${t[a]}, must be in [${e}, ${n}]`);e=t[a]}if(e!==n)throw new Error(`Last split value must be data size. Expected ${n}, got ${e}`)}const s=r-1,o=a.util.getArrayFromDType("int32",r);if(0===n||0===r){const e=new Array(n);for(let e=0;e<=s;++e)o[e]=0;return[e,o]}o[0]=0;for(let e=1;e<=s;++e){const n=t[e]-t[e-1];let r=0;this.nGramWidths.forEach((e=>{r+=this.getNumNGrams(n,e)})),this.preserveShort&&n>0&&0===r&&(r=1),o[e]=o[e-1]+r}const i=new Array(o[s]);for(let n=0;n<s;++n){const r=t[n];let a=o[n];if(this.nGramWidths.forEach((s=>{const o=t[n+1]-t[n],l=this.getNumNGrams(o,s);this.createNGrams(e,r,i,a,l,s),a+=l})),this.preserveShort&&a===o[n]){const s=t[n+1]-t[n];if(0===s)continue;const o=s+2*this.padWidth,l=1;this.createNGrams(e,r,i,a,l,o)}}return[i,o]}}function Qe(e,t,n,r,a,s,o,i){return new Xe(n,r,a,s,o,i).compute(e,t)}function et(e,t,n,r){if(!e.length)return;if(0===t.length){for(let t=0;t<e.length;++t)r.push(e.subarray(t,t+1));return}if(1===t.length){const a=t[0];let s=e.indexOf(a);for(;-1!==s;){const t=e.subarray(0,s);n&&0===t.length||r.push(t),s=(e=e.subarray(s+1)).indexOf(a)}return void(n&&0===e.length||r.push(e))}let a=0;for(let s=0;s<e.length+1;s++)if(s===e.length||-1!==t.indexOf(e[s])){const t=e.subarray(a,s);n&&0===t.length||r.push(t),a=s+1}}function tt(e,t,n){const r=e.length,s=[];let o=0,i=0;const l=new Array(r);for(let a=0;a<r;++a){const r=s.length;et(e[a],t,n,s);const u=s.length-r;l[a]=u,o+=u,i=Math.max(i,u)}const u=a.util.getArrayFromDType("int32",2*o),c=new Array(o),d=[r,i];let h=0;for(let e=0;e<r;++e)for(let t=0;t<l[e];++t)u[2*h]=e,u[2*h+1]=t,c[h]=s[h],++h;return[u,c,d]}function nt(e,t){const n=a.util.getArrayFromDType("int32",e.length);for(let r=0;r<e.length;++r)n[r]=a.util.fingerPrint64(e[r]).modulo(t).getLowBitsUnsigned();return n}const rt=c(((e,t)=>e-t)),at=I(((e,t,n,r)=>({real:e-n,imag:t-r}))),st=w(a.Sub,rt,at),ot={kernelName:a.Sub,backendName:"cpu",kernelFunc:st};function it(e,t){const n=new Array(e.rank);for(let r=0;r<n.length;r++)n[r]=e.shape[r]*t[r];const r=(0,a.buffer)(n,e.dtype);for(let t=0;t<r.values.length;++t){const n=r.indexToLoc(t),a=new Array(e.rank);for(let t=0;t<a.length;t++)a[t]=n[t]%e.shape[t];const s=e.locToIndex(a);r.values[t]=e.values[s]}return r}const lt=(e,t)=>{const n=t.value-e.value;return 0===n?e.index-t.index:n};function ut(e,t,n=0,r=e.length-1){for(;r>n;){if(r-n>600){const a=r-n+1,s=t-n+1,o=Math.log(a),i=.5*Math.exp(2*o/3),l=.5*Math.sqrt(o*i*(a-i)/a)*Math.sign(s-a/2);ut(e,t,Math.max(n,Math.floor(t-s*i/a+l)),Math.min(r,Math.floor(t+(a-s)*i/a+l)))}const s=e[t];let o=n,i=r;for(a.util.swap(e,n,t),lt(e[r],s)>0&&a.util.swap(e,n,r);o<i;){for(a.util.swap(e,o,i),o++,i--;lt(e[o],s)<0;)o+=1;for(;lt(e[i],s)>0;)i-=1}0===lt(e[n],s)?a.util.swap(e,n,i):(i+=1,a.util.swap(e,i,r)),i<=t&&(n=i+1),t<=i&&(r=i-1)}}function ct(e,t,n,r,s){const o=t[t.length-1],[i,l]=[e.length/o,o],u=a.util.getTypedArrayFromDType(n,i*r),c=a.util.getTypedArrayFromDType("int32",i*r);for(let t=0;t<i;t++){const n=t*l,a=e.subarray(n,n+l);let o=new Array(a.length);a.forEach(((e,t)=>o[t]={value:e,index:t})),r<o.length&&(ut(o,r),o=o.slice(0,r)),s&&o.sort(lt);const i=t*r,d=u.subarray(i,i+r),h=c.subarray(i,i+r);for(let e=0;e<r;e++)d[e]=o[e].value,h[e]=o[e].index}const d=t.slice();return d[d.length-1]=r,[(0,a.buffer)(d,n,u),(0,a.buffer)(d,"int32",c)]}function dt(e,t,n,r){const s=a.util.parseAxisParam(t,n)[0],o=[1,n[0],1];for(let e=0;e<s;e++)o[0]*=n[e];o[1]=n[s];for(let e=s+1;e<n.length;e++)o[2]*=n[e];const i={},l=new Int32Array(n[s]),u=new a.TensorBuffer(o,r,e),c=[],d=1===o[0]&&1===o[2];for(let t=0;t<n[s];t++){let n;if(d)n=e[t].toString();else{const e=[];for(let n=0;n<o[0];n++)for(let r=0;r<o[2];r++)e.push(u.get(n,t,r));n=e.join(",")}if(void 0!==i[n])l[t]=i[n];else{const e=Object.keys(i).length;i[n]=e,l[t]=e,c.push(t)}}const h=o.slice();h[1]=Object.keys(i).length;const p=new a.TensorBuffer(h,r);c.forEach(((e,t)=>{for(let n=0;n<o[0];n++)for(let r=0;r<o[2];r++)p.set(u.get(n,e,r),n,t,r)}));const f=n.slice();return f[s]=h[1],{outputValues:p.values,outputShape:f,indices:l}}const ht="3.15.0";(0,a.registerBackend)("cpu",(()=>new i),1);const pt=M(a.Elu,(e=>e>=0?e:Math.exp(e)-1)),ft={kernelName:a.Elu,backendName:"cpu",kernelFunc:pt};function mt(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{alpha:i}=r;s([o],"leakyRelu");const l=a.util.sizeFromShape(o.shape),u=n.data.get(o.dataId).values,c=a.util.getTypedArrayFromDType("float32",l);for(let e=0;e<u.length;e++)c[e]=u[e]<0?i*u[e]:u[e];return n.makeTensorInfo(o.shape,"float32",c)}const gt={kernelName:a.LeakyRelu,backendName:"cpu",kernelFunc:mt},bt=c(((e,t)=>e<0?t*e:e));function kt(e){const{inputs:t,backend:n}=e,{x:r,alpha:a}=t;s([r,a],"prelu");const o=n.data.get(r.dataId).values,i=n.data.get(a.dataId).values,[l,u]=bt(r.shape,a.shape,o,i,"float32");return n.makeTensorInfo(u,"float32",l)}const yt={kernelName:a.Prelu,backendName:"cpu",kernelFunc:kt},wt=M(a.Relu,(e=>Math.max(0,e))),It={kernelName:a.Relu,backendName:"cpu",kernelFunc:wt},vt=M(a.Relu6,(e=>Math.min(Math.max(0,e),6))),xt={kernelName:a.Relu6,backendName:"cpu",kernelFunc:vt};function St(e,t,n,r,a){if("linear"===n)return f({inputs:{x:t},backend:e});if("relu"===n)return wt({inputs:{x:t},backend:e});if("elu"===n)return pt({inputs:{x:t},backend:e});if("relu6"===n)return vt({inputs:{x:t},backend:e});if("prelu"===n)return kt({inputs:{x:t,alpha:r},backend:e});if("leakyrelu"===n)return mt({inputs:{x:t},backend:e,attrs:{alpha:a}});if("sigmoid"===n)return Pe({inputs:{x:t},backend:e});throw new Error(`Activation ${n} has not been implemented for the CPU backend.`)}function Et(e){const{inputs:t,backend:n,attrs:r}=e,{x:s}=t,{shape:o}=r,i=a.util.sizeFromShape(s.shape),l=a.util.inferFromImplicitShape(o,i),u=a.util.sizeFromShape(l);a.util.assert(i===u,(()=>`The new shape (${l}) has ${u} elements and the old shape (${s.shape}) has ${i} elements. The new shape and old shape must have the same number of elements.`)),n.incRef(s.dataId);const c=n.data.get(s.dataId);if(null!=c.complexTensorInfos){const e=c.complexTensorInfos.real,t=c.complexTensorInfos.imag;e.shape=l,t.shape=l}return{dataId:s.dataId,shape:l,dtype:s.dtype}}const Nt={kernelName:a.Reshape,backendName:"cpu",kernelFunc:Et};function Tt(e){const{inputs:t,backend:n,attrs:r}=e,{a:o,b:i}=t,{transposeA:l,transposeB:u}=r;s([o,i],"matMul");const c=o.shape.length,d=i.shape.length,h=l?o.shape[c-2]:o.shape[c-1],p=u?i.shape[d-1]:i.shape[d-2],f=l?o.shape[c-1]:o.shape[c-2],m=u?i.shape[d-2]:i.shape[d-1],g=o.shape.slice(0,-2),b=i.shape.slice(0,-2),k=a.util.sizeFromShape(g),y=a.util.sizeFromShape(b),w=a.broadcast_util.assertAndGetBroadcastShape(o.shape.slice(0,-2),i.shape.slice(0,-2)).concat([f,m]);a.util.assert(h===p,(()=>`Error in matMul: inner shapes (${h}) and (${p}) of Tensors with shapes ${o.shape} and ${i.shape} and transposeA=${l} and transposeB=${u} must match.`));const I=u?[y,m,p]:[y,p,m],v=Et({inputs:{x:o},backend:n,attrs:{shape:l?[k,h,f]:[k,f,h]}}),x=Et({inputs:{x:i},backend:n,attrs:{shape:I}}),S=l?v.shape[1]:v.shape[2],E=l?v.shape[2]:v.shape[1],N=u?x.shape[1]:x.shape[2],T=Math.max(k,y),A=n.data.get(v.dataId).values,M=n.data.get(x.dataId).values,F=a.util.computeStrides(v.shape),$=a.util.computeStrides(x.shape),[D,_,R]=l?[F[0],1,F[1]]:[F[0],F[1],1],[C,B,P]=u?[1,$[1],$[0]]:[$[1],1,$[0]],z=E*N,W=(0,a.buffer)([T,E,N],v.dtype),O=W.values,L=n.blockSize;for(let e=0;e<T;e++)for(let t=0;t<E;t+=L)for(let n=0;n<N;n+=L)for(let r=0;r<S;r+=L){const a=Math.min(t+L,E),s=Math.min(n+L,N),o=Math.min(r+L,S);for(let i=t;i<a;i++)for(let t=n;t<s;t++){let n=0;for(let a=r;a<o;a++){const r=Math.min(e,k-1)*D,s=Math.min(e,y-1)*P;n+=A[r+i*_+a*R]*M[a*C+t*B+s]}O[e*z+(i*N+t)]+=n}}return n.disposeIntermediateTensorInfo(v),n.disposeIntermediateTensorInfo(x),n.makeTensorInfo(w,W.dtype,W.values)}const At={kernelName:a.BatchMatMul,backendName:"cpu",kernelFunc:Tt},Mt={kernelName:a._FusedMatMul,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{a,b:s,bias:o,preluActivationWeights:i}=t,{transposeA:l,transposeB:u,activation:c,leakyreluAlpha:d}=r;let h,p,f;const m=[];h=Tt({inputs:{a,b:s},attrs:{transposeA:l,transposeB:u},backend:n}),o&&(p=S({inputs:{a:h,b:o},backend:n}),m.push(h),h=p),c&&(f=St(n,h,c,i,d),m.push(h),h=f);for(const e of m)n.disposeIntermediateTensorInfo(e);return h}},Ft=M(a.Acos,(e=>Math.acos(e))),$t={kernelName:a.Acos,backendName:"cpu",kernelFunc:Ft},Dt=M(a.Acosh,(e=>Math.acosh(e))),_t={kernelName:a.Acosh,backendName:"cpu",kernelFunc:Dt},Rt={kernelName:a.AddN,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,r=t;s(t,"addN");const o=r.map((e=>n.data.get(e.dataId).values)),i=(0,a.buffer)(r[0].shape,r[0].dtype),l=i.values;for(let e=0;e<r.length;e++){const t=o[e];for(let e=0;e<l.length;e++)l[e]+=t[e]}return n.makeTensorInfo(i.shape,i.dtype,i.values)}},Ct={kernelName:a.All,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{axis:i,keepDims:l}=r;s(o,"all");const u=a.util.parseAxisParam(i,o.shape);let c=u;const d=a.backend_util.getAxesPermutation(c,o.shape.length);let h=o;null!=d&&(h=Ae({inputs:{x:o},backend:n,attrs:{perm:d}}),c=a.backend_util.getInnerMostAxes(c.length,o.shape.length)),a.backend_util.assertAxesAreInnerMostDims("all",c,h.shape.length);const[p,f]=a.backend_util.computeOutAndReduceShapes(h.shape,c),m=a.util.sizeFromShape(f),g=a.util.makeZerosTypedArray(a.util.sizeFromShape(p),h.dtype),b=n.data.get(h.dataId).values;for(let e=0;e<g.length;++e){const t=e*m;let n=b[t];for(let e=0;e<m;++e){const r=b[t+e];n=n&&r}g[e]=n}null!=d&&n.disposeIntermediateTensorInfo(h);const k=n.makeTensorInfo(p,h.dtype,g);if(l){const e=Et({inputs:{x:k},backend:n,attrs:{shape:a.backend_util.expandShapeToKeepDim(p,u)}});return n.disposeIntermediateTensorInfo(k),e}return k}},Bt={kernelName:a.Any,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{axis:i,keepDims:l}=r;s(o,"any");const u=a.util.parseAxisParam(i,o.shape);let c=u;const d=a.backend_util.getAxesPermutation(c,o.shape.length);let h=o;null!=d&&(h=Ae({inputs:{x:o},backend:n,attrs:{perm:d}}),c=a.backend_util.getInnerMostAxes(c.length,o.shape.length)),a.backend_util.assertAxesAreInnerMostDims("any",c,h.shape.length);const[p,f]=a.backend_util.computeOutAndReduceShapes(h.shape,c),m=a.util.sizeFromShape(f),g=a.util.makeZerosTypedArray(a.util.sizeFromShape(p),h.dtype),b=n.data.get(h.dataId).values;for(let e=0;e<g.length;++e){const t=e*m;let n=b[t];for(let e=0;e<m;++e){const r=b[t+e];n=n||r}g[e]=n}null!=d&&n.disposeIntermediateTensorInfo(h);const k=n.makeTensorInfo(p,h.dtype,g);if(l){const e=Et({inputs:{x:k},backend:n,attrs:{shape:a.backend_util.expandShapeToKeepDim(p,u)}});return n.disposeIntermediateTensorInfo(k),e}return k}},Pt={kernelName:a.ArgMax,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{axis:i}=r;s(o,"argMax");let l=a.util.parseAxisParam(i,o.shape);const u=a.backend_util.getAxesPermutation(l,o.shape.length);let c=o;const d=[];null!=u&&(c=Ae({inputs:{x:o},backend:n,attrs:{perm:u}}),d.push(c),l=a.backend_util.getInnerMostAxes(l.length,c.shape.length)),l=[l[0]],a.backend_util.assertAxesAreInnerMostDims("argMax",l,c.shape.length);const[h,p]=a.backend_util.computeOutAndReduceShapes(c.shape,l),f=a.util.sizeFromShape(h),m=a.util.makeZerosTypedArray(f,"int32"),g=a.util.sizeFromShape(p),b=n.data.get(c.dataId).values;for(let e=0;e<m.length;++e){const t=e*g;let n=b[t],r=0;for(let e=0;e<g;++e){const a=b[t+e];a>n&&(n=a,r=e)}m[e]=r}return d.forEach((e=>n.disposeIntermediateTensorInfo(e))),n.makeTensorInfo(h,"int32",m)}},zt={kernelName:a.ArgMin,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{axis:i}=r;s(o,"argMin");let l=a.util.parseAxisParam(i,o.shape);const u=a.backend_util.getAxesPermutation(l,o.shape.length);let c=o;const d=[];null!=u&&(c=Ae({inputs:{x:o},backend:n,attrs:{perm:u}}),d.push(c),l=a.backend_util.getInnerMostAxes(l.length,c.shape.length)),l=[l[0]],a.backend_util.assertAxesAreInnerMostDims("argMin",l,c.shape.length);const[h,p]=a.backend_util.computeOutAndReduceShapes(c.shape,l),f=a.util.sizeFromShape(h),m=a.util.makeZerosTypedArray(f,"int32"),g=a.util.sizeFromShape(p),b=n.data.get(c.dataId).values;for(let e=0;e<m.length;++e){const t=e*g;let n=b[t],r=0;for(let e=0;e<g;++e){const a=b[t+e];a<n&&(n=a,r=e)}m[e]=r}return d.forEach((e=>n.disposeIntermediateTensorInfo(e))),n.makeTensorInfo(h,"int32",m)}},Wt=M(a.Asin,(e=>Math.asin(e))),Ot={kernelName:a.Asin,backendName:"cpu",kernelFunc:Wt},Lt=M(a.Asinh,(e=>Math.asinh(e))),Ht={kernelName:a.Asinh,backendName:"cpu",kernelFunc:Lt},Gt=M(a.Atan,(e=>Math.atan(e))),Kt={kernelName:a.Atan,backendName:"cpu",kernelFunc:Gt},qt=c(((e,t)=>Math.atan2(e,t))),Ut=w(a.Atan2,qt),Vt={kernelName:a.Atan2,backendName:"cpu",kernelFunc:Ut},jt=M(a.Atanh,(e=>Math.atanh(e))),Zt={kernelName:a.Atanh,backendName:"cpu",kernelFunc:jt};function Jt(e,t,n,r,s,o){const i=s.strideHeight,l=s.strideWidth,u=s.dilationHeight,c=s.dilationWidth,d=s.effectiveFilterHeight,h=s.effectiveFilterWidth,p=s.padInfo.top,f=s.padInfo.left,m="max"===o?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,g=(0,a.buffer)(s.outShape,n),b=g.values,k=s.outShape[1]*s.outShape[2]*s.outShape[3],y=s.outShape[2]*s.outShape[3],w=s.outShape[3];for(let t=0;t<s.batchSize;++t){const n=t*k,a=t*r[0];for(let t=0;t<s.inChannels;++t)for(let g=0;g<s.outHeight;++g){const k=g*i-p,I=Math.max(0,k),v=Math.min(s.inHeight,d+k),x=n+g*y;for(let n=0;n<s.outWidth;++n){const i=n*l-f,d=Math.max(0,i),p=Math.min(s.inWidth,h+i);let g=m,k=0,y=0;for(let n=I;n<v;n+=u){const s=a+n*r[1];for(let n=d;n<p;n+=c){const a=e[s+n*r[2]+t];"max"===o&&a>g?g=a:"avg"===o&&(k+=a,y++)}if(isNaN(g))break}b[x+n*w+t]="avg"===o?k/y:g}}}return g}function Yt(e,t,n,r,s=!1,o=!1){const i=(0,a.buffer)(r.outShape,"int32"),l=r.strideHeight,u=r.strideWidth,c=r.dilationHeight,d=r.dilationWidth,h=r.effectiveFilterHeight,p=r.effectiveFilterWidth,f=r.padInfo.top,m=r.padInfo.left,g=(0,a.buffer)(t,n,e);for(let e=0;e<r.batchSize;++e)for(let t=0;t<r.inChannels;++t)for(let n=0;n<r.outHeight;++n){const a=n*l-f;let b=a;for(;b<0;)b+=c;const k=Math.min(r.inHeight,h+a);for(let l=0;l<r.outWidth;++l){const h=l*u-m;let f=h;for(;f<0;)f+=d;const y=Math.min(r.inWidth,p+h);let w=Number.NEGATIVE_INFINITY,I=-1;for(let n=b;n<k;n+=c){const i=n-a;for(let a=f;a<y;a+=d){const l=a-h,u=g.get(e,n,a,t);u>w&&(w=u,I=s?o?((e*r.inHeight+n)*r.inWidth+a)*r.inChannels+t:(n*r.inWidth+a)*r.inChannels+t:i*p+l)}}i.set(I,e,n,l,t)}}return i}function Xt(e,t,n,r,s,o){const i=s.strideDepth,l=s.strideHeight,u=s.strideWidth,c=s.dilationDepth,d=s.dilationHeight,h=s.dilationWidth,p=s.effectiveFilterDepth,f=s.effectiveFilterHeight,m=s.effectiveFilterWidth,g=s.padInfo.front,b=s.padInfo.top,k=s.padInfo.left,y="max"===o?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,w=(0,a.buffer)(s.outShape,n),I=w.values,v=s.outShape[1]*s.outShape[2]*s.outShape[3]*s.outShape[4],x=s.outShape[2]*s.outShape[3]*s.outShape[4],S=s.outShape[3]*s.outShape[4],E=s.outShape[4];for(let t=0;t<s.batchSize;++t){const n=t*v,a=t*r[0];for(let t=0;t<s.inChannels;++t)for(let w=0;w<s.outDepth;++w){const v=w*i-g;let N=v;for(;N<0;)N+=c;const T=Math.min(s.inDepth,p+v),A=n+w*x;for(let n=0;n<s.outHeight;++n){const i=n*l-b;let p=i;for(;p<0;)p+=d;const g=Math.min(s.inHeight,f+i),w=A+n*S;for(let n=0;n<s.outWidth;++n){const i=n*u-k;let l=i;for(;l<0;)l+=h;const f=Math.min(s.inWidth,m+i),b=w+n*E;let v=y,x=0,S=0;for(let n=N;n<T;n+=c){const s=a+n*r[1];for(let n=p;n<g;n+=d){const a=s+n*r[2];for(let n=l;n<f;n+=h){const s=e[a+n*r[3]+t];if("max"===o&&s>v?v=s:"avg"===o&&(x+=s,S++),isNaN(v))break}if(isNaN(v))break}if(isNaN(v))break}I[b+t]="avg"===o?x/S:v}}}}return w}const Qt={kernelName:a.AvgPool,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t;s(o,"avgPool");const{filterSize:i,strides:l,pad:u,dimRoundingMode:c}=r;a.util.assert(a.backend_util.eitherStridesOrDilationsAreOne(l,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${l} and dilations '1'`));const d=a.backend_util.computePool2DInfo(o.shape,i,l,1,u,c);let h;if(1===d.filterWidth&&1===d.filterHeight&&a.util.arraysEqual(d.inShape,d.outShape))h=f({inputs:{x:o},backend:n});else{const e=n.data.get(o.dataId).values,t=a.util.computeStrides(o.shape),r=Jt(e,o.shape,o.dtype,t,d,"avg");h=n.makeTensorInfo(d.outShape,o.dtype,r.values)}return h}},en={kernelName:a.AvgPool3D,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{filterSize:i,strides:l,pad:u,dimRoundingMode:c,dataFormat:d}=r;s(o,"avgPool3d");const h=a.backend_util.computePool3DInfo(o.shape,i,l,1,u,c,d),p=Xt(n.data.get(o.dataId).values,o.shape,o.dtype,a.util.computeStrides(o.shape),h,"avg");return n.makeTensorInfo(p.shape,"float32",p.values)}},tn={kernelName:a.AvgPool3DGrad,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{dy:o,input:i}=t,{filterSize:l,strides:u,pad:c,dimRoundingMode:d}=r;s([o,i],"avgPool3DGrad");const h=a.backend_util.computePool3DInfo(i.shape,l,u,1,c,d),p=h.strideDepth,f=h.strideHeight,m=h.strideWidth,g=h.filterDepth,b=h.filterHeight,k=h.filterWidth,y=h.dilationDepth,w=h.dilationHeight,I=h.dilationWidth,v=h.effectiveFilterDepth,x=h.effectiveFilterHeight,S=h.effectiveFilterWidth,E=v-1-h.padInfo.front,N=S-1-h.padInfo.left,T=x-1-h.padInfo.top,A=(0,a.buffer)(i.shape,"float32"),M=1/(g*b*k),F=n.bufferSync(o);for(let e=0;e<h.batchSize;++e)for(let t=0;t<h.inChannels;++t)for(let n=0;n<h.inDepth;++n)for(let r=0;r<h.inHeight;++r)for(let a=0;a<h.inWidth;++a){const s=n-E,o=r-T,i=a-N;let l=0;for(let n=0;n<v;n+=y){const r=(s+n)/p;if(!(r<0||r>=h.outDepth||Math.floor(r)!==r))for(let n=0;n<x;n+=w){const a=(o+n)/f;if(!(a<0||a>=h.outHeight||Math.floor(a)!==a))for(let n=0;n<S;n+=I){const s=(i+n)/m;s<0||s>=h.outWidth||Math.floor(s)!==s||(l+=F.get(e,r,a,s,t))}}}A.set(l*M,e,n,r,a,t)}return n.makeTensorInfo(A.shape,A.dtype,A.values)}},nn={kernelName:a.AvgPoolGrad,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{dy:o,input:i}=t,l=i;s([o,i],"avgPoolGrad");const{filterSize:u,strides:c,pad:d}=r,h=a.backend_util.computePool2DInfo(l.shape,u,c,1,d),p=h.strideHeight,f=h.strideWidth,m=h.filterHeight,g=h.filterWidth,b=h.dilationHeight,k=h.dilationWidth,y=h.effectiveFilterHeight,w=h.effectiveFilterWidth,I=w-1-h.padInfo.left,v=y-1-h.padInfo.top,x=(0,a.buffer)(l.shape,"float32"),S=1/(m*g),E=n.data.get(o.dataId).values,N=(0,a.buffer)(o.shape,"float32",E);for(let e=0;e<h.batchSize;++e)for(let t=0;t<h.inChannels;++t)for(let n=0;n<h.inHeight;++n)for(let r=0;r<h.inWidth;++r){const a=n-v,s=r-I;let o=0;for(let n=0;n<y;n+=b){const r=(a+n)/p;if(!(r<0||r>=h.outHeight||Math.floor(r)!==r))for(let n=0;n<w;n+=k){const a=(s+n)/f;a<0||a>=h.outWidth||Math.floor(a)!==a||(o+=N.get(e,r,a,t))}}x.set(o*S,e,n,r,t)}return n.makeTensorInfo(x.shape,x.dtype,x.values)}},rn={kernelName:a.FusedBatchNorm,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o,scale:i,offset:l,mean:u,variance:c}=t;a.util.assert(u.shape.length===c.shape.length,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),a.util.assert(null==l||u.shape.length===l.shape.length,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),a.util.assert(null==i||u.shape.length===i.shape.length,(()=>"Batch normalization gradient requires mean and scale to have equal ranks.")),s([o,u,c,i,l],"batchNorm");let{varianceEpsilon:d}=r;null==d&&(d=.001);const h=n.data.get(o.dataId).values,p=n.data.get(u.dataId).values,f=n.data.get(c.dataId).values,m=i?n.data.get(i.dataId).values:new Float32Array([1]),g=l?n.data.get(l.dataId).values:new Float32Array([0]),b=new Float32Array(h.length),k=g.length,y=m.length,w=f.length,I=p.length;let v=0,x=0,S=0,E=0;for(let e=0;e<h.length;++e)b[e]=g[v++]+(h[e]-p[x++])*m[S++]/Math.sqrt(f[E++]+d),v>=k&&(v=0),x>=I&&(x=0),S>=y&&(S=0),E>=w&&(E=0);return n.makeTensorInfo(o.shape,o.dtype,b)}},an={kernelName:a.BatchToSpaceND,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{blockShape:i,crops:l}=r;s([o],"batchToSpaceND");const u=i.reduce(((e,t)=>e*t)),c=a.backend_util.getReshaped(o.shape,i,u),d=a.backend_util.getPermuted(c.length,i.length),h=a.backend_util.getReshapedPermuted(o.shape,i,u),p=a.backend_util.getSliceBeginCoords(l,i.length),f=a.backend_util.getSliceSize(h,l,i.length),m=Et({inputs:{x:o},backend:n,attrs:{shape:c}}),g=Ae({inputs:{x:m},backend:n,attrs:{perm:d}}),b=Et({inputs:{x:g},backend:n,attrs:{shape:h}}),k=Oe({inputs:{x:b},backend:n,attrs:{begin:p,size:f}});return n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(g),n.disposeIntermediateTensorInfo(b),k}},sn={kernelName:a.Bincount,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,weights:s}=t,{size:o}=r,i=N(n.data.get(a.dataId).values,n.data.get(s.dataId).values,s.dtype,s.shape,o);return n.makeTensorInfo([o],s.dtype,i)}},on={kernelName:a.BroadcastArgs,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{s0:r,s1:s}=t,o=n.data.get(r.dataId).values,i=n.data.get(s.dataId).values,l=a.backend_util.assertAndGetBroadcastShape(Array.from(o),Array.from(i));return n.makeTensorInfo([l.length],"int32",Int32Array.from(l))}},ln=M(a.ClipByValue,((e,t)=>{const n=t;return e>n.clipValueMax?n.clipValueMax:e<n.clipValueMin?n.clipValueMin:e})),un={kernelName:a.ClipByValue,backendName:"cpu",kernelFunc:ln},cn={kernelName:a.ComplexAbs,backendName:"cpu",kernelFunc:e=>{const{x:t}=e.inputs,n=e.backend,r=new Float32Array(a.util.sizeFromShape(t.shape)),s=n.data.get(t.dataId),o=s.complexTensorInfos.real,i=s.complexTensorInfos.imag,l=n.data.get(o.dataId).values,u=n.data.get(i.dataId).values;for(let e=0;e<l.length;e++){const t=l[e],n=u[e];r[e]=Math.hypot(t,n)}return n.makeOutput(r,t.shape,"float32")}};function dn(e){const{inputs:t,backend:n}=e,{input:r}=t,a=n.data.get(r.dataId).complexTensorInfos.imag,s=n.data.get(a.dataId).values;return n.makeTensorInfo(a.shape,a.dtype,s)}const hn={kernelName:a.Imag,backendName:"cpu",kernelFunc:dn};function pn(e){const{inputs:t,backend:n,attrs:r}=e,{axis:s}=r,o=a.util.parseAxisParam(s,t[0].shape)[0];let i=a.backend_util.computeOutShape(t.map((e=>e.shape)),o);if(0===a.util.sizeFromShape(i))return n.makeTensorInfo(i,t[0].dtype,[]);const l=t.filter((e=>a.util.sizeFromShape(e.shape)>0));if(1===l.length)return f({inputs:{x:l[0]},backend:n});const u=l.map((e=>e.shape));if(a.backend_util.assertParamsConsistent(u,o),"complex64"===l[0].dtype){const e=l.map((e=>g({inputs:{input:e},backend:n}))),t=l.map((e=>dn({inputs:{input:e},backend:n}))),r=pn({inputs:e,backend:n,attrs:{axis:o}}),a=pn({inputs:t,backend:n,attrs:{axis:o}}),s=d({inputs:{real:r,imag:a},backend:n});return e.forEach((e=>n.disposeIntermediateTensorInfo(e))),t.forEach((e=>n.disposeIntermediateTensorInfo(e))),n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(a),s}const c=l.map((e=>{const t=a.util.sizeFromShape(e.shape.slice(o));return Et({inputs:{x:e},backend:n,attrs:{shape:[-1,t]}})})),h=c.map((e=>({vals:n.data.get(e.dataId).values,shape:e.shape})));i=a.backend_util.computeOutShape(c.map((e=>e.shape)),1);const p=1===c[0].shape[0],m=R(h,i,t[0].dtype,p),b=a.backend_util.computeOutShape(l.map((e=>e.shape)),o),k=n.makeTensorInfo(b,t[0].dtype,m);return c.forEach((e=>n.disposeIntermediateTensorInfo(e))),k}const fn={kernelName:a.Concat,backendName:"cpu",kernelFunc:pn};function mn(e){const{inputs:t,backend:n,attrs:r}=e,{x:o,filter:i}=t,{strides:l,pad:u,dataFormat:c,dilations:d,dimRoundingMode:h}=r;s([o,i],"conv2d");const p=a.backend_util.convertConv2DDataFormat(c),f=a.backend_util.computeConv2DInfo(o.shape,i.shape,l,d,u,h,!1,p),m=f.filterHeight,g=f.filterWidth,b=f.dilationHeight,k=f.dilationWidth,y=f.padInfo.left,w=f.padInfo.top,I="channelsLast"===f.dataFormat,v=new a.TensorBuffer(f.outShape,o.dtype),x=a.util.computeStrides(o.shape),S=a.util.computeStrides(i.shape),E=x[0],N=I?x[1]:x[2],T=I?x[2]:1,A=I?1:x[1],M=v.strides[0],F=I?v.strides[1]:v.strides[2],$=I?v.strides[2]:1,D=I?1:v.strides[1],_=n.data.get(o.dataId).values,R=n.data.get(i.dataId).values,C=v.values;for(let e=0;e<f.batchSize;++e){const t=e*E,n=e*M;for(let e=0;e<f.outHeight;++e){const r=n+e*F,a=e*f.strideHeight-w;for(let e=0;e<m;++e){const n=a+e*b;if(n<0||n>=f.inHeight)continue;const s=e*S[0],o=t+n*N;for(let e=0;e<f.outWidth;++e){const t=r+e*$,n=e*f.strideWidth-y;for(let e=0;e<g;++e){const r=n+e*k;if(r<0||r>=f.inWidth)continue;const a=o+r*T;let i=s+e*S[1];for(let e=0;e<f.inChannels;++e){const n=_[a+e*A];for(let e=0;e<f.outChannels;++e)C[t+e*D]+=n*R[i+e];i+=f.outChannels}}}}}}return n.makeTensorInfo(v.shape,v.dtype,C)}const gn={kernelName:a.Conv2D,backendName:"cpu",kernelFunc:mn},bn={kernelName:a.Conv2DBackpropFilter,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o,dy:i}=t,{strides:l,pad:u,dataFormat:c,dimRoundingMode:d,filterShape:h}=r;s([o,i],"conv2dBackpropFilter");const p=a.backend_util.convertConv2DDataFormat(c),f=a.backend_util.computeConv2DInfo(o.shape,h,l,1,u,d,!1,p),{strideHeight:m,strideWidth:g,filterHeight:b,filterWidth:k}=f,y="channelsLast"===f.dataFormat,w=new a.TensorBuffer(f.filterShape,"float32"),I=f.padInfo.left,v=f.padInfo.top,x=n.data.get(o.dataId).values,S=n.data.get(i.dataId).values,E=new a.TensorBuffer(o.shape,o.dtype,x),N=new a.TensorBuffer(i.shape,i.dtype,S);for(let e=0;e<b;++e){const t=Math.max(0,Math.ceil((v-e)/m)),n=Math.min(f.outHeight,(f.inHeight+v-e)/m);for(let r=0;r<k;++r){const a=Math.max(0,Math.ceil((I-r)/g)),s=Math.min(f.outWidth,(f.inWidth+I-r)/g);for(let o=0;o<f.inChannels;++o)for(let i=0;i<f.outChannels;++i){let l=0;for(let u=0;u<f.batchSize;++u)for(let c=t;c<n;++c){const t=e+c*m-v;for(let e=a;e<s;++e){const n=r+e*g-I;l+=y?E.get(u,t,n,o)*N.get(u,c,e,i):E.get(u,o,t,n)*N.get(u,i,c,e)}}w.set(l,e,r,o,i)}}}return n.makeTensorInfo(w.shape,w.dtype,w.values)}},kn={kernelName:a.Conv2DBackpropInput,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{dy:o,filter:i}=t,{inputShape:l,strides:u,pad:c,dataFormat:d,dimRoundingMode:h}=r;s([o,i],"conv2dBackpropInput");const p=a.util.computeStrides(i.shape),f=a.util.computeStrides(o.shape);let m=a.backend_util.convertConv2DDataFormat(d);const g=a.backend_util.computeConv2DInfo(l,i.shape,u,1,c,h,!1,m),b=new a.TensorBuffer(g.inShape,"float32"),k=b.values,y=n.data.get(o.dataId).values,w=n.data.get(i.dataId).values,[I,v,x]=p,{batchSize:S,filterHeight:E,filterWidth:N,inChannels:T,inHeight:A,inWidth:M,outChannels:F,outHeight:$,outWidth:D,strideHeight:_,strideWidth:R}=g;m=g.dataFormat;const C=E-1-g.padInfo.top,B=N-1-g.padInfo.left,P="channelsLast"===m,z=b.strides[0],W=P?b.strides[1]:b.strides[2],O=P?b.strides[2]:1,L=P?1:b.strides[1],H=f[0],G=P?f[1]:f[2],K=P?f[2]:1,q=P?1:f[1];for(let e=0;e<S;++e)for(let t=0;t<T;++t)for(let n=0;n<A;++n){const r=n-C,a=Math.max(0,Math.ceil(r/_)),s=Math.min($,(E+r)/_);for(let o=0;o<M;++o){const i=o-B,l=Math.max(0,Math.ceil(i/R)),u=Math.min(D,(N+i)/R);let c=0;for(let n=a;n<s;++n){const a=n*_-r;for(let r=l;r<u;++r){const s=H*e+G*n+K*r,o=I*(E-1-a)+v*(N-1-(r*R-i))+x*t;for(let e=0;e<F;++e)c+=y[s+q*e]*w[o+e]}}k[z*e+W*n+O*o+L*t]=c}}return n.makeTensorInfo(b.shape,b.dtype,b.values)}},yn={kernelName:a.Conv3D,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o,filter:i}=t,{strides:l,pad:u,dilations:c}=r;s([o,i],"conv3d");const d=a.backend_util.computeConv3DInfo(o.shape,i.shape,l,c,u),{filterDepth:h,filterHeight:p,filterWidth:f,dilationDepth:m,dilationHeight:g,dilationWidth:b,padInfo:k}=d,y=k.front,w=k.left,I=k.top,v=new a.TensorBuffer(d.outShape,o.dtype),x=n.data.get(o.dataId).values,S=n.data.get(i.dataId).values,E=v.values,N=a.util.computeStrides(o.shape),T=a.util.computeStrides(i.shape);for(let e=0;e<d.batchSize;++e){const t=e*N[0],n=e*v.strides[0];for(let e=0;e<d.outDepth;++e){const r=n+e*v.strides[1],a=e*d.strideDepth-y;for(let e=0;e<h;++e){const n=a+e*m;if(n<0||n>=d.inDepth)continue;const s=e*T[0],o=t+n*N[1];for(let e=0;e<d.outHeight;++e){const t=r+e*v.strides[2],n=e*d.strideHeight-I;for(let e=0;e<p;++e){const r=n+e*g;if(r<0||r>=d.inHeight)continue;const a=s+e*T[1],i=o+r*N[2];for(let e=0;e<d.outWidth;++e){const n=t+e*d.outChannels,r=e*d.strideWidth-w;for(let e=0;e<f;++e){const t=r+e*b;if(t<0||t>=d.inWidth)continue;const s=a+e*T[2],o=i+t*d.inChannels;let l=s;for(let e=0;e<d.inChannels;++e){const t=x[o+e];for(let e=0;e<d.outChannels;++e)E[n+e]+=t*S[l+e];l+=d.outChannels}}}}}}}}return n.makeTensorInfo(v.shape,v.dtype,v.values)}},wn={kernelName:a.Conv3DBackpropFilterV2,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o,dy:i}=t,{strides:l,pad:u,filterShape:c}=r;s([o,i],"conv3dBackpropFilterV2");const d=a.util.computeStrides(o.shape),h=a.util.computeStrides(i.shape),p=a.backend_util.computeConv3DInfo(o.shape,c,l,1,u),f=p.strideDepth,m=p.strideHeight,g=p.strideWidth,b=p.filterDepth,k=p.filterHeight,y=p.filterWidth,w=new a.TensorBuffer(p.filterShape,"float32"),I=w.values,[v,x,S,E]=w.strides,N=n.data.get(i.dataId).values,[T,A,M,F]=h,$=n.data.get(o.dataId).values,[D,_,R,C]=d,B=p.padInfo.front,P=p.padInfo.left,z=p.padInfo.top;for(let e=0;e<b;++e){const t=Math.max(0,Math.ceil((B-e)/f)),n=Math.min(p.outDepth,(p.inDepth+B-e)/f),r=e*v;for(let a=0;a<k;++a){const s=Math.max(0,Math.ceil((z-a)/m)),o=Math.min(p.outHeight,(p.inHeight+z-a)/m),i=a*x+r;for(let r=0;r<y;++r){const l=Math.max(0,Math.ceil((P-r)/g)),u=Math.min(p.outWidth,(p.inWidth+P-r)/g),c=r*S+i;for(let i=0;i<p.inChannels;++i){const d=i*E+c;for(let c=0;c<p.outChannels;++c){let h=0;for(let d=0;d<p.batchSize;++d){const p=d*D,b=d*T;for(let d=t;d<n;++d){const t=(e+d*f-B)*_+p,n=d*A+b;for(let e=s;e<o;++e){const s=(a+e*m-z)*R+t,o=e*M+n;for(let e=l;e<u;++e){const t=e*F+o;h+=$[(r+e*g-P)*C+s+i]*N[t+c]}}}}I[d+c]=h}}}}}return n.makeTensorInfo(w.shape,w.dtype,w.values)}},In={kernelName:a.Conv3DBackpropInputV2,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{dy:o,filter:i}=t,{pad:l,strides:u,inputShape:c}=r;s([o],"conv3dBackpropInputV2");const d=a.util.computeStrides(o.shape),h=a.util.computeStrides(i.shape),p=a.backend_util.computeConv3DInfo(c,i.shape,u,1,l),f=new a.TensorBuffer(p.inShape,"float32"),m=f.values,[g,b,k,y]=f.strides,w=n.data.get(o.dataId).values,[I,v,x,S]=d,E=n.data.get(i.dataId).values,[N,T,A,M]=h,{batchSize:F,filterDepth:$,filterHeight:D,filterWidth:_,inChannels:R,inDepth:C,inHeight:B,inWidth:P,outChannels:z,outDepth:W,outHeight:O,outWidth:L,strideDepth:H,strideHeight:G,strideWidth:K}=p,q=$-1-p.padInfo.front,U=D-1-p.padInfo.top,V=_-1-p.padInfo.left;for(let e=0;e<F;++e)for(let t=0;t<R;++t)for(let n=0;n<C;++n){const r=n-q,a=Math.max(0,Math.ceil(r/H)),s=Math.min(W,($+r)/H);for(let o=0;o<B;++o){const i=o-U,l=Math.max(0,Math.ceil(i/G)),u=Math.min(O,(D+i)/G);for(let c=0;c<P;++c){const d=c-V,h=Math.max(0,Math.ceil(d/K)),p=Math.min(L,(_+d)/K);let f=0;for(let n=a;n<s;++n){const a=n*H-r;for(let r=l;r<u;++r){const s=r*G-i;for(let o=h;o<p;++o){const i=I*e+v*n+x*r+S*o,l=N*($-1-a)+T*(D-1-s)+A*(_-1-(o*K-d))+M*t;for(let e=0;e<z;++e)f+=w[i+e]*E[l+e]}}}m[g*e+b*n+k*o+y*c+t]=f}}}return n.makeTensorInfo(f.shape,f.dtype,f.values)}},vn=M(a.Cos,(e=>Math.cos(e))),xn={kernelName:a.Cos,backendName:"cpu",kernelFunc:vn},Sn=M(a.Cosh,(e=>Math.cosh(e))),En={kernelName:a.Cosh,backendName:"cpu",kernelFunc:Sn},Nn={kernelName:a.CropAndResize,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{image:s,boxes:o,boxInd:i}=t,{cropSize:l,method:u,extrapolationValue:c}=r,[d,h,p,f]=s.shape,m=o.shape[0],[g,b]=l,k=(0,a.buffer)([m,g,b,f],"float32"),y=n.data.get(o.dataId).values,w=n.data.get(i.dataId).values,I=n.data.get(s.dataId).values,v=a.util.computeStrides(s.shape),x=a.util.computeStrides(k.shape);for(let e=0;e<m;e++){const t=4*e,n=y[t],r=y[t+1],a=y[t+2],s=y[t+3],o=w[e];if(o>=d)continue;const i=g>1?(a-n)*(h-1)/(g-1):0,l=b>1?(s-r)*(p-1)/(b-1):0;for(let t=0;t<g;t++){const d=g>1?n*(h-1)+t*i:.5*(n+a)*(h-1);if(d<0||d>h-1)for(let n=0;n<b;n++)for(let r=0;r<f;r++){const a=r+n*x[2]+t*x[1]+e*x[0];k.values[a]=c}else if("bilinear"===u){const n=Math.floor(d),a=Math.ceil(d),i=d-n;for(let u=0;u<b;u++){const d=b>1?r*(p-1)+u*l:.5*(r+s)*(p-1);if(d<0||d>p-1){for(let n=0;n<f;n++){const r=n+u*x[2]+t*x[1]+e*x[0];k.values[r]=c}continue}const h=Math.floor(d),m=Math.ceil(d),g=d-h;for(let r=0;r<f;r++){let s=r+h*v[2]+n*v[1]+o*v[0];const l=I[s];s=r+m*v[2]+n*v[1]+o*v[0];const c=I[s];s=r+h*v[2]+a*v[1]+o*v[0];const d=I[s];s=r+m*v[2]+a*v[1]+o*v[0];const p=l+(c-l)*g,f=d+(I[s]-d)*g;s=r+u*x[2]+t*x[1]+e*x[0],k.values[s]=p+(f-p)*i}}}else for(let n=0;n<b;++n){const a=b>1?r*(p-1)+n*l:.5*(r+s)*(p-1);if(a<0||a>p-1){for(let r=0;r<f;r++){const a=r+n*x[2]+t*x[1]+e*x[0];k.values[a]=c}continue}const i=Math.round(a),u=Math.round(d);for(let r=0;r<f;r++){const a=r+i*v[2]+u*v[1]+o*v[0],s=r+n*x[2]+t*x[1]+e*x[0];k.values[s]=I[a]}}}}return n.makeTensorInfo(k.shape,k.dtype,k.values)}},Tn={kernelName:a.Cumprod,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{axis:i,exclusive:l,reverse:u}=r;s(o,"cumprod");const c=a.backend_util.getAxesPermutation([i],o.shape.length);let d=o;null!=c&&(d=Ae({inputs:{x:o},backend:n,attrs:{perm:c}}));const h=a.backend_util.getInnerMostAxes(1,o.shape.length)[0];if(h!==d.shape.length-1)throw new Error(`backend.cumprod in CPU expects an inner-most axis=${d.shape.length-1} but got axis=${h}`);const p=(0,a.upcastType)(d.dtype,"int32"),f=a.util.makeOnesTypedArray(a.util.sizeFromShape(d.shape),p),m=n.data.get(d.dataId).values,g=d.shape[d.shape.length-1],b=u?(e,t)=>e+g-t-1:(e,t)=>e+t;for(let e=0;e<m.length;e+=g)for(let t=0;t<g;t++){const n=b(e,t);if(0===t)f[n]=l?1:m[n];else{const r=b(e,t-1);f[n]=l?m[r]*f[r]:m[n]*f[r]}}const k=n.makeTensorInfo(d.shape,p,f);if(null!=c){const e=Ae({inputs:{x:k},backend:n,attrs:{perm:a.backend_util.getUndoAxesPermutation(c)}});return n.disposeIntermediateTensorInfo(k),n.disposeIntermediateTensorInfo(d),e}return k}},An={kernelName:a.Cumsum,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{axis:i,exclusive:l,reverse:u}=r;s(o,"cumsum");const c=a.backend_util.getAxesPermutation([i],o.shape.length);let d=o;null!=c&&(d=Ae({inputs:{x:o},backend:n,attrs:{perm:c}}));const h=a.backend_util.getInnerMostAxes(1,o.shape.length)[0];if(h!==d.shape.length-1)throw new Error(`backend.cumsum in CPU expects an inner-most axis=${d.shape.length-1} but got axis=${h}`);const p=(0,a.upcastType)(d.dtype,"int32"),f=a.util.makeZerosTypedArray(a.util.sizeFromShape(d.shape),p),m=n.data.get(d.dataId).values,g=d.shape[d.shape.length-1],b=u?(e,t)=>e+g-t-1:(e,t)=>e+t;for(let e=0;e<m.length;e+=g)for(let t=0;t<g;t++){const n=b(e,t);if(0===t)f[n]=l?0:m[n];else{const r=b(e,t-1);f[n]=l?m[r]+f[r]:m[n]+f[r]}}const k=n.makeTensorInfo(d.shape,p,f);if(null!=c){const e=Ae({inputs:{x:k},backend:n,attrs:{perm:a.backend_util.getUndoAxesPermutation(c)}});return n.disposeIntermediateTensorInfo(k),n.disposeIntermediateTensorInfo(d),e}return k}},Mn={kernelName:a.DenseBincount,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,weights:s}=t,{size:o,binaryOutput:i}=r;if(1===a.shape.length){const e=N(n.data.get(a.dataId).values,n.data.get(s.dataId).values,s.dtype,s.shape,o);return n.makeTensorInfo([o],s.dtype,e)}if(2===a.shape.length){const e=T(n.bufferSync(a),n.bufferSync(s),o,i);return n.makeTensorInfo(e.shape,s.dtype,e.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${a.shape.length}.`)}},Fn={kernelName:a.DepthToSpace,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:s}=t,{blockSize:o,dataFormat:i}=r;a.util.assert("NHWC"===i,(()=>`Only NHWC dataFormat supported on CPU for depthToSpace. Got ${i}`));const l=s.shape[0],u=s.shape[1],c=s.shape[2],d=s.shape[3],h=u*o,p=c*o,f=d/(o*o),m=n.data.get(s.dataId).values,g=new Float32Array(l*h*p*f);let b=0;for(let e=0;e<l;++e)for(let t=0;t<h;++t){const n=Math.floor(t/o),r=t%o;for(let t=0;t<p;++t){const a=Math.floor(t/o),s=(r*o+t%o)*f;for(let t=0;t<f;++t){const r=t+s+d*(a+c*(n+u*e));g[b++]=m[r]}}}return n.makeTensorInfo([l,h,p,f],s.dtype,g)}};function $n(e){const{inputs:t,backend:n,attrs:r}=e,{x:o,filter:i}=t,{strides:l,pad:u,dilations:c,dimRoundingMode:d}=r;s([o,i],"depthwiseConv2DNative");const h=a.util.computeStrides(o.shape),p=a.util.computeStrides(i.shape);let f=c;null==f&&(f=[1,1]),a.util.assert(a.backend_util.eitherStridesOrDilationsAreOne(l,f),(()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${l} and dilations '${f}'`));const m=a.backend_util.computeConv2DInfo(o.shape,i.shape,l,f,u,d,!0),{filterHeight:g,filterWidth:b,dilationHeight:k,dilationWidth:y,padInfo:w}=m,I=w.left,v=w.top,x=m.outChannels/m.inChannels,S=new a.TensorBuffer(m.outShape,o.dtype),E=n.data.get(o.dataId).values,N=n.data.get(i.dataId).values,T=S.values;for(let e=0;e<m.batchSize;++e){const t=e*h[0],n=e*S.strides[0];for(let e=0;e<m.outHeight;++e){const r=n+e*S.strides[1],a=e*m.strideHeight-v;for(let e=0;e<g;++e){const n=a+e*k;if(n<0||n>=m.inHeight)continue;const s=e*p[0],o=t+n*h[1];for(let e=0;e<m.outWidth;++e){const t=r+e*S.strides[2],n=e*m.strideWidth-I;for(let e=0;e<b;++e){const r=n+e*y;if(r<0||r>=m.inWidth)continue;const a=s+e*p[1],i=o+r*m.inChannels;let l=t,u=a;for(let e=0;e<m.inChannels;++e){const t=E[i+e];for(let e=0;e<x;++e)T[l+e]+=t*N[u+e];l+=x,u+=x}}}}}}return n.makeTensorInfo(S.shape,S.dtype,S.values)}const Dn={kernelName:a.DepthwiseConv2dNative,backendName:"cpu",kernelFunc:$n},_n={kernelName:a.DepthwiseConv2dNativeBackpropFilter,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o,dy:i}=t,{strides:l,dilations:u,pad:c,dimRoundingMode:d,filterShape:h}=r;s([o,i],"depthwiseConv2dNativeBackpropFilter");const p=a.backend_util.computeConv2DInfo(o.shape,h,l,u,c,d,!0),{strideHeight:f,strideWidth:m,filterHeight:g,filterWidth:b}=p,k=new a.TensorBuffer(p.filterShape,"float32"),y=p.padInfo.left,w=p.padInfo.top,I=p.outChannels/p.inChannels,v=n.data.get(o.dataId).values,x=new a.TensorBuffer(o.shape,o.dtype,v),S=n.data.get(i.dataId).values,E=new a.TensorBuffer(i.shape,i.dtype,S);for(let e=0;e<g;++e){const t=Math.max(0,Math.ceil((w-e)/f)),n=Math.min(p.outHeight,(p.inHeight+w-e)/f);for(let r=0;r<b;++r){const a=Math.max(0,Math.ceil((y-r)/m)),s=Math.min(p.outWidth,(p.inWidth+y-r)/m);for(let o=0;o<p.outChannels;++o){const i=Math.trunc(o/I),l=o%I;let u=0;for(let l=0;l<p.batchSize;++l)for(let c=t;c<n;++c){const t=e+c*f-w;for(let e=a;e<s;++e){const n=r+e*m-y;u+=x.get(l,t,n,i)*E.get(l,c,e,o)}}k.set(u,e,r,i,l)}}}return n.makeTensorInfo(k.shape,k.dtype,k.values)}},Rn={kernelName:a.DepthwiseConv2dNativeBackpropInput,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{dy:o,filter:i}=t,{strides:l,dilations:u,pad:c,dimRoundingMode:d,inputShape:h}=r;s([o,i],"depthwiseConv2DNativeBackpropInput");const p=a.util.computeStrides(o.shape),f=a.util.computeStrides(i.shape),m=a.backend_util.computeConv2DInfo(h,i.shape,l,u,c,d,!0),g=new a.TensorBuffer(m.inShape,"float32"),b=g.values,[k,y,w]=g.strides,I=n.data.get(o.dataId).values,[v,x,S]=p,E=n.data.get(i.dataId).values,[N,T,A]=f,{batchSize:M,filterHeight:F,filterWidth:$,inChannels:D,inHeight:_,inWidth:R,outChannels:C,outHeight:B,outWidth:P,strideHeight:z,strideWidth:W}=m,O=F-1-m.padInfo.top,L=$-1-m.padInfo.left,H=C/D;for(let e=0;e<M;++e)for(let t=0;t<D;++t)for(let n=0;n<_;++n){const r=n-O,a=Math.max(0,Math.ceil(r/z)),s=Math.min(B,(F+r)/z);for(let o=0;o<R;++o){const i=o-L,l=Math.max(0,Math.ceil(i/W)),u=Math.min(P,($+i)/W);let c=0;for(let n=a;n<s;++n){const a=n*z-r;for(let r=l;r<u;++r){const s=v*e+x*n+S*r,o=N*(F-1-a)+T*($-1-(r*W-i))+A*t;for(let e=0;e<H;++e)c+=I[s+(t*H+e)]*E[o+e]}}b[k*e+y*n+w*o+t]=c}}return n.makeTensorInfo(g.shape,g.dtype,g.values)}},Cn={kernelName:a.Diag,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{x:r}=t,s=a.util.sizeFromShape(r.shape),o=n.data.get(r.dataId).values,i=(0,a.buffer)([s,s],r.dtype),l=i.values;for(let e=0;e<o.length;e++)l[e*s+e]=o[e];const u=[...r.shape,...r.shape];return n.makeTensorInfo(u,i.dtype,i.values)}},Bn={kernelName:a.Dilation2D,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:r,filter:s}=e,{strides:o,pad:i,dilations:l}=n,u=t,c=u.data.get(r.dataId).values,d=r.shape.length,h=u.data.get(s.dataId).values,p=s.shape.length,{batchSize:f,inHeight:m,inWidth:g,inChannels:b,outHeight:k,outWidth:y,padInfo:w,strideHeight:I,strideWidth:v,filterHeight:x,filterWidth:S,dilationHeight:E,dilationWidth:N,outShape:T}=a.backend_util.computeDilation2DInfo(r.shape,s.shape,o,i,"NHWC",l),A=a.util.sizeFromShape(T),M=T.length,F=a.util.getArrayFromDType(r.dtype,A);for(let e=0;e<f;++e)for(let t=0;t<k;++t){const n=t*I-w.top;for(let o=0;o<y;++o){const i=o*v-w.left;for(let l=0;l<b;++l){let u=Number.MIN_SAFE_INTEGER;for(let t=0;t<x;++t){const o=n+t*E;if(o>=0&&o<m)for(let n=0;n<S;++n){const f=i+n*N;if(f>=0&&f<g){const i=a.util.locToIndex([e,o,f,l],d,a.util.computeStrides(r.shape)),m=a.util.locToIndex([t,n,l],p,a.util.computeStrides(s.shape)),g=c[i]+h[m];g>u&&(u=g)}}}F[a.util.locToIndex([e,t,o,l],M,a.util.computeStrides(T))]=u}}}return{dataId:u.write(a.util.toTypedArray(F,r.dtype),T,r.dtype),shape:T,dtype:r.dtype}}},Pn={kernelName:a.Dilation2DBackpropFilter,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:r,filter:s,dy:o}=e,{strides:i,pad:l,dilations:u}=n,c=t,d=a.util.toNestedArray(r.shape,c.data.get(r.dataId).values),h=a.util.toNestedArray(s.shape,c.data.get(s.dataId).values),{batchSize:p,inHeight:f,inWidth:m,inChannels:g,outHeight:b,outWidth:k,padInfo:y,strideHeight:w,strideWidth:I,filterHeight:v,filterWidth:x,dilationHeight:S,dilationWidth:E,outShape:N}=a.backend_util.computeDilation2DInfo(r.shape,s.shape,i,l,"NHWC",u);a.util.assert(o.rank===N.length,(()=>`Error in ${a.Dilation2DBackpropFilter}, dy must have the same rank as output ${N.length}, but got ${o.rank}`));const T=a.util.toNestedArray(N,c.data.get(o.dataId).values),A=a.util.makeZerosNestedTypedArray(s.shape,s.dtype);for(let e=0;e<p;++e)for(let t=0;t<b;++t){const n=t*w-y.top;for(let r=0;r<k;++r){const a=r*I-y.left;for(let s=0;s<g;++s){let o=Number.MIN_SAFE_INTEGER,i=0,l=0;for(let t=0;t<v;++t){const r=n+t*S;if(r>=0&&r<f)for(let n=0;n<x;++n){const u=a+n*E;if(u>=0&&u<m){const a=d[e][r][u][s]+h[t][n][s];a>o&&(o=a,i=t,l=n)}}}A[i][l][s]+=T[e][t][r][s]}}}return{dataId:c.write(a.util.toTypedArray(A,r.dtype),s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},zn={kernelName:a.Dilation2DBackpropInput,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:r,filter:s,dy:o}=e,{strides:i,pad:l,dilations:u}=n,c=t,d=a.util.toNestedArray(r.shape,c.data.get(r.dataId).values),h=a.util.toNestedArray(s.shape,c.data.get(s.dataId).values),{batchSize:p,inHeight:f,inWidth:m,inChannels:g,outHeight:b,outWidth:k,padInfo:y,strideHeight:w,strideWidth:I,filterHeight:v,filterWidth:x,dilationHeight:S,dilationWidth:E,outShape:N}=a.backend_util.computeDilation2DInfo(r.shape,s.shape,i,l,"NHWC",u);a.util.assert(o.rank===N.length,(()=>`Error in ${a.Dilation2DBackpropInput}, dy must have the same rank as output ${N.length}, but got ${o.rank}`));const T=a.util.toNestedArray(N,c.data.get(o.dataId).values),A=a.util.makeZerosNestedTypedArray(r.shape,r.dtype);for(let e=0;e<p;++e)for(let t=0;t<b;++t){const n=t*w-y.top;for(let r=0;r<k;++r){const a=r*I-y.left;for(let s=0;s<g;++s){let o=Number.MIN_SAFE_INTEGER,i=n<0?0:n,l=a<0?0:a;for(let t=0;t<v;++t){const r=n+t*S;if(r>=0&&r<f)for(let n=0;n<x;++n){const u=a+n*E;if(u>=0&&u<m){const a=d[e][r][u][s]+h[t][n][s];a>o&&(o=a,i=r,l=u)}}}A[e][i][l][s]+=T[e][t][r][s]}}}return{dataId:c.write(a.util.toTypedArray(A,r.dtype),r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}};function Wn(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{axis:i,keepDims:l}=r;let u;s(o,"sum"),u="bool"===o.dtype?k({inputs:{x:o},backend:n,attrs:{dtype:"int32"}}):f({inputs:{x:o},backend:n});const c=u.shape.length,d=a.util.parseAxisParam(i,u.shape),h=a.backend_util.getAxesPermutation(d,c);let m=d,g=u;null!=h&&(g=Ae({inputs:{x:u},backend:n,attrs:{perm:h}}),m=a.backend_util.getInnerMostAxes(m.length,c)),a.backend_util.assertAxesAreInnerMostDims("sum",m,g.shape.length);const[b,y]=a.backend_util.computeOutAndReduceShapes(g.shape,m);let w=p(n,b,a.backend_util.upcastType(g.dtype,"int32"));const I=a.util.sizeFromShape(y),v=n.data.get(w.dataId).values,x=n.data.get(g.dataId).values;for(let e=0;e<v.length;++e){const t=e*I;let n=0;for(let e=0;e<I;++e)n+=x[t+e];v[e]=n}if(l){const e=w;w=Et({inputs:{x:w},backend:n,attrs:{shape:a.backend_util.expandShapeToKeepDim(w.shape,d)}}),n.disposeIntermediateTensorInfo(e)}return n.disposeIntermediateTensorInfo(u),null!=h&&n.disposeIntermediateTensorInfo(g),w}const On={kernelName:a.Sum,backendName:"cpu",kernelFunc:Wn},Ln={kernelName:a.Einsum,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{equation:s}=r,o=t,{allDims:i,summedDims:l,idDims:u}=a.backend_util.decodeEinsumEquation(s,o.length);a.backend_util.checkEinsumDimSizes(i.length,u,o);const{path:c,steps:d}=a.backend_util.getEinsumComputePath(l,u),h=d.length;let p=null,f=i.length;const m=[];for(let e=0;e<h;++e){for(const t of d[e]){const{permutationIndices:e,expandDims:r}=a.backend_util.getEinsumPermutation(f,u[t]);let s;a.backend_util.isIdentityPermutation(e)?s=o[t]:(s=Ae({inputs:{x:o[t]},backend:n,attrs:{perm:e}}),m.push(s));const i=s.shape.slice();for(let e=0;e<r.length;++e)i.splice(r[e],0,1);a.util.arraysEqual(s.shape,i)||(s=Et({inputs:{x:s},backend:n,attrs:{shape:i}}),m.push(s)),null===p?p=s:(p=we({inputs:{a:s,b:p},backend:n}),m.push(p))}e<h-1&&(c[e]>=0&&(p=Wn({inputs:{x:p},backend:n,attrs:{axis:c[e]-(i.length-f),keepDims:!1}}),m.push(p)),f--)}for(const e of m)e!==p&&n.disposeIntermediateTensorInfo(e);return p}},Hn={kernelName:a.EluGrad,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{dy:r,y:o}=t;s([r,o],"eluGrad");const i=new Float32Array(a.util.sizeFromShape(o.shape)),l=n.data.get(o.dataId).values,u=n.data.get(r.dataId).values;for(let e=0;e<l.length;++e){const t=l[e];i[e]=t>=1?u[e]:u[e]*(t+1)}return n.makeTensorInfo(o.shape,"float32",i)}},Gn=a.backend_util.ERF_P,Kn=a.backend_util.ERF_A1,qn=a.backend_util.ERF_A2,Un=a.backend_util.ERF_A3,Vn=a.backend_util.ERF_A4,jn=a.backend_util.ERF_A5,Zn=M(a.Erf,(e=>{const t=Math.sign(e),n=Math.abs(e),r=1/(1+Gn*n);return t*(1-((((jn*r+Vn)*r+Un)*r+qn)*r+Kn)*r*Math.exp(-n*n))})),Jn={kernelName:a.Erf,backendName:"cpu",kernelFunc:Zn};function Yn(e){const{inputs:t,backend:n,attrs:r}=e,{input:s}=t,{dim:o}=r,i=s.shape.length,l=s.shape.slice();let u=o;return o<0&&(a.util.assert(-(i+1)<=o,(()=>`Axis must be in the interval [${-(i+1)}, ${i}]`)),u=i+o+1),l.splice(u,0,1),Et({inputs:{x:s},backend:n,attrs:{shape:l}})}const Xn={kernelName:a.ExpandDims,backendName:"cpu",kernelFunc:Yn},Qn=c(((e,t)=>e/t)),er=w(a.RealDiv,Qn),tr={kernelName:a.RealDiv,backendName:"cpu",kernelFunc:er};function nr(e,t,n){const r=e.shape,s=r[0],o=r[1],i=n.data.get(e.dataId),l=i.complexTensorInfos.real,u=i.complexTensorInfos.imag,c=[s,o],h=a.util.sizeFromShape(c),p=a.util.getTypedArrayFromDType("float32",h),f=a.util.getTypedArrayFromDType("float32",h);for(let e=0;e<s;e++){const r=Oe({inputs:{x:l},backend:n,attrs:{begin:[e,0],size:[1,o]}}),s=Oe({inputs:{x:u},backend:n,attrs:{begin:[e,0],size:[1,o]}}),i=d({inputs:{real:r,imag:s},backend:n}),{real:c,imag:h}=rr(i,t,n),m=a.backend_util.mergeRealAndImagArrays(c,h);for(let t=0;t<o;t++){const n=a.backend_util.getComplexWithIndex(m,t);p[e*o+t]=n.real,f[e*o+t]=n.imag}n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(i)}const m=n.makeTensorInfo(c,"float32",p),g=n.makeTensorInfo(c,"float32",f),b=d({inputs:{real:m,imag:g},backend:n});return n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(g),b}function rr(e,t,n){const r=a.util.sizeFromShape(e.shape),s=n.data.get(e.dataId),o=n.data.get(s.complexTensorInfos.real.dataId).values,i=n.data.get(s.complexTensorInfos.imag.dataId).values;if(0==((l=r)&l-1)){const s=ar(o,i,r,t,n),l=[e.shape[0],e.shape[1]];if(t){const e=n.makeTensorInfo(l,"float32",s.real),t=n.makeTensorInfo(l,"float32",s.imag),o=n.makeTensorInfo([],"float32",a.util.createScalarValue(r,"float32")),i=f({inputs:{x:o},backend:n}),u=tr.kernelFunc({inputs:{a:e,b:o},backend:n}),c=tr.kernelFunc({inputs:{a:t,b:i},backend:n}),d=n.data.get(u.dataId).values,h=n.data.get(c.dataId).values;return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(c),{real:d,imag:h}}return s}{const e=function(e,t,n){const r=new Float32Array(2*t);for(let s=0;s<t;s++){let o=0,i=0;for(let r=0;r<t;r++){const l=a.backend_util.exponent(s*r,t,n),u=a.backend_util.getComplexWithIndex(e,r);o+=u.real*l.real-u.imag*l.imag,i+=u.real*l.imag+u.imag*l.real}n&&(o/=t,i/=t),a.backend_util.assignToTypedArray(r,o,i,s)}return r}(a.backend_util.mergeRealAndImagArrays(o,i),r,t);return a.backend_util.splitRealAndImagArrays(e)}var l}function ar(e,t,n,r,s){if(1===n)return{real:e,imag:t};const o=a.backend_util.mergeRealAndImagArrays(e,t),i=n/2,l=a.backend_util.complexWithEvenIndex(o),u=l.real,c=l.imag,h=[u.length],p=s.makeTensorInfo(h,"float32",u),f=s.makeTensorInfo(h,"float32",c),m=d({inputs:{real:p,imag:f},backend:s}),b=a.backend_util.complexWithOddIndex(o),k=b.real,y=b.imag,w=[k.length],I=s.makeTensorInfo(w,"float32",k),v=s.makeTensorInfo(w,"float32",y),x=d({inputs:{real:I,imag:v},backend:s}),E=ar(u,c,i,r,s),N=E.real,T=E.imag,A=[N.length],M=s.makeTensorInfo(A,"float32",N),F=s.makeTensorInfo(A,"float32",T),$=d({inputs:{real:M,imag:F},backend:s}),D=ar(k,y,i,r,s),_=D.real,R=D.imag,C=[_.length],B=s.makeTensorInfo(C,"float32",_),P=s.makeTensorInfo(C,"float32",R),z=d({inputs:{real:B,imag:P},backend:s}),W=a.backend_util.exponents(n,r),O=[W.real.length],L=s.makeTensorInfo(O,"float32",W.real),H=s.makeTensorInfo(O,"float32",W.imag),G=d({inputs:{real:L,imag:H},backend:s}),K=we({inputs:{a:G,b:z},backend:s}),q=S({inputs:{a:$,b:K},backend:s}),U=st({inputs:{a:$,b:K},backend:s}),V=g({inputs:{input:q},backend:s}),j=g({inputs:{input:U},backend:s}),Z=dn({inputs:{input:q},backend:s}),J=dn({inputs:{input:U},backend:s}),Y=pn({inputs:[V,j],backend:s,attrs:{axis:0}}),X=pn({inputs:[Z,J],backend:s,attrs:{axis:0}}),Q=s.data.get(Y.dataId).values,ee=s.data.get(X.dataId).values;return s.disposeIntermediateTensorInfo(p),s.disposeIntermediateTensorInfo(f),s.disposeIntermediateTensorInfo(m),s.disposeIntermediateTensorInfo(I),s.disposeIntermediateTensorInfo(v),s.disposeIntermediateTensorInfo(x),s.disposeIntermediateTensorInfo(M),s.disposeIntermediateTensorInfo(F),s.disposeIntermediateTensorInfo($),s.disposeIntermediateTensorInfo(B),s.disposeIntermediateTensorInfo(P),s.disposeIntermediateTensorInfo(z),s.disposeIntermediateTensorInfo(L),s.disposeIntermediateTensorInfo(H),s.disposeIntermediateTensorInfo(G),s.disposeIntermediateTensorInfo(K),s.disposeIntermediateTensorInfo(q),s.disposeIntermediateTensorInfo(U),s.disposeIntermediateTensorInfo(V),s.disposeIntermediateTensorInfo(Z),s.disposeIntermediateTensorInfo(j),s.disposeIntermediateTensorInfo(J),s.disposeIntermediateTensorInfo(Y),s.disposeIntermediateTensorInfo(X),{real:Q,imag:ee}}const sr={kernelName:a.FFT,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{input:r}=t,s=a.util.sizeFromShape(r.shape),o=r.shape[r.shape.length-1],i=Et({inputs:{x:r},backend:n,attrs:{shape:[s/o,o]}}),l=nr(i,!1,n),u=Et({inputs:{x:l},backend:n,attrs:{shape:r.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(l),u}};function or(e){const{backend:t,attrs:n}=e,{shape:r,value:s,dtype:o}=n,i=o||a.util.inferDtype(s),l=a.util.getArrayFromDType(i,a.util.sizeFromShape(r));return function(e,t,n){e.fill(t)}(l,s),t.makeTensorInfo(r,i,l)}const ir={kernelName:a.Fill,backendName:"cpu",kernelFunc:or},lr={kernelName:a.FlipLeftRight,backendName:"cpu",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{image:r}=e,s=n,o=a.util.getTypedArrayFromDType(r.dtype,a.util.sizeFromShape(r.shape)),[i,l,u,c]=r.shape,d=s.data.get(r.dataId).values;for(let e=0;e<i;e++){const t=e*u*l*c;for(let e=0;e<l;e++){const n=e*(u*c);for(let e=0;e<u;e++){const r=e*c;for(let a=0;a<c;a++){const s=Math.round(u-e-1),i=t+n+r+a;let l=d[i];s>=0&&s<u&&(l=d[t+n+s*c+a]),o[i]=l}}}}return{dataId:s.write(o,r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}},ur=c(((e,t)=>Math.floor(e/t))),cr=w(a.FloorDiv,ur,null,"int32"),dr={kernelName:a.FloorDiv,backendName:"cpu",kernelFunc:cr},hr={kernelName:a.FusedConv2D,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s,bias:o,preluActivationWeights:i}=t,{strides:l,pad:u,dataFormat:c,dilations:d,dimRoundingMode:h,activation:p,leakyreluAlpha:f}=r;let m=mn({inputs:{x:a,filter:s},backend:n,attrs:{strides:l,pad:u,dataFormat:c,dilations:d,dimRoundingMode:h}});if(o){const e=m;m=S({inputs:{a:m,b:o},backend:n}),n.disposeIntermediateTensorInfo(e)}if(p){const e=m;m=St(n,m,p,i,f),n.disposeIntermediateTensorInfo(e)}return m}},pr={kernelName:a.FusedDepthwiseConv2D,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s,bias:o,preluActivationWeights:i}=t,{strides:l,pad:u,dataFormat:c,dilations:d,dimRoundingMode:h,activation:p,leakyreluAlpha:f}=r;let m=$n({inputs:{x:a,filter:s},backend:n,attrs:{strides:l,pad:u,dataFormat:c,dilations:d,dimRoundingMode:h}});if(o){const e=m;m=S({inputs:{a:m,b:o},backend:n}),n.disposeIntermediateTensorInfo(e)}if(p){const e=m;m=St(n,m,p,i,f),n.disposeIntermediateTensorInfo(e)}return m}},fr={kernelName:a.GatherNd,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{params:r,indices:s}=t,o=a.util.sizeFromShape(r.shape),i=s.shape,l=i[i.length-1],[u,c,d,h]=a.backend_util.prepareAndValidate(r,s);if(0===c)return n.makeTensorInfo(u,r.dtype,[]);const p=V(n.data.get(s.dataId).values,n.bufferSync(r),r.dtype,c,l,d,h,r.shape,o);return n.makeTensorInfo(u,r.dtype,p.values)}},mr={kernelName:a.GatherV2,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o,indices:i}=t,{axis:l,batchDims:u}=r;s([o,i],"gatherV2");const c=a.util.parseAxisParam(l,o.shape)[0],d=n.data.get(i.dataId).values,h=o.shape[c];for(let e=0;e<d.length;++e){const t=d[e];a.util.assert(t<=h-1&&t>=0,(()=>`GatherV2: the index value ${t} is not in [0, ${h-1}]`))}let p=u;null==u&&(p=0);const f=a.util.sizeFromShape(i.shape),m=a.backend_util.segment_util.collectGatherOpShapeInfo(o,i,c,p),g=Et({inputs:{x:o},backend:n,attrs:{shape:[m.batchSize,m.outerSize,m.dimSize,m.sliceSize]}}),b=Et({inputs:{x:i},backend:n,attrs:{shape:[m.batchSize,f/m.batchSize]}}),k=[m.batchSize,m.outerSize,f/m.batchSize,m.sliceSize],y=n.bufferSync(b),w=j(n.bufferSync(g),y,k);return n.disposeIntermediateTensorInfo(g),n.disposeIntermediateTensorInfo(b),n.makeTensorInfo(m.outputShape,w.dtype,w.values)}},gr={kernelName:a.IFFT,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{input:r}=t,s=a.util.sizeFromShape(r.shape),o=r.shape[r.shape.length-1],i=Et({inputs:{x:r},backend:n,attrs:{shape:[s/o,o]}}),l=nr(i,!0,n),u=Et({inputs:{x:l},backend:n,attrs:{shape:r.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(l),u}},br=M(a.IsFinite,(e=>Number.isFinite(e)?1:0),"bool"),kr={kernelName:a.IsFinite,backendName:"cpu",kernelFunc:br},yr=M(a.IsInf,(e=>Math.abs(e)===1/0?1:0),"bool"),wr={kernelName:a.IsInf,backendName:"cpu",kernelFunc:yr},Ir=M(a.IsNan,(e=>Number.isNaN(e)?1:0),"bool"),vr={kernelName:a.IsNan,backendName:"cpu",kernelFunc:Ir},xr={kernelName:a.LinSpace,backendName:"cpu",kernelFunc:function(e){const{backend:t,attrs:n}=e,{start:r,stop:a,num:s}=n,o=ie(r,a,s);return t.makeTensorInfo([o.length],"float32",o)}},Sr=M(a.Log1p,(e=>Math.log1p(e))),Er={kernelName:a.Log1p,backendName:"cpu",kernelFunc:Sr},Nr=c(((e,t)=>e&&t)),Tr=w(a.LogicalAnd,Nr,null,"bool"),Ar={kernelName:a.LogicalAnd,backendName:"cpu",kernelFunc:Tr},Mr=M(a.LogicalNot,(e=>e?0:1),"bool"),Fr={kernelName:a.LogicalNot,backendName:"cpu",kernelFunc:Mr},$r=c(((e,t)=>e||t)),Dr=w(a.LogicalOr,$r,null,"bool"),_r={kernelName:a.LogicalOr,backendName:"cpu",kernelFunc:Dr},Rr={kernelName:a.LRN,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{depthRadius:i,bias:l,alpha:u,beta:c}=r;s(o,"LRN");const d=o.shape[3],h=d-1,p=n.data.get(o.dataId).values,f=a.util.sizeFromShape(o.shape),m=new Float32Array(f);function g(e){const t=e%d;let n=e-t+Math.max(0,t-i);const r=e-t+Math.min(t+i,h);let a=0;for(;n<=r;n++){const e=p[n];a+=e*e}return a}for(let e=0;e<f;e++){const t=g(e),n=p[e]*Math.pow(l+u*t,-c);m[e]=n}return n.makeTensorInfo(o.shape,o.dtype,m)}},Cr={kernelName:a.LRNGrad,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o,y:i,dy:l}=t,{depthRadius:u,bias:c,alpha:d,beta:h}=r;s(l,"LRNGrad");const p=a.util.sizeFromShape(l.shape),f=l.shape[3],m=n.data.get(l.dataId).values,g=n.data.get(o.dataId).values,b=n.data.get(i.dataId).values,k=new Float32Array(p),y=p;for(let e=0;e<y;e++){const t=e%f,n=e-t+Math.max(0,t-u),r=e-t+Math.min(f,t+u+1);let a=0;for(let e=n;e<r;e++)a+=Math.pow(g[e],2);a=d*a+c;for(let t=n;t<r;t++){let n=-2*d*h*g[t]*b[e]/a;e===t&&(n+=Math.pow(a,-h)),n*=m[e],k[t]+=n}}return n.makeTensorInfo(l.shape,o.dtype,k)}};function Br(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{reductionIndices:i,keepDims:l}=r,u=n;let c=o.shape;const d=c.length,h=a.util.parseAxisParam(i,c);let p=h;const f=a.backend_util.getAxesPermutation(p,d);let m=u.data.get(o.dataId).values;if(null!=f){const e=new Array(d);for(let t=0;t<e.length;t++)e[t]=c[f[t]];m=Te(m,c,o.dtype,f,e),p=a.backend_util.getInnerMostAxes(p.length,d),c=e}s(o,"max"),a.backend_util.assertAxesAreInnerMostDims("max",p,d);const[g,b]=a.backend_util.computeOutAndReduceShapes(c,p),k=de(m,a.util.sizeFromShape(b),g,o.dtype),y=u.write(k,g,o.dtype);let w=g;return l&&(w=a.backend_util.expandShapeToKeepDim(g,h)),{dataId:y,shape:w,dtype:o.dtype}}const Pr={kernelName:a.Max,backendName:"cpu",kernelFunc:Br},zr={kernelName:a.MaxPool,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t;s(o,"maxPool");const{filterSize:i,strides:l,pad:u,dimRoundingMode:c}=r;a.util.assert(a.backend_util.eitherStridesOrDilationsAreOne(l,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${l} and dilations '1'`));const d=a.backend_util.computePool2DInfo(o.shape,i,l,1,u,c);let h;if(1===d.filterWidth&&1===d.filterHeight&&a.util.arraysEqual(d.inShape,d.outShape))h=f({inputs:{x:o},backend:n});else{const e=n.data.get(o.dataId).values,t=a.util.computeStrides(o.shape),r=Jt(e,o.shape,o.dtype,t,d,"max");h=n.makeTensorInfo(d.outShape,o.dtype,r.values)}return h}},Wr={kernelName:a.MaxPool3D,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{filterSize:i,strides:l,pad:u,dimRoundingMode:c,dataFormat:d}=r;s(o,"maxPool3d");const h=a.backend_util.computePool3DInfo(o.shape,i,l,1,u,c,d),p=Xt(n.data.get(o.dataId).values,o.shape,o.dtype,a.util.computeStrides(o.shape),h,"max");return n.makeTensorInfo(p.shape,"float32",p.values)}},Or={kernelName:a.MaxPool3DGrad,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{dy:o,input:i}=t,{filterSize:l,strides:u,pad:c,dimRoundingMode:d}=r;s([o,i],"maxPool3DGrad");const h=a.backend_util.computePool3DInfo(i.shape,l,u,1,c,d),p=function(e,t){const n=(0,a.buffer)(t.outShape,"int32"),r=t.strideDepth,s=t.strideHeight,o=t.strideWidth,i=t.dilationDepth,l=t.dilationHeight,u=t.dilationWidth,c=t.effectiveFilterDepth,d=t.effectiveFilterHeight,h=t.effectiveFilterWidth,p=t.padInfo.front,f=t.padInfo.top,m=t.padInfo.left;for(let a=0;a<t.batchSize;++a)for(let g=0;g<t.inChannels;++g)for(let b=0;b<t.outDepth;++b){const k=b*r-p;let y=k;for(;y<0;)y+=i;const w=Math.min(t.inDepth,c+k);for(let r=0;r<t.outHeight;++r){const c=r*s-f;let p=c;for(;p<0;)p+=l;const I=Math.min(t.inHeight,d+c);for(let s=0;s<t.outWidth;++s){const f=s*o-m;let v=f;for(;v<0;)v+=u;const x=Math.min(t.inWidth,h+f);let S=Number.NEGATIVE_INFINITY,E=-1;for(let t=y;t<w;t+=i){const n=t-k;for(let r=p;r<I;r+=l){const s=r-c;for(let o=v;o<x;o+=u){const i=o-f,l=e.get(a,t,r,o,g);l>=S&&(S=l,E=n*d*h+s*d+i)}}}n.set(E,a,b,r,s,g)}}}return n}(n.bufferSync(i),h),f=h.strideDepth,m=h.strideHeight,g=h.strideWidth,b=h.dilationDepth,k=h.dilationHeight,y=h.dilationWidth,w=h.effectiveFilterDepth,I=h.effectiveFilterHeight,v=h.effectiveFilterWidth,x=w-1-h.padInfo.front,S=v-1-h.padInfo.left,E=I-1-h.padInfo.top,N=(0,a.buffer)(i.shape,"float32"),T=n.bufferSync(o);for(let e=0;e<h.batchSize;++e)for(let t=0;t<h.inChannels;++t)for(let n=0;n<h.inDepth;++n)for(let r=0;r<h.inHeight;++r)for(let a=0;a<h.inWidth;++a){const s=n-x,o=r-E,i=a-S;let l=0;for(let n=0;n<w;n+=b){const r=(s+n)/f;if(!(r<0||r>=h.outDepth||Math.floor(r)!==r))for(let a=0;a<I;a+=k){const s=(o+a)/m;if(!(s<0||s>=h.outHeight||Math.floor(s)!==s))for(let o=0;o<v;o+=y){const u=(i+o)/g;if(u<0||u>=h.outWidth||Math.floor(u)!==u)continue;const c=w*I*v-1-p.get(e,r,s,u,t)===n*I*v+a*v+o?1:0;0!==c&&(l+=T.get(e,r,s,u,t)*c)}}}N.set(l,e,n,r,a,t)}return n.makeTensorInfo(N.shape,N.dtype,N.values)}},Lr={kernelName:a.MaxPoolGrad,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{dy:o,input:i,output:l}=t,u=i;s([i,l],"maxPoolGrad");const{filterSize:c,strides:d,pad:h,dimRoundingMode:p}=r,f=a.backend_util.computePool2DInfo(u.shape,c,d,1,h,p),m=n.data.get(u.dataId).values,g=(0,a.buffer)(f.outShape,u.dtype,Yt(m,u.shape,u.dtype,f).values),b=f.strideHeight,k=f.strideWidth,y=f.dilationHeight,w=f.dilationWidth,I=f.effectiveFilterHeight,v=f.effectiveFilterWidth,x=v-1-f.padInfo.left,S=I-1-f.padInfo.top,E=(0,a.buffer)(u.shape,"float32"),N=n.data.get(o.dataId).values,T=(0,a.buffer)(o.shape,"float32",N);for(let e=0;e<f.batchSize;++e)for(let t=0;t<f.inChannels;++t)for(let n=0;n<f.inHeight;++n)for(let r=0;r<f.inWidth;++r){const a=n-S,s=r-x;let o=0;for(let n=0;n<I;n+=y){const r=(a+n)/b;if(!(r<0||r>=f.outHeight||Math.floor(r)!==r))for(let a=0;a<v;a+=w){const i=(s+a)/k;if(i<0||i>=f.outWidth||Math.floor(i)!==i)continue;const l=I*v-1-g.get(e,r,i,t)===n*v+a?1:0;0!==l&&(o+=T.get(e,r,i,t)*l)}}E.set(o,e,n,r,t)}return n.makeTensorInfo(E.shape,E.dtype,E.values)}},Hr={kernelName:a.MaxPoolWithArgmax,backendName:"cpu",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{x:r}=e,{filterSize:o,strides:i,pad:l,includeBatchInIndex:u}=t,c=n;s(r,"MaxPoolWithArgmax");const d=c.data.get(r.dataId).values,h=a.backend_util.computePool2DInfo(r.shape,o,i,[1,1],l),[p,f]=function(e,t,n,r,s){const o=Jt(e,0,n,a.util.computeStrides(t),s,"max"),i=Yt(e,t,n,s,!0,r);return[o.values,i.values]}(d,r.shape,r.dtype,u,h),m=c.write(p,h.outShape,r.dtype),g=c.write(f,h.outShape,r.dtype);return[{dataId:m,shape:h.outShape,dtype:r.dtype},{dataId:g,shape:h.outShape,dtype:"int32"}]}},Gr={kernelName:a.Mean,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:s}=t,{axis:o,keepDims:i}=r,l=a.util.parseAxisParam(o,s.shape),u=a.backend_util.computeOutAndReduceShapes(s.shape,l)[1],c=a.util.sizeFromShape(u),d=[],h=n.makeTensorInfo([],"float32",new Float32Array([c]));d.push(h);const p=k({inputs:{x:s},backend:n,attrs:{dtype:"float32"}});d.push(p);const f=er({inputs:{a:p,b:h},backend:n});d.push(f);const m=Wn({inputs:{x:f},backend:n,attrs:{axis:o,keepDims:i}});return d.forEach((e=>n.disposeIntermediateTensorInfo(e))),m}},Kr={kernelName:a.Min,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{axis:i,keepDims:l}=r;s(o,"min");const u=a.util.parseAxisParam(i,o.shape);let c=u;const d=a.backend_util.getAxesPermutation(c,o.shape.length);let h=o;null!=d&&(h=Ae({inputs:{x:o},backend:n,attrs:{perm:d}}),c=a.backend_util.getInnerMostAxes(c.length,o.shape.length)),a.backend_util.assertAxesAreInnerMostDims("min",c,h.shape.length);const[p,f]=a.backend_util.computeOutAndReduceShapes(h.shape,c),m=a.util.sizeFromShape(f),g=a.util.makeZerosTypedArray(a.util.sizeFromShape(p),h.dtype),b=n.data.get(h.dataId).values;for(let e=0;e<g.length;++e){const t=e*m;let n=b[t];for(let e=0;e<m;++e){const r=b[t+e];(Number.isNaN(r)||r<n)&&(n=r)}g[e]=n}null!=d&&n.disposeIntermediateTensorInfo(h);const k=n.makeTensorInfo(p,h.dtype,g);if(l){const e=Et({inputs:{x:k},backend:n,attrs:{shape:a.backend_util.expandShapeToKeepDim(p,u)}});return n.disposeIntermediateTensorInfo(k),e}return k}},qr={kernelName:a.MirrorPad,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{paddings:i,mode:l}=r;s(o,"mirrorPad");const u=i.map(((e,t)=>e[0]+o.shape[t]+e[1])),c=i.map((e=>e[0])),d=i.map(((e,t)=>e[0]+o.shape[t])),h="reflect"===l?0:1,p=n.data.get(o.dataId).values,f=o.shape.length,m=a.util.computeStrides(o.shape),g=a.util.sizeFromShape(u),b=u.length,k=a.util.computeStrides(u),y=a.util.getTypedArrayFromDType(o.dtype,g);for(let e=0;e<g;e++){let t=a.util.indexToLoc(e,b,k);for(let e=0;e<b;e++)t[e]<c[e]?t[e]=2*c[e]-t[e]-h:t[e]>=d[e]&&(t[e]=2*(d[e]-1)-t[e]+h);t=t.map(((e,t)=>e-c[t]));const n=a.util.locToIndex(t,f,m);y[e]=p[n]}return{dataId:n.write(y,u,o.dtype),shape:u,dtype:o.dtype}}},Ur=c(((e,t)=>{const n=e%t;return e<0&&t<0||e>=0&&t>=0?n:(n+t)%t})),Vr=w(a.Mod,Ur),jr={kernelName:a.Mod,backendName:"cpu",kernelFunc:Vr};var Zr=n(6377);function Jr(e){const{inputs:t,backend:n,attrs:r}=e,{logits:s}=t,{dim:o}=r,i=s.shape.length;let l=o;if(-1===l&&(l=i-1),l!==i-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${i} and dim was ${l}`);const u=a.util.parseAxisParam([l],s.shape),c=Br({inputs:{x:s},backend:n,attrs:{reductionIndices:u,keepDims:!1}}),d=a.backend_util.expandShapeToKeepDim(c.shape,u),h=Et({inputs:{x:c},backend:n,attrs:{shape:d}}),p=st({inputs:{a:s,b:h},backend:n}),f=W({inputs:{x:p},backend:n}),m=Wn({inputs:{x:f},backend:n,attrs:{axis:u,keepDims:!1}}),g=Et({inputs:{x:m},backend:n,attrs:{shape:d}}),b=er({inputs:{a:f,b:g},backend:n});return n.disposeIntermediateTensorInfo(c),n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(g),b}const Yr={kernelName:a.Softmax,backendName:"cpu",kernelFunc:Jr},Xr={kernelName:a.Multinomial,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{logits:o}=t,{numSamples:i,seed:l,normalized:u}=r;s(o,"multinomial");const c=u?o:Jr({inputs:{logits:o},backend:n,attrs:{dim:-1}}),d=c.shape[0],h=c.shape[1],p=n.data.get(c.dataId).values,f=[d,i],m=a.util.makeZerosTypedArray(a.util.sizeFromShape(f),"int32");for(let e=0;e<d;++e){const t=e*h,n=new Float32Array(h-1);n[0]=p[t];for(let e=1;e<n.length;++e)n[e]=n[e-1]+p[t+e];const r=Zr.alea(l.toString()),a=e*i;for(let e=0;e<i;++e){const t=r();m[a+e]=n.length;for(let r=0;r<n.length;r++)if(t<n[r]){m[a+e]=r;break}}}return u||n.disposeIntermediateTensorInfo(c),n.makeTensorInfo(f,"int32",m)}},Qr=a.kernel_impls.nonMaxSuppressionV3Impl,ea={kernelName:a.NonMaxSuppressionV3,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:o}=t,{maxOutputSize:i,iouThreshold:l,scoreThreshold:u}=r;s(a,"NonMaxSuppression");const c=n.data.get(a.dataId).values,d=n.data.get(o.dataId).values,{selectedIndices:h}=Qr(c,d,i,l,u);return n.makeTensorInfo([h.length],"int32",new Int32Array(h))}},ta=a.kernel_impls.nonMaxSuppressionV4Impl,na={kernelName:a.NonMaxSuppressionV4,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:o}=t,{maxOutputSize:i,iouThreshold:l,scoreThreshold:u,padToMaxOutputSize:c}=r;s(a,"NonMaxSuppressionPadded");const d=n.data.get(a.dataId).values,h=n.data.get(o.dataId).values,{selectedIndices:p,validOutputs:f}=ta(d,h,i,l,u,c);return[n.makeTensorInfo([p.length],"int32",new Int32Array(p)),n.makeTensorInfo([],"int32",new Int32Array([f]))]}},ra=a.kernel_impls.nonMaxSuppressionV5Impl,aa={kernelName:a.NonMaxSuppressionV5,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:o}=t,{maxOutputSize:i,iouThreshold:l,scoreThreshold:u,softNmsSigma:c}=r;s(a,"NonMaxSuppressionWithScore");const d=n.data.get(a.dataId).values,h=n.data.get(o.dataId).values,p=i,f=l,m=u,g=c,{selectedIndices:b,selectedScores:k}=ra(d,h,p,f,m,g);return[n.makeTensorInfo([b.length],"int32",new Int32Array(b)),n.makeTensorInfo([k.length],"float32",new Float32Array(k))]}},sa={kernelName:a.OneHot,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{indices:o}=t,{depth:i,onValue:l,offValue:u}=r;s(o,"oneHot");const c=a.util.sizeFromShape(o.shape),d=new Float32Array(c*i);d.fill(u);const h=n.data.get(o.dataId).values;for(let e=0;e<c;++e)h[e]>=0&&h[e]<i&&(d[e*i+h[e]]=l);return n.makeTensorInfo([...o.shape,i],"int32",d)}};function oa(e){const{inputs:t,backend:n}=e,{x:r}=t;if("string"===r.dtype)throw new Error("zerosLike is not supported for string tensors");if("complex64"===r.dtype){const e=g({inputs:{input:r},backend:n}),t=oa({inputs:{x:e},backend:n}),a=dn({inputs:{input:r},backend:n}),s=oa({inputs:{x:a},backend:n}),o=d({inputs:{real:t,imag:s},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}return or({backend:n,attrs:{shape:r.shape,value:0,dtype:r.dtype}})}const ia={kernelName:a.ZerosLike,backendName:"cpu",kernelFunc:oa},la={kernelName:a.OnesLike,backendName:"cpu",kernelFunc:function e(t){const{inputs:n,backend:r}=t,{x:a}=n;if("string"===a.dtype)throw new Error("onesLike is not supported for string tensors");if("complex64"===a.dtype){const t=g({inputs:{input:a},backend:r}),n=e({inputs:{x:t},backend:r}),s=dn({inputs:{input:a},backend:r}),o=oa({inputs:{x:s},backend:r}),i=d({inputs:{real:n,imag:o},backend:r});return r.disposeIntermediateTensorInfo(t),r.disposeIntermediateTensorInfo(n),r.disposeIntermediateTensorInfo(s),r.disposeIntermediateTensorInfo(o),i}return or({backend:r,attrs:{shape:a.shape,value:1,dtype:a.dtype}})}};function ua(e){const{inputs:t,backend:n,attrs:r}=e,{axis:s}=r;if(1===t.length)return Yn({inputs:{input:t[0]},backend:n,attrs:{dim:s}});const o=t[0].shape,i=t[0].dtype;t.forEach((e=>{a.util.assertShapesMatch(o,e.shape,"All tensors passed to stack must have matching shapes"),a.util.assert(i===e.dtype,(()=>"All tensors passed to stack must have matching dtypes"))}));const l=[],u=pn({inputs:t.map((e=>{const t=Yn({inputs:{input:e},backend:n,attrs:{dim:s}});return l.push(t),t})),backend:n,attrs:{axis:s}});return l.forEach((e=>n.disposeIntermediateTensorInfo(e))),u}const ca={kernelName:a.Pack,backendName:"cpu",kernelFunc:ua},da={kernelName:a.PadV2,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{paddings:i,constantValue:l}=r;s(o,"pad");const u=i.map(((e,t)=>e[0]+o.shape[t]+e[1])),c=i.map((e=>e[0])),d=n.data.get(o.dataId).values,h=a.util.sizeFromShape(o.shape),p=o.shape.length,f=a.util.computeStrides(o.shape),m=a.util.sizeFromShape(u),g=u.length,b=a.util.computeStrides(u),k=a.util.getTypedArrayFromDType(o.dtype,m);0!==l&&k.fill(l);for(let e=0;e<h;e++){const t=a.util.indexToLoc(e,p,f).map(((e,t)=>e+c[t]));k[a.util.locToIndex(t,g,b)]=d[e]}return{dataId:n.write(k,u,o.dtype),shape:u,dtype:o.dtype}}},ha=c(((e,t)=>Math.pow(e,t))),pa=w(a.Pow,ha),fa={kernelName:a.Pow,backendName:"cpu",kernelFunc:pa},ma={kernelName:a.Range,backendName:"cpu",kernelFunc:function(e){const{backend:t,attrs:n}=e,{start:r,stop:a,dtype:s,step:o}=n,i=De(r,a,o,s);return t.makeTensorInfo([i.length],s,i)}},ga=M(a.Reciprocal,(e=>1/e)),ba={kernelName:a.Reciprocal,backendName:"cpu",kernelFunc:ga},ka={kernelName:a.ResizeBilinear,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{images:o}=t,{alignCorners:i,halfPixelCenters:l,size:u}=r;s(o,"resizeBilinear");const c=a.util.computeStrides(o.shape),[d,h]=u,[p,f,m,g]=o.shape,b=n.data.get(o.dataId).values,k=new Float32Array(a.util.sizeFromShape([p,d,h,g])),y=[i&&d>1?f-1:f,i&&h>1?m-1:m],w=[i&&d>1?d-1:d,i&&h>1?h-1:h];let I=0;const v=y[0]/w[0],x=y[1]/w[1];for(let e=0;e<p;e++)for(let t=0;t<d;t++){let n;n=l?v*(t+.5)-.5:v*t;const r=Math.max(0,Math.floor(n)),a=n-r,s=Math.min(f-1,Math.ceil(n)),o=e*c[0]+r*c[1],i=e*c[0]+s*c[1];for(let e=0;e<h;e++){let t;t=l?x*(e+.5)-.5:x*e;const n=Math.max(0,Math.floor(t)),r=t-n,s=Math.min(m-1,Math.ceil(t)),u=o+n*c[2],d=i+n*c[2],h=o+s*c[2],p=i+s*c[2];for(let e=0;e<g;e++){const t=b[u+e],n=b[d+e],s=t+(b[h+e]-t)*r,o=s+(n+(b[p+e]-n)*r-s)*a;k[I++]=o}}}return n.makeTensorInfo([p,d,h,g],"float32",k)}},ya={kernelName:a.ResizeBilinearGrad,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{images:o,dy:i}=t,{alignCorners:l}=r;s([i,o],"resizeBilinearGrad");const u=a.util.computeStrides(o.shape),[c,d,h,p]=o.shape,[,f,m]=i.shape,g=new Float32Array(c*d*h*p),b=[l&&f>1?d-1:d,l&&m>1?h-1:h],k=[l&&f>1?f-1:f,l&&m>1?m-1:m],y=b[0]/k[0],w=b[1]/k[1],I=n.data.get(i.dataId).values;let v=0;for(let e=0;e<c;e++){const t=e*u[0];for(let e=0;e<f;e++){const n=e*y,r=Math.floor(n),a=Math.min(Math.ceil(n),d-1),s=t+r*u[1],o=t+a*u[1],i=n-r,l=1-i;for(let e=0;e<m;e++){const t=e*w,n=Math.floor(t),r=Math.min(Math.ceil(t),h-1),a=t-n,c=1-a,d=s+n*u[2],f=s+r*u[2],m=o+n*u[2],b=o+r*u[2],k=l*c,y=l*a,x=i*c,S=i*a;for(let e=0;e<p;e++){const t=I[v++];g[d+e]+=t*k,g[f+e]+=t*y,g[m+e]+=t*x,g[b+e]+=t*S}}}}return n.makeTensorInfo([c,h,d,p],"float32",g)}},wa={kernelName:a.ResizeNearestNeighbor,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{images:o}=t,{alignCorners:i,halfPixelCenters:l,size:u}=r;s(o,"resizeNearestNeighbor");const c=a.util.computeStrides(o.shape),[d,h]=u,[p,f,m,g]=o.shape,b=n.data.get(o.dataId).values,k=new Float32Array(p*d*h*g),y=[i&&d>1?f-1:f,i&&h>1?m-1:m],w=[i&&d>1?d-1:d,i&&h>1?h-1:h],I=y[0]/w[0],v=y[1]/w[1];let x=0;for(let e=0;e<p;e++){const t=e*c[0];for(let e=0;e<d;e++){const n=l?I*(e+.5):I*e;let r=Math.min(f-1,i?Math.round(n):Math.floor(n));l&&(r=Math.max(0,r));const a=t+r*c[1];for(let e=0;e<h;e++){const t=l?v*(e+.5):v*e;let n=Math.min(m-1,i?Math.round(t):Math.floor(t));l&&(n=Math.max(0,n));const r=a+n*c[2];for(let e=0;e<g;e++){const t=b[r+e];k[x++]=t}}}}return n.makeTensorInfo([p,d,h,g],o.dtype,k)}},Ia={kernelName:a.ResizeNearestNeighborGrad,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{images:o,dy:i}=t,{alignCorners:l}=r;s([i,o],"resizeNearestNeighborGrad");const u=a.util.computeStrides(o.shape),c=a.util.computeStrides(i.shape),[d,h,p,f]=o.shape,[,m,g]=i.shape,b=new Float32Array(d*h*p*f),k=n.data.get(i.dataId).values,y=[l&&m>1?h-1:h,l&&g>1?p-1:p],w=[l&&m>1?m-1:m,l&&g>1?g-1:g],I=y[0]/w[0],v=y[1]/w[1],x=1/I,S=1/v,E=2*Math.ceil(x)+2,N=2*Math.ceil(S)+2;for(let e=0;e<d;e++){const t=e*u[0];for(let e=0;e<h;e++){const n=t+e*u[1],r=Math.floor(e*x),a=Math.floor(r-E/2);for(let r=0;r<p;r++){const s=n+r*u[2],o=Math.floor(r*S),i=Math.floor(o-N/2);for(let n=0;n<f;n++){let o=0;for(let s=0;s<E;s++){const u=s+a;if(u<0||u>=m)continue;const d=t+u*c[1],f=u*I;if(e===Math.min(h-1,l?Math.round(f):Math.floor(f)))for(let e=0;e<N;e++){const t=e+i;if(t<0||t>=g)continue;const a=d+t*c[2],s=t*v;r===Math.min(p-1,l?Math.round(s):Math.floor(s))&&(o+=k[a+n])}}b[s+n]=o}}}}return n.makeTensorInfo(o.shape,o.dtype,b)}},va={kernelName:a.Reverse,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{dims:i}=r;s(o,"reverse");const l=o.shape.length,u=a.util.parseAxisParam(i,o.shape);if(0===l)return f({inputs:{x:o},backend:n});const c=new a.TensorBuffer(o.shape,o.dtype),d=n.bufferSync(o);for(let e=0;e<c.size;e++){const t=c.indexToLoc(e),n=t.slice();u.forEach((e=>n[e]=o.shape[e]-1-n[e])),c.set(d.get(...n),...t)}return n.makeTensorInfo(c.shape,c.dtype,c.values)}},xa={kernelName:a.RotateWithOffset,backendName:"cpu",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{image:r}=e,{radians:s,fillValue:o,center:i}=t,l=n,u=a.util.getTypedArrayFromDType(r.dtype,a.util.sizeFromShape(r.shape)),[c,d,h,p]=r.shape,[f,m]=a.backend_util.getImageCenter(i,d,h),g=Math.sin(s),b=Math.cos(s),k=l.data.get(r.dataId).values;for(let e=0;e<c;e++){const t=e*h*d*p;for(let e=0;e<d;e++){const n=e*(h*p);for(let r=0;r<h;r++){const a=r*p;for(let s=0;s<p;s++){const i=[c,e,r,s],l=i[2],y=i[1];let w=(l-f)*b-(y-m)*g,I=(l-f)*g+(y-m)*b;w=Math.round(w+f),I=Math.round(I+m);let v=o;"number"!=typeof o&&(v=3===s?255:o[s]),w>=0&&w<h&&I>=0&&I<d&&(v=k[t+I*(h*p)+w*p+s]),u[t+n+a+s]=v}}}}return{dataId:l.write(u,r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}},Sa=M(a.Round,(e=>{const t=Math.floor(e);return e-t<.5?Math.floor(e):e-t>.5?Math.ceil(e):t%2==0?t:t+1})),Ea={kernelName:a.Round,backendName:"cpu",kernelFunc:Sa};function Na(e,t,n,r,s,o,i,l,u,c){const d=[r/s,s],h=e.values,p=t.values;if(0===r)return(0,a.buffer)(n,t.dtype);const f=(0,a.buffer)(d,t.dtype);f.values.fill(u);for(let e=0;e<o;e++){const a=[];let o=0;for(let t=0;t<i;t++){const n=h[e*i+t];a.push(n),o+=n*l[t]}if(o<0||o>=r/s)throw new Error(`Invalid indices: ${a} does not index into ${n}`);for(let n=0;n<s;n++)c?f.values[o*s+n]+=p[e*s+n]:f.values[o*s+n]=0===t.rank?p[0]:p[e*s+n]}return f}const Ta={kernelName:a.ScatterNd,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{indices:s,updates:o}=t,{shape:i}=r,{sliceRank:l,numUpdates:u,sliceSize:c,strides:d,outputSize:h}=a.backend_util.calculateShapes(o,s,i),p=Na(n.bufferSync(s),n.bufferSync(o),i,h,c,u,l,d,0,!0);return n.makeTensorInfo(i,p.dtype,p.values)}},Aa={kernelName:a.Select,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{condition:r,t:o,e:i}=t;s([r,o,i],"select");const l=r.shape.length,u=n.data.get(r.dataId).values,c=n.data.get(o.dataId).values,d=n.data.get(i.dataId).values,h=(0,a.upcastType)(o.dtype,i.dtype),p=a.util.makeZerosTypedArray(a.util.sizeFromShape(o.shape),h);let f=0;const m=0===l||l>1||1===o.shape.length?1:a.util.sizeFromShape(o.shape.slice(1));for(let e=0;e<u.length;e++)for(let t=0;t<m;t++)1===u[e]?p[f++]=c[e]:p[f++]=d[e];return n.makeTensorInfo(o.shape,h,p)}},Ma=a.backend_util.SELU_SCALEALPHA,Fa=a.backend_util.SELU_SCALE,$a=M(a.Selu,(e=>e>=0?Fa*e:Ma*(Math.exp(e)-1))),Da={kernelName:a.Selu,backendName:"cpu",kernelFunc:$a},_a=M(a.Sign,(e=>e<0?-1:e>0?1:0)),Ra={kernelName:a.Sign,backendName:"cpu",kernelFunc:_a},Ca=M(a.Sin,(e=>Math.sin(e))),Ba={kernelName:a.Sin,backendName:"cpu",kernelFunc:Ca},Pa=M(a.Sinh,(e=>Math.sinh(e))),za={kernelName:a.Sinh,backendName:"cpu",kernelFunc:Pa},Wa=Math.log(1.1920928955078125e-7)+2,Oa=M(a.Softplus,(e=>{const t=e>-Wa,n=e<Wa,r=Math.exp(e);let a;return a=n?r:t?e:Math.log(1+r),a})),La={kernelName:a.Softplus,backendName:"cpu",kernelFunc:Oa},Ha={kernelName:a.SpaceToBatchND,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{blockShape:i,paddings:l}=r;s([o],"spaceToBatchND");const u=a.util.sizeFromShape(i),c=[[0,0]];c.push(...l);for(let e=1+i.length;e<o.shape.length;++e)c.push([0,0]);const d=da.kernelFunc({inputs:{x:o},backend:n,attrs:{paddings:c,constantValue:0}}),h=a.backend_util.getReshaped(d.shape,i,u,!1),p=a.backend_util.getPermuted(h.length,i.length,!1),f=a.backend_util.getReshapedPermuted(d.shape,i,u,!1),m=Et({inputs:{x:d},backend:n,attrs:{shape:h}}),g=Ae({inputs:{x:m},backend:n,attrs:{perm:p}}),b=Et({inputs:{x:g},backend:n,attrs:{shape:f}});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(g),b}},Ga={kernelName:a.SparseFillEmptyRows,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{indices:r,values:a,denseShape:s,defaultValue:o}=t;if(1!==s.shape.length)throw new Error(`Dense shape must be a vector, saw:\n        ${s.shape}`);if(2!==r.shape.length)throw new Error(`Indices must be a matrix, saw:\n        ${r.shape}`);if(1!==a.shape.length)throw new Error(`Values must be a vector, saw:\n        ${a.shape}`);if(0!==o.shape.length)throw new Error(`Default value must be a scalar, saw:\n        ${o.shape}`);const i=n.data.get(r.dataId).values,l=n.data.get(a.dataId).values,u=n.data.get(s.dataId).values,c=n.data.get(o.dataId).values[0],[d,h,p,f,m]=He(i,r.shape,r.dtype,l,a.dtype,u,c);return[n.makeTensorInfo(h,r.dtype,d),n.makeTensorInfo([h[0]],a.dtype,p),n.makeTensorInfo([f.length],"bool",new Uint8Array(f.map((e=>Number(e))))),n.makeTensorInfo([m.length],r.dtype,new Int32Array(m))]}},Ka={kernelName:a.SparseReshape,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{inputIndices:r,inputShape:a,newShape:s}=t;if(2!==r.shape.length)throw new Error(`Input indices should be a matrix but received shape\n        ${r.shape}`);if(1!==a.shape.length)throw new Error(`Input shape should be a vector but received shape\n        ${a.shape}`);if(1!==s.shape.length)throw new Error(`Target shape should be a vector but received shape ${s.shape}`);const o=Array.from(n.data.get(a.dataId).values),i=n.data.get(r.dataId).values,l=Array.from(n.data.get(s.dataId).values),[u,c,d]=Ge(i,r.shape,r.dtype,o,l);return[n.makeTensorInfo(c,r.dtype,u),n.makeTensorInfo([d.length],s.dtype,new Int32Array(d))]}},qa={kernelName:a.SparseSegmentMean,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{data:r,indices:a,segmentIds:s}=t;if(r.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.shape.length)throw new Error(`Indices should be a vector but received shape\n          ${a.shape}`);if(1!==s.shape.length)throw new Error(`Segment ids should be a vector but received shape\n          ${s.shape}`);if(a.shape[0]!==s.shape[0])throw new Error("segmentIds and indices should have same size.");const o=n.data.get(r.dataId).values,i=n.data.get(a.dataId).values,l=n.data.get(s.dataId).values,[u,c]=Ke(o,r.shape,r.dtype,i,l,!0);return n.makeTensorInfo(c,r.dtype,u)}},Ua={kernelName:a.SparseSegmentSum,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{data:r,indices:a,segmentIds:s}=t;if(r.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.shape.length)throw new Error(`Indices should be a vector but received shape\n         ${a.shape}`);if(1!==s.shape.length)throw new Error(`Segment ids should be a vector but received shape\n         ${s.shape}`);if(a.shape[0]!==s.shape[0])throw new Error("segmentIds and indices should have same size.");const o=n.data.get(r.dataId).values,i=n.data.get(a.dataId).values,l=n.data.get(s.dataId).values,[u,c]=Ke(o,r.shape,r.dtype,i,l);return n.makeTensorInfo(c,r.dtype,u)}},Va={kernelName:a.SparseToDense,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{sparseIndices:s,sparseValues:o,defaultValue:i}=t,{outputShape:l}=r,{sliceRank:u,numUpdates:c,sliceSize:d,strides:h,outputSize:p}=a.backend_util.calculateShapes(o,s,l),f=Na(n.bufferSync(s),n.bufferSync(o),l,p,d,c,u,h,n.data.get(i.dataId).values[0],!1);return n.makeTensorInfo(l,f.dtype,f.values)}},ja={kernelName:a.SplitV,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:s}=t,{numOrSizeSplits:o,axis:i}=r,l=a.util.parseAxisParam(i,s.shape)[0],u=a.backend_util.prepareSplitSize(s,o,l),c=new Array(s.shape.length).fill(0),d=s.shape.slice();return u.map((e=>{const t=[...d];t[l]=e;const r=Oe({inputs:{x:s},backend:n,attrs:{begin:c,size:t}});return c[l]+=e,r}))}},Za={kernelName:a.Square,backendName:"cpu",kernelFunc:({inputs:e,backend:t})=>{const{x:n}=e,r=t;s(n,"square");const a=r.data.get(n.dataId).values,o=new Float32Array(a.length);for(let e=0;e<a.length;++e){const t=a[e];o[e]=t*t}return{dataId:r.write(o,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}},Ja=M(a.Step,((e,t)=>{const n=t;return isNaN(e)?NaN:e>0?1:n.alpha})),Ya={kernelName:a.Step,backendName:"cpu",kernelFunc:Ja},Xa={kernelName:a.StridedSlice,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o}=t,{begin:i,end:l,strides:u,beginMask:c,endMask:d,ellipsisMask:h,newAxisMask:p,shrinkAxisMask:f}=r;s(o,"stridedSlice");const{finalShapeSparse:m,finalShape:g,isIdentity:b,sliceDim0:k,isSimpleSlice:y,begin:w,end:I,strides:v}=a.slice_util.sliceInfo(o.shape,i,l,u,c,d,h,p,f);let x;if(b)x=Et({inputs:{x:o},backend:n,attrs:{shape:g}});else if(k||y){a.util.assert(o.shape.length>=1,(()=>`Input must have rank at least 1, got: ${o.shape.length}`));const e=a.slice_util.computeOutShape(w,I,v),t=Oe({inputs:{x:o},backend:n,attrs:{begin:w,size:e}});x=Et({inputs:{x:t},backend:n,attrs:{shape:g}}),n.disposeIntermediateTensorInfo(t)}else{const e=Ye(m,n.bufferSync(o),v,w);x=n.makeTensorInfo(g,e.dtype,e.values)}return x}},Qa={kernelName:a.StringNGrams,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{separator:a,nGramWidths:s,leftPad:o,rightPad:i,padWidth:l,preserveShortSequences:u}=r,{data:c,dataSplits:d}=t,h=n.data.get(c.dataId).values,p=n.data.get(d.dataId).values,[f,m]=Qe(h,p,a,s,o,i,l,u);return[n.makeTensorInfo([f.length],"string",f),n.makeTensorInfo(d.shape,"int32",m)]}},es={kernelName:a.StringSplit,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{skipEmpty:a}=r,{input:s,delimiter:o}=t;if("string"!==s.dtype)throw new Error("Input must be of datatype string");if(1!==s.shape.length)throw new Error(`Input must be a vector, got shape: ${s.shape}`);if(0!==o.shape.length)throw new Error(`Delimiter must be a scalar, got shape: ${o.shape}`);const i=n.data.get(s.dataId).values,l=n.data.get(o.dataId).values[0],[u,c,d]=tt(i,l,a),h=c.length;return[n.makeTensorInfo([h,2],"int32",u),n.makeTensorInfo([h],"string",c),n.makeTensorInfo([2],"int32",new Int32Array(d))]}},ts={kernelName:a.StringToHashBucketFast,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{numBuckets:a}=r,{input:s}=t;if("string"!==s.dtype)throw new Error("Input must be of datatype string");if(a<=0)throw new Error("Number of buckets must be at least 1");const o=nt(n.data.get(s.dataId).values,a);return n.makeTensorInfo(s.shape,"int32",o)}},ns=M(a.Tan,(e=>Math.tan(e))),rs={kernelName:a.Tan,backendName:"cpu",kernelFunc:ns},as=M(a.Tanh,(e=>Math.tanh(e))),ss={kernelName:a.Tanh,backendName:"cpu",kernelFunc:as},os={kernelName:a.Tile,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{reps:o}=r;s(a,"tile");const i=it(n.bufferSync(a),o);return n.makeTensorInfo(i.shape,i.dtype,i.values)}},is={kernelName:a.TopK,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{k:o,sorted:i}=r;s(a,"topk");const l=n.data.get(a.dataId).values,[u,c]=ct(l,a.shape,a.dtype,o,i);return[n.makeTensorInfo(u.shape,u.dtype,u.values),n.makeTensorInfo(c.shape,c.dtype,c.values)]}},ls={kernelName:a.Transform,backendName:"cpu",kernelFunc:function(e){const{inputs:t,attrs:n,backend:r}=e,{image:s,transforms:o}=t,{interpolation:i,fillMode:l,fillValue:u,outputShape:c}=n,[d,h,p,f]=s.shape,[m,g]=null!=c?c:[h,p],b=[d,m,g,f],k=a.util.computeStrides(s.shape),y=k[0],w=k[1],I=k[2],v=a.util.getTypedArrayFromDType(s.dtype,a.util.sizeFromShape(b));v.fill(u);const x=r.data.get(s.dataId).values,S=r.data.get(o.dataId).values;for(let e=0;e<d;++e){const t=1===o.shape[0]?S:S.subarray(8*e,8*e+8);for(let n=0;n<m;++n)for(let r=0;r<g;++r)for(let a=0;a<f;++a){let s;const o=t[6]*r+t[7]*n+1;if(0===o)continue;const c=(t[0]*r+t[1]*n+t[2])/o,d=(t[3]*r+t[4]*n+t[5])/o,f=us(c,p,l),m=us(d,h,l);switch(i){case"nearest":s=ds(x,h,p,y,w,I,e,m,f,a,u);break;case"bilinear":s=hs(x,h,p,y,w,I,e,m,f,a,u);break;default:throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${i}`)}v[e*y+n*w+r*I+a]=s}return r.makeTensorInfo(b,s.dtype,v)}return{dataId:r.write(v,b,s.dtype),shape:s.shape,dtype:s.dtype}}};function us(e,t,n){switch(n){case"reflect":return function(e,t){let n=e;if(n<0)if(t<=1)n=0;else{const e=2*t;n<e&&(n=e*Math.trunc(-n/e)+n),n=n<-t?n+e:-n-1}else if(n>t-1)if(t<=1)n=0;else{const e=2*t;n-=e*Math.trunc(n/e),n>=t&&(n=e-n-1)}return a.util.clamp(0,n,t-1)}(e,t);case"wrap":return function(e,t){let n=e;if(n<0)if(t<=1)n=0;else{const e=t-1;n+=t*(Math.trunc(-n/e)+1)}else if(n>t-1)if(t<=1)n=0;else{const e=t-1;n-=t*Math.trunc(n/e)}return a.util.clamp(0,n,t-1)}(e,t);case"nearest":return function(e,t){return a.util.clamp(0,e,t-1)}(e,t);default:return function(e,t){return e}(e)}}function cs(e,t,n,r,a,s,o,i,l,u,c){return 0<=i&&i<t&&0<=l&&l<n?e[o*r+i*a+l*s+u]:c}function ds(e,t,n,r,a,s,o,i,l,u,c){return cs(e,t,n,r,a,s,o,Math.round(i),Math.round(l),u,c)}function hs(e,t,n,r,a,s,o,i,l,u,c){const d=Math.floor(i),h=Math.floor(l),p=d+1,f=h+1;return(p-i)*((f-l)*cs(e,t,n,r,a,s,o,d,h,u,c)+(l-h)*cs(e,t,n,r,a,s,o,d,f,u,c))+(i-d)*((f-l)*cs(e,t,n,r,a,s,o,p,h,u,c)+(l-h)*cs(e,t,n,r,a,s,o,p,f,u,c))}const ps={kernelName:a.Unique,backendName:"cpu",kernelFunc:function(e){const{inputs:t,attrs:n,backend:r}=e,{axis:a}=n,{x:o}=t;s(o,"unique");const i=r.data.get(o.dataId).values,{outputValues:l,outputShape:u,indices:c}=dt(i,a,o.shape,o.dtype);return[r.makeTensorInfo(u,o.dtype,l),r.makeTensorInfo([c.length],"int32",c)]}},fs={kernelName:a.Unpack,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{value:a}=t;let{axis:s}=r;s<0&&(s+=a.shape.length);const o=a.shape.length,i=a.shape[s],l=new Array(o-1);let u=0;for(let e=0;e<o;e++)e!==s&&(l[u++]=a.shape[e]);const c=new Array(o).fill(0),d=a.shape.slice();d[s]=1;const h=new Array(i);for(let e=0;e<h.length;e++){c[s]=e;const t=Oe({inputs:{x:a},backend:n,attrs:{begin:c,size:d}});h[e]=Et({inputs:{x:t},backend:n,attrs:{shape:l}}),n.disposeIntermediateTensorInfo(t)}return h}},ms={kernelName:a.UnsortedSegmentSum,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:r}=e,{x:o,segmentIds:i}=t,{numSegments:l}=r;s(o,"unsortedSegmentSum");const u=[],c=[],d=o.shape.length-i.shape.length;let h=i;for(let e=0;e<d;++e){const t=Yn({inputs:{input:h},backend:n,attrs:{dim:e+1}});h=t,c.push(t)}for(let e=0;e<l;++e){const t=a.util.createScalarValue(e,"int32"),r=n.makeTensorInfo([],"int32",t),s=B({inputs:{a:r,b:h},backend:n}),i=k({inputs:{x:s},backend:n,attrs:{dtype:"float32"}}),l=we({inputs:{a:i,b:o},backend:n}),d=Wn({inputs:{x:l},backend:n,attrs:{axis:0,keepDims:!1}});u.push(d),c.push(r),c.push(s),c.push(i),c.push(l),c.push(d)}const p=ua({inputs:u,backend:n,attrs:{axis:0}});return c.forEach((e=>n.disposeIntermediateTensorInfo(e))),p}},gs=[Mt,u,$t,_t,E,Rt,Ct,Bt,Pt,zt,Ot,Ht,Kt,Vt,Zt,Qt,en,tn,nn,At,rn,an,sn,on,y,_,un,h,cn,fn,gn,bn,kn,yn,wn,In,xn,En,Nn,Tn,An,Mn,Fn,Dn,_n,Rn,Cn,Bn,Pn,zn,Ln,ft,Hn,P,Jn,O,Xn,G,sr,ir,lr,U,dr,hr,pr,fr,mr,Y,ee,m,gr,hn,kr,wr,vr,gt,re,oe,xr,ce,Er,Ar,Fr,_r,Rr,Cr,Pr,fe,zr,Wr,Or,Lr,Hr,Gr,Kr,be,qr,jr,Xr,Ie,xe,ea,na,aa,Ne,sa,la,ca,da,fa,yt,$e,ma,b,tr,ba,It,xt,Nt,ka,ya,wa,Ia,va,xa,Ea,Ce,Ta,Aa,Da,ze,Ra,Ba,za,Le,Yr,La,Ha,Ga,Ka,qa,Ua,Va,ja,Ve,Za,Je,Ya,Xa,Qa,es,ts,ot,On,rs,ss,os,is,ls,Me,ps,fs,ms,ia];for(const e of gs)(0,a.registerKernel)(e)},356:(e,t,n)=>{n.r(t),n.d(t,{Abs:()=>xe,Acos:()=>Se,Acosh:()=>Ee,AdadeltaOptimizer:()=>Yi,AdagradOptimizer:()=>Qi,AdamOptimizer:()=>nl,AdamaxOptimizer:()=>sl,Add:()=>Ne,AddN:()=>Te,All:()=>Ae,Any:()=>Me,ArgMax:()=>Fe,ArgMin:()=>$e,Asin:()=>De,Asinh:()=>_e,Atan:()=>Re,Atan2:()=>Be,Atanh:()=>Ce,AvgPool:()=>Pe,AvgPool3D:()=>We,AvgPool3DGrad:()=>Oe,AvgPoolGrad:()=>ze,BatchMatMul:()=>Le,BatchToSpaceND:()=>He,Bincount:()=>Ge,BroadcastArgs:()=>qe,BroadcastTo:()=>Ke,Cast:()=>Ue,Ceil:()=>Ve,ClipByValue:()=>je,Complex:()=>Ze,ComplexAbs:()=>Je,Concat:()=>Ye,Conv2D:()=>Xe,Conv2DBackpropFilter:()=>Qe,Conv2DBackpropInput:()=>et,Conv3D:()=>tt,Conv3DBackpropFilterV2:()=>nt,Conv3DBackpropInputV2:()=>rt,Cos:()=>at,Cosh:()=>st,CropAndResize:()=>lt,Cumprod:()=>ot,Cumsum:()=>it,DataStorage:()=>y,DenseBincount:()=>ut,DepthToSpace:()=>ct,DepthwiseConv2dNative:()=>dt,DepthwiseConv2dNativeBackpropFilter:()=>ht,DepthwiseConv2dNativeBackpropInput:()=>pt,Diag:()=>ft,Dilation2D:()=>mt,Dilation2DBackpropFilter:()=>bt,Dilation2DBackpropInput:()=>gt,ENV:()=>we,Einsum:()=>yt,Elu:()=>wt,EluGrad:()=>It,Environment:()=>ge,Equal:()=>xt,Erf:()=>vt,Exp:()=>St,ExpandDims:()=>Et,Expm1:()=>Nt,FFT:()=>Tt,Fill:()=>At,FlipLeftRight:()=>Mt,Floor:()=>Ft,FloorDiv:()=>$t,FromPixels:()=>Er,FusedBatchNorm:()=>Dt,FusedConv2D:()=>Ar,FusedDepthwiseConv2D:()=>Mr,GatherNd:()=>Rt,GatherV2:()=>_t,Greater:()=>Ct,GreaterEqual:()=>Bt,IFFT:()=>zt,Identity:()=>Pt,Imag:()=>Wt,IsFinite:()=>Ot,IsInf:()=>Lt,IsNan:()=>Ht,KernelBackend:()=>w,LRN:()=>Qt,LRNGrad:()=>en,LeakyRelu:()=>Gt,Less:()=>Kt,LessEqual:()=>qt,LinSpace:()=>Ut,Log:()=>Vt,Log1p:()=>jt,LogSoftmax:()=>Xt,LogicalAnd:()=>Zt,LogicalNot:()=>Jt,LogicalOr:()=>Yt,Max:()=>tn,MaxPool:()=>rn,MaxPool3D:()=>sn,MaxPool3DGrad:()=>on,MaxPoolGrad:()=>an,MaxPoolWithArgmax:()=>ln,Maximum:()=>nn,Mean:()=>un,Min:()=>cn,Minimum:()=>dn,MirrorPad:()=>hn,Mod:()=>pn,MomentumOptimizer:()=>il,Multinomial:()=>fn,Multiply:()=>mn,Neg:()=>gn,NonMaxSuppressionV3:()=>kn,NonMaxSuppressionV4:()=>yn,NonMaxSuppressionV5:()=>wn,NotEqual:()=>bn,OP_SCOPE_SUFFIX:()=>Xa,OneHot:()=>vn,OnesLike:()=>In,Optimizer:()=>Ji,OptimizerConstructors:()=>ul,Pack:()=>xn,PadV2:()=>Sn,Pool:()=>En,Pow:()=>Nn,Prelu:()=>Tn,Prod:()=>An,RMSPropOptimizer:()=>ll,Range:()=>Mn,Rank:()=>xa,Real:()=>Fn,RealDiv:()=>kt,Reciprocal:()=>$n,Reduction:()=>Ch,Relu:()=>Dn,Relu6:()=>zn,Reshape:()=>_n,ResizeBilinear:()=>Bn,ResizeBilinearGrad:()=>Pn,ResizeNearestNeighbor:()=>Rn,ResizeNearestNeighborGrad:()=>Cn,Reverse:()=>Wn,RotateWithOffset:()=>Nr,Round:()=>On,Rsqrt:()=>Ln,SGDOptimizer:()=>ol,ScatterNd:()=>Hn,Select:()=>Gn,Selu:()=>Kn,Sigmoid:()=>Zn,Sign:()=>jn,Sin:()=>Un,Sinh:()=>Vn,Slice:()=>qn,Softmax:()=>tr,Softplus:()=>Jn,SpaceToBatchND:()=>Qn,SparseFillEmptyRows:()=>nr,SparseReshape:()=>rr,SparseSegmentMean:()=>ar,SparseSegmentSum:()=>sr,SparseToDense:()=>or,SplitV:()=>er,Sqrt:()=>Yn,Square:()=>lr,SquaredDifference:()=>ir,Step:()=>Sr,StridedSlice:()=>ur,StringNGrams:()=>cr,StringSplit:()=>dr,StringToHashBucketFast:()=>hr,Sub:()=>pr,Sum:()=>Xn,Tan:()=>fr,Tanh:()=>mr,Tensor:()=>Ia,TensorBuffer:()=>ba,Tile:()=>gr,TopK:()=>br,Transform:()=>kr,Transpose:()=>yr,Unique:()=>wr,Unpack:()=>Ir,UnsortedSegmentSum:()=>vr,Variable:()=>va,ZerosLike:()=>xr,_FusedMatMul:()=>Tr,abs:()=>rl,acos:()=>cl,acosh:()=>dl,add:()=>Ci,addN:()=>hl,all:()=>pl,any:()=>fl,argMax:()=>ml,argMin:()=>gl,asin:()=>bl,asinh:()=>kl,atan:()=>yl,atan2:()=>wl,atanh:()=>Il,avgPool:()=>Pl,avgPool3d:()=>zl,backend:()=>_i,backend_util:()=>b,basicLSTMCell:()=>Gl,batchNorm:()=>ql,batchNorm2d:()=>Ul,batchNorm3d:()=>Vl,batchNorm4d:()=>jl,batchToSpaceND:()=>Kl,bincount:()=>Zl,booleanMaskAsync:()=>Wd,broadcastArgs:()=>Jl,broadcastTo:()=>Yl,broadcast_util:()=>l,browser:()=>u,buffer:()=>Ys,cast:()=>Xs,ceil:()=>Xl,clipByValue:()=>Ql,clone:()=>Qs,complex:()=>es,concat:()=>Wl,concat1d:()=>eu,concat2d:()=>tu,concat3d:()=>nu,concat4d:()=>ru,conv1d:()=>su,conv2d:()=>au,conv2dTranspose:()=>iu,conv3d:()=>lu,conv3dTranspose:()=>cu,copyRegisteredKernels:()=>Lr,cos:()=>du,cosh:()=>hu,cosineWindow:()=>jd,cumprod:()=>pu,cumsum:()=>fu,customGrad:()=>Vi,denseBincount:()=>mu,deprecationWarn:()=>bi,depthToSpace:()=>gu,depthwiseConv2d:()=>bu,device_util:()=>s,diag:()=>ku,dilation2d:()=>yu,disableDeprecationWarnings:()=>gi,dispose:()=>xi,disposeVariables:()=>ki,div:()=>Pi,divNoNan:()=>vu,dot:()=>xu,dropout:()=>Ud,einsum:()=>Su,elu:()=>Eu,enableDebugMode:()=>mi,enableProdMode:()=>fi,enclosingPowerOfTwo:()=>Vd,engine:()=>yi,env:()=>ke,equal:()=>wu,erf:()=>Nu,exp:()=>Tu,expandDims:()=>Au,expm1:()=>Mu,eye:()=>$u,fft:()=>md,fill:()=>Xi,findBackend:()=>Fi,findBackendFactory:()=>$i,floor:()=>Du,floorDiv:()=>Bi,fused:()=>m,gather:()=>_u,gatherND:()=>qd,gather_util:()=>c,getBackend:()=>Ai,getGradient:()=>Cr,getKernel:()=>Rr,getKernelsForBackend:()=>Br,grad:()=>Hi,grads:()=>Gi,greater:()=>Ru,greaterEqual:()=>Cu,ifft:()=>gd,imag:()=>Bu,image:()=>ep,inTopKAsync:()=>Zd,io:()=>o,irfft:()=>bd,isFinite:()=>Pu,isInf:()=>zu,isNaN:()=>Wu,keep:()=>Si,kernel_impls:()=>k,leakyRelu:()=>Ou,less:()=>Lu,lessEqual:()=>Hu,linalg:()=>tp,linspace:()=>Gu,localResponseNormalization:()=>Ku,log:()=>qu,log1p:()=>Uu,logSigmoid:()=>Zu,logSoftmax:()=>Xu,logSumExp:()=>ic,logicalAnd:()=>lc,logicalNot:()=>uc,logicalOr:()=>cc,logicalXor:()=>dc,losses:()=>np,matMul:()=>yo,math:()=>i,max:()=>Ju,maxPool:()=>hc,maxPool3d:()=>pc,maxPoolWithArgmax:()=>fc,maximum:()=>al,mean:()=>mc,memory:()=>wi,meshgrid:()=>kc,min:()=>yc,minimum:()=>wc,mirrorPad:()=>Ic,mod:()=>vc,moments:()=>xc,movingAverage:()=>Hd,mul:()=>zi,multiRNNCell:()=>Sc,multinomial:()=>Ec,neg:()=>Vu,nextFrame:()=>ip,norm:()=>Ld,notEqual:()=>Nc,oneHot:()=>wo,ones:()=>bc,onesLike:()=>Tc,op:()=>Qa,outerProduct:()=>Ac,pad:()=>Mc,pad1d:()=>Fc,pad2d:()=>$c,pad3d:()=>Dc,pad4d:()=>_c,pool:()=>Cc,pow:()=>el,prelu:()=>Bc,print:()=>eo,prod:()=>Pc,profile:()=>Ii,rand:()=>zc,randomGamma:()=>Gc,randomNormal:()=>Kc,randomUniform:()=>qc,range:()=>Uc,ready:()=>Ti,real:()=>Vc,reciprocal:()=>jc,registerBackend:()=>Di,registerGradient:()=>zr,registerKernel:()=>Pr,relu:()=>Zc,relu6:()=>Jc,removeBackend:()=>Mi,reshape:()=>Bl,reverse:()=>Yc,reverse1d:()=>Xc,reverse2d:()=>Qc,reverse3d:()=>ed,reverse4d:()=>td,rfft:()=>yd,round:()=>nd,rsqrt:()=>rd,scalar:()=>Zi,scatterND:()=>Gd,scatter_util:()=>d,selu:()=>ad,separableConv2d:()=>sd,serialization:()=>p,setBackend:()=>Ni,setPlatform:()=>Ri,setdiff1dAsync:()=>od,sigmoid:()=>Ol,sign:()=>id,signal:()=>Qh,sin:()=>ld,sinh:()=>ud,slice:()=>Ll,slice1d:()=>cd,slice2d:()=>dd,slice3d:()=>hd,slice4d:()=>pd,slice_util:()=>h,softmax:()=>fd,softplus:()=>ju,spaceToBatchND:()=>Rc,sparse:()=>rp,sparseToDense:()=>Kd,spectral:()=>Xh,split:()=>kd,sqrt:()=>Wi,square:()=>Oi,squaredDifference:()=>wd,squeeze:()=>Id,stack:()=>vd,step:()=>xd,stridedSlice:()=>Sd,string:()=>ap,sub:()=>tl,sum:()=>Yu,sumOutType:()=>Fa,tan:()=>Ed,tanh:()=>Hl,tensor:()=>ns,tensor1d:()=>Nd,tensor2d:()=>Td,tensor3d:()=>No,tensor4d:()=>Ad,tensor5d:()=>Md,tensor6d:()=>Fd,tensor_util:()=>a,test_util:()=>f,tidy:()=>vi,tile:()=>Fu,time:()=>Ei,topk:()=>$d,train:()=>sp,transpose:()=>Io,truncatedNormal:()=>Dd,unique:()=>_d,unregisterGradient:()=>Or,unregisterKernel:()=>Wr,unsortedSegmentSum:()=>Rd,unstack:()=>Cd,upcastType:()=>Ma,util:()=>r,valueAndGrad:()=>Ki,valueAndGrads:()=>qi,variable:()=>Bd,variableGrads:()=>Ui,version_core:()=>pi,where:()=>Iu,whereAsync:()=>zd,zeros:()=>gc,zerosLike:()=>Li});var r={};n.r(r),n.d(r,{arraysEqual:()=>B,assert:()=>F,assertNonNegativeIntegerDimensions:()=>he,assertNonNull:()=>D,assertShapesMatch:()=>$,bytesFromStringArray:()=>Q,bytesPerElement:()=>X,checkConversionForErrors:()=>j,clamp:()=>S,computeStrides:()=>oe,createScalarValue:()=>ra,createShuffledIndices:()=>O,decodeString:()=>la,distSquared:()=>M,encodeString:()=>ia,fetch:()=>oa,fingerPrint64:()=>na,flatten:()=>_,getArrayFromDType:()=>V,getTypedArrayFromDType:()=>U,hasEncodingLoss:()=>J,hexToLong:()=>qr,indexToLoc:()=>fe,inferDtype:()=>re,inferFromImplicitShape:()=>G,isBoolean:()=>te,isFunction:()=>ae,isInt:()=>P,isNumber:()=>ne,isPromise:()=>me,isScalarShape:()=>C,isString:()=>ee,isTypedArray:()=>Y,isValidDtype:()=>Z,locToIndex:()=>pe,makeOnesTypedArray:()=>ue,makeZerosNestedTypedArray:()=>de,makeZerosTypedArray:()=>ce,nearestDivisor:()=>se,nearestLargerEven:()=>E,now:()=>sa,parseAxisParam:()=>K,randUniform:()=>A,repeatedTry:()=>H,rightPad:()=>L,shuffle:()=>v,shuffleCombo:()=>x,sizeFromShape:()=>R,sizeToSquarishShape:()=>W,squeezeShape:()=>q,sum:()=>T,swap:()=>N,tanh:()=>z,toNestedArray:()=>le,toTypedArray:()=>aa});var a={};n.r(a),n.d(a,{assertTypesMatch:()=>Da,getTensorsInContainer:()=>Ra,isTensorInList:()=>_a,makeTypesMatch:()=>$a});var s={};n.r(s),n.d(s,{isBrowser:()=>qa,isMobile:()=>Ka,mockIsMobile:()=>Ga});var o={};n.r(o),n.d(o,{browserFiles:()=>ao,browserHTTPRequest:()=>fo,concatenateArrayBuffers:()=>us,copyModel:()=>Vs,decodeWeights:()=>ss,encodeWeights:()=>as,fromMemory:()=>bo,getLoadHandlers:()=>ys,getModelArtifactsForJSON:()=>hs,getModelArtifactsInfoForJSON:()=>ps,getSaveHandlers:()=>ks,http:()=>po,isHTTPScheme:()=>co,listModels:()=>qs,loadWeights:()=>io,moveModel:()=>js,registerLoadRouter:()=>bs,registerSaveRouter:()=>gs,removeModel:()=>Us,weightsLoaderFactory:()=>lo,withSaveHandler:()=>ko});var i={};n.r(i),n.d(i,{confusionMatrix:()=>vo});var l={};n.r(l),n.d(l,{assertAndGetBroadcastShape:()=>Eo,getBroadcastDims:()=>xo,getReductionAxes:()=>So});var u={};n.r(u),n.d(u,{fromPixels:()=>$o,fromPixelsAsync:()=>Mo,toPixels:()=>Fo});var c={};n.r(c),n.d(c,{prepareAndValidate:()=>Do});var d={};n.r(d),n.d(d,{calculateShapes:()=>Co,validateInput:()=>Ro,validateUpdateShape:()=>_o});var h={};n.r(h),n.d(h,{assertParamsValid:()=>Bo,computeFlatOffset:()=>Zo,computeOutShape:()=>zo,getNormalizedAxes:()=>Ho,isSliceContinous:()=>jo,maskToAxes:()=>Po,parseSliceParams:()=>Jo,sliceInfo:()=>Yo,startForAxis:()=>Uo,startIndicesWithElidedDims:()=>Go,stopForAxis:()=>Vo,stopIndicesWithElidedDims:()=>Ko,stridesForAxis:()=>qo,stridesWithElidedDims:()=>Wo});var p={};n.r(p),n.d(p,{Serializable:()=>Qo,SerializationMap:()=>ei,registerClass:()=>ti});var f={};n.r(f),n.d(f,{TEST_EPSILON_FLOAT16:()=>ni,encodeStrings:()=>hi,expectArrayBuffersEqual:()=>di,expectArraysClose:()=>ri,expectArraysEqual:()=>ii,expectNumbersClose:()=>li,expectPromiseToFail:()=>oi,expectValuesInRange:()=>ci,testEpsilon:()=>ai});var m={};n.r(m),n.d(m,{conv2d:()=>th,depthwiseConv2d:()=>ah,matMul:()=>sh});var g={};n.r(g),n.d(g,{collectGatherOpShapeInfo:()=>nf,computeOutShape:()=>tf,segOpComputeOptimalWindowSize:()=>ef});var b={};n.r(b),n.d(b,{ERF_A1:()=>Ip,ERF_A2:()=>vp,ERF_A3:()=>xp,ERF_A4:()=>Sp,ERF_A5:()=>Ep,ERF_P:()=>wp,PARALLELIZE_THRESHOLD:()=>cp,SELU_SCALE:()=>yp,SELU_SCALEALPHA:()=>kp,applyActivation:()=>Qd,assertAndGetBroadcastShape:()=>Eo,assertAxesAreInnerMostDims:()=>rc,assertParamsConsistent:()=>lp,assignToTypedArray:()=>$p,axesAreInnerMostDims:()=>Qu,calculateShapes:()=>Co,checkEinsumDimSizes:()=>Pp,checkPadOnDimRoundingMode:()=>Cl,combineLocations:()=>ec,complexWithEvenIndex:()=>Ap,complexWithOddIndex:()=>Mp,computeConv2DInfo:()=>El,computeConv3DInfo:()=>Nl,computeDefaultPad:()=>Tl,computeDilation2DInfo:()=>vl,computeOptimalWindowSize:()=>dp,computeOutAndReduceShapes:()=>tc,computeOutShape:()=>up,computePool2DInfo:()=>xl,computePool3DInfo:()=>Sl,convertConv2DDataFormat:()=>Rl,decodeEinsumEquation:()=>Cp,eitherStridesOrDilationsAreOne:()=>_l,expandShapeToKeepDim:()=>nc,exponent:()=>_p,exponents:()=>Dp,fromStringArrayToUint8:()=>af,fromUint8ToStringArray:()=>rf,getAxesPermutation:()=>ac,getBroadcastDims:()=>xo,getComplexWithIndex:()=>Fp,getEinsumComputePath:()=>zp,getEinsumPermutation:()=>Bp,getFusedBiasGradient:()=>Xd,getFusedDyActivation:()=>Yd,getImageCenter:()=>hp,getInnerMostAxes:()=>oc,getPermuted:()=>fp,getReductionAxes:()=>So,getReshaped:()=>pp,getReshapedPermuted:()=>mp,getSliceBeginCoords:()=>gp,getSliceSize:()=>bp,getSparseFillEmptyRowsIndicesDenseShapeMismatch:()=>Hp,getSparseFillEmptyRowsNegativeIndexErrorMessage:()=>Gp,getSparseFillEmptyRowsOutOfRangeIndexErrorMessage:()=>Kp,getSparseReshapeEmptyTensorZeroOutputDimErrorMessage:()=>Vp,getSparseReshapeInputOutputMismatchErrorMessage:()=>Zp,getSparseReshapeInputOutputMultipleErrorMessage:()=>jp,getSparseReshapeMultipleNegativeOneOutputDimErrorMessage:()=>qp,getSparseReshapeNegativeOutputDimErrorMessage:()=>Up,getSparseSegmentReductionIndicesOutOfRangeErrorMessage:()=>Qp,getSparseSegmentReductionNegativeSegmentIdsErrorMessage:()=>Jp,getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage:()=>Yp,getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage:()=>Xp,getUndoAxesPermutation:()=>sc,isIdentityPermutation:()=>Wp,log:()=>$r,mergeRealAndImagArrays:()=>Np,prepareAndValidate:()=>Do,prepareSplitSize:()=>Lp,segment_util:()=>g,shouldFuse:()=>eh,slice_util:()=>h,splitRealAndImagArrays:()=>Tp,tupleValuesAreOne:()=>Dl,upcastType:()=>Ma,validateInput:()=>Ro,validateUpdateShape:()=>_o,warn:()=>Fr});var k={};n.r(k),n.d(k,{nonMaxSuppressionV3Impl:()=>kh,nonMaxSuppressionV4Impl:()=>yh,nonMaxSuppressionV5Impl:()=>wh,whereImpl:()=>Pd});class y{constructor(e,t){this.backend=e,this.dataMover=t,this.data=new WeakMap,this.dataIdsCount=0}get(e){return this.data.has(e)||this.dataMover.moveData(this.backend,e),this.data.get(e)}set(e,t){this.dataIdsCount++,this.data.set(e,t)}has(e){return this.data.has(e)}delete(e){return this.dataIdsCount--,this.data.delete(e)}numDataIds(){return this.dataIdsCount}}class w{refCount(e){return I("refCount")}incRef(e){return I("incRef")}timerAvailable(){return!0}time(e){return I("time")}read(e){return I("read")}readSync(e){return I("readSync")}readToGPU(e,t){return I("readToGPU")}numDataIds(){return I("numDataIds")}disposeData(e,t){return I("disposeData")}write(e,t,n){return I("write")}move(e,t,n,r,a){return I("move")}memory(){return I("memory")}floatPrecision(){return I("floatPrecision")}epsilon(){return 32===this.floatPrecision()?1e-7:1e-4}dispose(){return I("dispose")}}function I(e){throw new Error(`'${e}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`)}function v(e){let t=e.length,n=0;for(;t>0;)n=Math.random()*t|0,t--,N(e,t,n)}function x(e,t){if(e.length!==t.length)throw new Error(`Array sizes must match to be shuffled together First array length was ${e.length}Second array length was ${t.length}`);let n=e.length,r=0;for(;n>0;)r=Math.random()*n|0,n--,N(e,n,r),N(t,n,r)}function S(e,t,n){return Math.max(e,Math.min(t,n))}function E(e){return e%2==0?e:e+1}function N(e,t,n){const r=e[t];e[t]=e[n],e[n]=r}function T(e){let t=0;for(let n=0;n<e.length;n++)t+=e[n];return t}function A(e,t){const n=Math.random();return t*n+(1-n)*e}function M(e,t){let n=0;for(let r=0;r<e.length;r++){const a=Number(e[r])-Number(t[r]);n+=a*a}return n}function F(e,t){if(!e)throw new Error("string"==typeof t?t:t())}function $(e,t,n=""){F(B(e,t),(()=>n+` Shapes ${e} and ${t} must match`))}function D(e){F(null!=e,(()=>"The input to the tensor constructor must be a non-null value."))}function _(e,t=[],n=!1){if(null==t&&(t=[]),Array.isArray(e)||Y(e)&&!n)for(let r=0;r<e.length;++r)_(e[r],t,n);else t.push(e);return t}function R(e){if(0===e.length)return 1;let t=e[0];for(let n=1;n<e.length;n++)t*=e[n];return t}function C(e){return 0===e.length}function B(e,t){if(e===t)return!0;if(null==e||null==t)return!1;if(e.length!==t.length)return!1;for(let n=0;n<e.length;n++)if(e[n]!==t[n])return!1;return!0}function P(e){return e%1==0}function z(e){if(null!=Math.tanh)return Math.tanh(e);if(e===1/0)return 1;if(e===-1/0)return-1;{const t=Math.exp(2*e);return(t-1)/(t+1)}}function W(e){const t=Math.ceil(Math.sqrt(e));return[t,Math.ceil(e/t)]}function O(e){const t=new Uint32Array(e);for(let n=0;n<e;++n)t[n]=n;return v(t),t}function L(e,t){return t<=e.length?e:e+" ".repeat(t-e.length)}function H(e,t=(e=>0),n){return new Promise(((r,a)=>{let s=0;const o=()=>{if(e())return void r();s++;const i=t(s);null!=n&&s>=n?a():setTimeout(o,i)};o()}))}function G(e,t){let n=1,r=-1;for(let t=0;t<e.length;++t)if(e[t]>=0)n*=e[t];else if(-1===e[t]){if(-1!==r)throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${r} and dim ${t}`);r=t}else if(e[t]<0)throw Error(`Shapes can not be < 0. Found ${e[t]} at dim ${t}`);if(-1===r){if(t>0&&t!==n)throw Error(`Size(${t}) must match the product of shape ${e}`);return e}if(0===n)throw Error(`Cannot infer the missing size in [${e}] when there are 0 elements`);if(t%n!=0)throw Error(`The implicit shape can't be a fractional number. Got ${t} / ${n}`);const a=e.slice();return a[r]=t/n,a}function K(e,t){const n=t.length;return F((e=null==e?t.map(((e,t)=>t)):[].concat(e)).every((e=>e>=-n&&e<n)),(()=>`All values in axis param must be in range [-${n}, ${n}) but got axis ${e}`)),F(e.every((e=>P(e))),(()=>`All values in axis param must be integers but got axis ${e}`)),e.map((e=>e<0?n+e:e))}function q(e,t){const n=[],r=[],a=null!=t&&Array.isArray(t)&&0===t.length,s=null==t||a?null:K(t,e).sort();let o=0;for(let t=0;t<e.length;++t){if(null!=s){if(s[o]===t&&1!==e[t])throw new Error(`Can't squeeze axis ${t} since its dim '${e[t]}' is not 1`);(null==s[o]||s[o]>t)&&1===e[t]&&(n.push(e[t]),r.push(t)),s[o]<=t&&o++}1!==e[t]&&(n.push(e[t]),r.push(t))}return{newShape:n,keptDims:r}}function U(e,t){let n=null;if(null==e||"float32"===e)n=new Float32Array(t);else if("int32"===e)n=new Int32Array(t);else{if("bool"!==e)throw new Error(`Unknown data type ${e}`);n=new Uint8Array(t)}return n}function V(e,t){let n=null;if(null==e||"float32"===e)n=new Float32Array(t);else if("int32"===e)n=new Int32Array(t);else if("bool"===e)n=new Uint8Array(t);else{if("string"!==e)throw new Error(`Unknown data type ${e}`);n=new Array(t)}return n}function j(e,t){for(let n=0;n<e.length;n++){const r=e[n];if(isNaN(r)||!isFinite(r))throw Error(`A tensor of type ${t} being uploaded contains ${r}.`)}}function Z(e){return"bool"===e||"complex64"===e||"float32"===e||"int32"===e||"string"===e}function J(e,t){return!("complex64"===t||"float32"===t&&"complex64"!==e||"int32"===t&&"float32"!==e&&"complex64"!==e||"bool"===t&&"bool"===e)}function Y(e){return e instanceof Float32Array||e instanceof Int32Array||e instanceof Uint8Array||e instanceof Uint8ClampedArray}function X(e){if("float32"===e||"int32"===e)return 4;if("complex64"===e)return 8;if("bool"===e)return 1;throw new Error(`Unknown dtype ${e}`)}function Q(e){if(null==e)return 0;let t=0;return e.forEach((e=>t+=e.length)),t}function ee(e){return"string"==typeof e||e instanceof String}function te(e){return"boolean"==typeof e}function ne(e){return"number"==typeof e}function re(e){return Array.isArray(e)?re(e[0]):e instanceof Float32Array?"float32":e instanceof Int32Array||e instanceof Uint8Array||e instanceof Uint8ClampedArray?"int32":ne(e)?"float32":ee(e)?"string":te(e)?"bool":"float32"}function ae(e){return!!(e&&e.constructor&&e.call&&e.apply)}function se(e,t){for(let n=t;n<e;++n)if(e%n==0)return n;return e}function oe(e){const t=e.length;if(t<2)return[];const n=new Array(t-1);n[t-2]=e[t-1];for(let r=t-3;r>=0;--r)n[r]=n[r+1]*e[r+1];return n}function ie(e,t,n,r=!1){const a=new Array;if(1===t.length){const s=t[0]*(r?2:1);for(let t=0;t<s;t++)a[t]=n[e+t]}else{const s=t[0],o=t.slice(1),i=o.reduce(((e,t)=>e*t))*(r?2:1);for(let t=0;t<s;t++)a[t]=ie(e+t*i,o,n,r)}return a}function le(e,t,n=!1){if(0===e.length)return t[0];const r=e.reduce(((e,t)=>e*t))*(n?2:1);if(0===r)return[];if(r!==t.length)throw new Error(`[${e}] does not match the input size ${t.length}${n?" for a complex tensor":""}.`);return ie(0,e,t,n)}function ue(e,t){const n=ce(e,t);for(let e=0;e<n.length;e++)n[e]=1;return n}function ce(e,t){if(null==t||"float32"===t||"complex64"===t)return new Float32Array(e);if("int32"===t)return new Int32Array(e);if("bool"===t)return new Uint8Array(e);throw new Error(`Unknown data type ${t}`)}function de(e,t){const n=e.reduce(((e,t)=>e*t),1);if(null==t||"float32"===t)return le(e,new Float32Array(n));if("int32"===t)return le(e,new Int32Array(n));if("bool"===t)return le(e,new Uint8Array(n));throw new Error(`Unknown data type ${t}`)}function he(e){e.forEach((t=>{F(Number.isInteger(t)&&t>=0,(()=>`Tensor must have a shape comprised of positive integers but got shape [${e}].`))}))}function pe(e,t,n){if(0===t)return 0;if(1===t)return e[0];let r=e[e.length-1];for(let t=0;t<e.length-1;++t)r+=n[t]*e[t];return r}function fe(e,t,n){if(0===t)return[];if(1===t)return[e];const r=new Array(t);for(let t=0;t<r.length-1;++t)r[t]=Math.floor(e/n[t]),e-=r[t]*n[t];return r[r.length-1]=e,r}function me(e){return e&&e.then&&"function"==typeof e.then}class ge{constructor(e){this.global=e,this.flags={},this.flagRegistry={},this.urlFlags={},this.getQueryParams=be,this.populateURLFlags()}setPlatform(e,t){null!=this.platform&&(ke().getBool("IS_TEST")||ke().getBool("PROD")||console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${e}.`)),this.platformName=e,this.platform=t}registerFlag(e,t,n){if(this.flagRegistry[e]={evaluationFn:t,setHook:n},null!=this.urlFlags[e]){const t=this.urlFlags[e];ke().getBool("IS_TEST")||ke().getBool("PROD")||console.warn(`Setting feature override from URL ${e}: ${t}.`),this.set(e,t)}}async getAsync(e){return e in this.flags||(this.flags[e]=await this.evaluateFlag(e)),this.flags[e]}get(e){if(e in this.flags)return this.flags[e];const t=this.evaluateFlag(e);if(me(t))throw new Error(`Flag ${e} cannot be synchronously evaluated. Please use getAsync() instead.`);return this.flags[e]=t,this.flags[e]}getNumber(e){return this.get(e)}getBool(e){return this.get(e)}getFlags(){return this.flags}get features(){return this.flags}set(e,t){if(null==this.flagRegistry[e])throw new Error(`Cannot set flag ${e} as it has not been registered.`);this.flags[e]=t,null!=this.flagRegistry[e].setHook&&this.flagRegistry[e].setHook(t)}evaluateFlag(e){if(null==this.flagRegistry[e])throw new Error(`Cannot evaluate flag '${e}': no evaluation function found.`);return this.flagRegistry[e].evaluationFn()}setFlags(e){this.flags=Object.assign({},e)}reset(){this.flags={},this.urlFlags={},this.populateURLFlags()}populateURLFlags(){if(void 0===this.global||void 0===this.global.location||void 0===this.global.location.search)return;const e=this.getQueryParams(this.global.location.search);"tfjsflags"in e&&e.tfjsflags.split(",").forEach((e=>{const[t,n]=e.split(":");this.urlFlags[t]=function(e,t){if("true"===(t=t.toLowerCase())||"false"===t)return"true"===t;if(""+ +t===t)return+t;throw new Error(`Could not parse value flag value ${t} for flag ${e}.`)}(t,n)}))}}function be(e){const t={};return e.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g,((e,...n)=>(function(e,t,n){e[decodeURIComponent(t)]=decodeURIComponent(n||"")}(t,n[0],n[1]),n.join("=")))),t}function ke(){return we}let ye,we=null;function Ie(){if(null==ye){let e;if("undefined"!=typeof window)e=window;else if(void 0!==n.g)e=n.g;else if("undefined"!=typeof process)e=process;else{if("undefined"==typeof self)throw new Error("Could not find a global object");e=self}ye=e}return ye}function ve(e,t){const n=function(){const e=Ie();return null==e._tfGlobals&&(e._tfGlobals=new Map),e._tfGlobals}();if(n.has(e))return n.get(e);{const r=t();return n.set(e,r),n.get(e)}}const xe="Abs",Se="Acos",Ee="Acosh",Ne="Add",Te="AddN",Ae="All",Me="Any",Fe="ArgMax",$e="ArgMin",De="Asin",_e="Asinh",Re="Atan",Ce="Atanh",Be="Atan2",Pe="AvgPool",ze="AvgPoolGrad",We="AvgPool3D",Oe="AvgPool3DGrad",Le="BatchMatMul",He="BatchToSpaceND",Ge="Bincount",Ke="BroadcastTo",qe="BroadcastArgs",Ue="Cast",Ve="Ceil",je="ClipByValue",Ze="Complex",Je="ComplexAbs",Ye="Concat",Xe="Conv2D",Qe="Conv2DBackpropFilter",et="Conv2DBackpropInput",tt="Conv3D",nt="Conv3DBackpropFilterV2",rt="Conv3DBackpropInputV2",at="Cos",st="Cosh",ot="Cumprod",it="Cumsum",lt="CropAndResize",ut="DenseBincount",ct="DepthToSpace",dt="DepthwiseConv2dNative",ht="DepthwiseConv2dNativeBackpropFilter",pt="DepthwiseConv2dNativeBackpropInput",ft="Diag",mt="Dilation2D",gt="Dilation2DBackpropInput",bt="Dilation2DBackpropFilter",kt="RealDiv",yt="Einsum",wt="Elu",It="EluGrad",vt="Erf",xt="Equal",St="Exp",Et="ExpandDims",Nt="Expm1",Tt="FFT",At="Fill",Mt="FlipLeftRight",Ft="Floor",$t="FloorDiv",Dt="FusedBatchNorm",_t="GatherV2",Rt="GatherNd",Ct="Greater",Bt="GreaterEqual",Pt="Identity",zt="IFFT",Wt="Imag",Ot="IsFinite",Lt="IsInf",Ht="IsNan",Gt="LeakyRelu",Kt="Less",qt="LessEqual",Ut="LinSpace",Vt="Log",jt="Log1p",Zt="LogicalAnd",Jt="LogicalNot",Yt="LogicalOr",Xt="LogSoftmax",Qt="LRN",en="LRNGrad",tn="Max",nn="Maximum",rn="MaxPool",an="MaxPoolGrad",sn="MaxPool3D",on="MaxPool3DGrad",ln="MaxPoolWithArgmax",un="Mean",cn="Min",dn="Minimum",hn="MirrorPad",pn="Mod",fn="Multinomial",mn="Multiply",gn="Neg",bn="NotEqual",kn="NonMaxSuppressionV3",yn="NonMaxSuppressionV4",wn="NonMaxSuppressionV5",In="OnesLike",vn="OneHot",xn="Pack",Sn="PadV2",En="Pool",Nn="Pow",Tn="Prelu",An="Prod",Mn="Range",Fn="Real",$n="Reciprocal",Dn="Relu",_n="Reshape",Rn="ResizeNearestNeighbor",Cn="ResizeNearestNeighborGrad",Bn="ResizeBilinear",Pn="ResizeBilinearGrad",zn="Relu6",Wn="Reverse",On="Round",Ln="Rsqrt",Hn="ScatterNd",Gn="Select",Kn="Selu",qn="Slice",Un="Sin",Vn="Sinh",jn="Sign",Zn="Sigmoid",Jn="Softplus",Yn="Sqrt",Xn="Sum",Qn="SpaceToBatchND",er="SplitV",tr="Softmax",nr="SparseFillEmptyRows",rr="SparseReshape",ar="SparseSegmentMean",sr="SparseSegmentSum",or="SparseToDense",ir="SquaredDifference",lr="Square",ur="StridedSlice",cr="StringNGrams",dr="StringSplit",hr="StringToHashBucketFast",pr="Sub",fr="Tan",mr="Tanh",gr="Tile",br="TopK",kr="Transform",yr="Transpose",wr="Unique",Ir="Unpack",vr="UnsortedSegmentSum",xr="ZerosLike",Sr="Step",Er="FromPixels",Nr="RotateWithOffset",Tr="_FusedMatMul",Ar="FusedConv2D",Mr="FusedDepthwiseConv2D";function Fr(...e){ke().getBool("IS_TEST")||ke().getBool("PROD")||console.warn(...e)}function $r(...e){ke().getBool("IS_TEST")||ke().getBool("PROD")||console.log(...e)}const Dr=ve("kernelRegistry",(()=>new Map)),_r=ve("gradRegistry",(()=>new Map));function Rr(e,t){const n=Hr(e,t);return Dr.get(n)}function Cr(e){return _r.get(e)}function Br(e){const t=Dr.entries(),n=[];for(;;){const{done:r,value:a}=t.next();if(r)break;const[s,o]=a,[i]=s.split("_");i===e&&n.push(o)}return n}function Pr(e){const{kernelName:t,backendName:n}=e,r=Hr(t,n);Dr.has(r)&&Fr(`The kernel '${t}' for backend '${n}' is already registered`),Dr.set(r,e)}function zr(e){const{kernelName:t}=e;_r.has(t)&&ke().getBool("DEBUG")&&Fr(`Overriding the gradient for '${t}'`),_r.set(t,e)}function Wr(e,t){const n=Hr(e,t);if(!Dr.has(n))throw new Error(`The kernel '${e}' for backend '${t}' is not registered`);Dr.delete(n)}function Or(e){if(!_r.has(e))throw new Error(`The gradient '${e}' for backend is not registered`);_r.delete(e)}function Lr(e,t){Br(e).forEach((e=>{Pr(Object.assign({},e,{backendName:t}))}))}function Hr(e,t){return`${t}_${e}`}var Gr=n(3720);const Kr=n.n(Gr)()||Gr;function qr(e){return Kr.fromString(e,!0,16)}const Ur=qr("c3a5c85c97cb3127"),Vr=qr("b492b66fbe98f273"),jr=qr("9ae16a3b2f90404f");function Zr(e){return e.xor(e.shru(47))}function Jr(e,t,n){const r=e.slice(t,t+n);return Kr.fromBytes(Array.from(r),!0,!0)}function Yr(e,t){return Jr(e,t,8)}function Xr(e,t){return Jr(e,t,4)}function Qr(e,t){return 0===t?e:e.shru(t).or(e.shl(64-t))}function ea(e,t,n=qr("9ddfea08eb382d69")){let r=e.xor(t).mul(n);r=r.xor(r.shru(47));let a=t.xor(r).mul(n);return a=a.xor(a.shru(47)),a=a.mul(n),a}function ta(e,t,n,r){return function(e,t,n,r,a,s){a=a.add(e),s=Qr(s.add(a).add(r),21);const o=a;return a=(a=a.add(t)).add(n),s=s.add(Qr(a,44)),[a.add(r),s.add(o)]}(Yr(e,t),Yr(e,t+8),Yr(e,t+16),Yr(e,t+24),n,r)}function na(e,t=e.length){const n=Kr.fromNumber(81,!0);if(t<=32)return t<=16?function(e,t=e.length){if(t>=8){const n=jr.add(2*t),r=Yr(e,0).add(jr),a=Yr(e,t-8);return ea(Qr(a,37).mul(n).add(r),Qr(r,25).add(a).mul(n),n)}if(t>=4){const n=jr.add(2*t);return ea(Xr(e,0).shl(3).add(t),Xr(e,t-4),n)}if(t>0){const n=e[0]+(e[t>>1]<<8),r=t+(e[t-1]<<2);return Zr(jr.mul(n).xor(Ur.mul(r))).mul(jr)}return jr}(e,t):function(e,t=e.length){const n=jr.add(2*t),r=Yr(e,0).mul(Vr),a=Yr(e,8),s=Yr(e,t-8).mul(n),o=Yr(e,t-16).mul(jr);return ea(Qr(r.add(a),43).add(Qr(s,30)).add(o),r.add(Qr(a.add(jr),18)).add(s),n)}(e,t);if(t<=64)return function(e,t=e.length){const n=jr.add(2*t),r=Yr(e,0).mul(jr),a=Yr(e,8),s=Yr(e,t-8).mul(n),o=Yr(e,t-16).mul(jr),i=Qr(r.add(a),43).add(Qr(s,30)).add(o),l=ea(i,r.add(Qr(a.add(jr),18)).add(s),n),u=Yr(e,16).mul(n),c=Yr(e,24),d=i.add(Yr(e,t-32)).mul(n),h=l.add(Yr(e,t-24)).mul(n);return ea(Qr(u.add(c),43).add(Qr(d,30)).add(h),u.add(Qr(c.add(r),18)).add(d),n)}(e,t);let r=n,a=n.mul(Vr).add(113),s=Zr(a.mul(jr).add(113)).mul(jr),o=[Kr.UZERO,Kr.UZERO],i=[Kr.UZERO,Kr.UZERO];r=r.mul(jr).add(Yr(e,0));let l=0;const u=64*(t-1>>6),c=u+(t-1&63)-63;do{r=Qr(r.add(a).add(o[0]).add(Yr(e,l+8)),37).mul(Vr),a=Qr(a.add(o[1]).add(Yr(e,l+48)),42).mul(Vr),r=r.xor(i[1]),a=a.add(o[0]).add(Yr(e,l+40)),s=Qr(s.add(i[0]),33).mul(Vr),o=ta(e,l,o[1].mul(Vr),r.add(i[0])),i=ta(e,l+32,s.add(i[1]),a.add(Yr(e,l+16))),[s,r]=[r,s],l+=64}while(l!==u);const d=Vr.add(s.and(255).shl(1));return l=c,i[0]=i[0].add(t-1&63),o[0]=o[0].add(i[0]),i[0]=i[0].add(o[0]),r=Qr(r.add(a).add(o[0]).add(Yr(e,l+8)),37).mul(d),a=Qr(a.add(o[1]).add(Yr(e,l+48)),42).mul(d),r=r.xor(i[1].mul(9)),a=a.add(o[0].mul(9).add(Yr(e,l+40))),s=Qr(s.add(i[0]),33).mul(d),o=ta(e,l,o[1].mul(d),r.add(i[0])),i=ta(e,l+32,s.add(i[1]),a.add(Yr(e,l+16))),[s,r]=[r,s],ea(ea(o[0],i[0],d).add(Zr(a).mul(Ur)).add(s),ea(o[1],i[1],d).add(r),d)}function ra(e,t){return"string"===t?ia(e):aa([e],t)}function aa(e,t){if("string"===t)throw new Error("Cannot convert a string[] to a TypedArray");if(Array.isArray(e)&&(e=_(e)),ke().getBool("DEBUG")&&j(e,t),function(e,t){return e instanceof Float32Array&&"float32"===t||e instanceof Int32Array&&"int32"===t||e instanceof Uint8Array&&"bool"===t}(e,t))return e;if(null==t||"float32"===t||"complex64"===t)return new Float32Array(e);if("int32"===t)return new Int32Array(e);if("bool"===t){const t=new Uint8Array(e.length);for(let n=0;n<t.length;++n)0!==Math.round(e[n])&&(t[n]=1);return t}throw new Error(`Unknown data type ${t}`)}function sa(){return ke().platform.now()}function oa(e,t){return ke().platform.fetch(e,t)}function ia(e,t="utf-8"){return t=t||"utf-8",ke().platform.encode(e,t)}function la(e,t="utf-8"){return t=t||"utf-8",ke().platform.decode(e,t)}class ua{constructor(e,t){this.backendTimer=e,this.logger=t,null==t&&(this.logger=new da)}profileKernel(e,t,n){let r;const a=()=>{r=n()};let s;const o=sa();if(this.backendTimer.timerAvailable())s=this.backendTimer.time(a);else{a();for(const e of r)e.dataSync();s=Promise.resolve({kernelMs:sa()-o})}if(ke().getBool("CHECK_COMPUTATION_FOR_ERRORS"))for(let t=0;t<r.length;t++){const n=r[t];n.data().then((t=>{ca(t,n.dtype,e)}))}return{kernelName:e,outputs:r,inputs:t,timeMs:s.then((e=>e.kernelMs)),extraInfo:s.then((e=>null!=e.getExtraProfileInfo?e.getExtraProfileInfo():""))}}logKernelProfile(e){const{kernelName:t,outputs:n,timeMs:r,inputs:a,extraInfo:s}=e;n.forEach((e=>{Promise.all([e.data(),r,s]).then((n=>{this.logger.logKernelProfile(t,e,n[0],n[1],a,n[2])}))}))}}function ca(e,t,n){if("float32"!==t)return!1;for(let t=0;t<e.length;t++){const r=e[t];if(isNaN(r)||!isFinite(r))return console.warn(`Found ${r} in the result of '${n}'`),!0}return!1}class da{logKernelProfile(e,t,n,r,a,s){const o="number"==typeof r?L(`${r}ms`,9):r.error,i=L(e,25),l=t.rank,u=t.size,c=L(t.shape.toString(),14);let d="";for(const e in a){const n=a[e];if(null!=n){const r=n.shape||t.shape,a=r.length;d+=`${e}: ${a}D ${a>0?r:""} `}}console.log(`%c${i}\t%c${o}\t%c${l}D ${c}\t%c${u}\t%c${d}\t%c${s}`,"font-weight:bold","color:red","color:blue","color: orange","color: green","color: steelblue")}}function ha(e,t,n,r){const a=oe(t),s=function(e,t,n,r){const a=R(t),s=r[r.length-1],o=new Array(s).fill(0),i=t.length,l="complex64"===n?ga(e):e;if(i>1)for(let e=0;e<a/s;e++){const t=e*s;for(let e=0;e<s;e++)o[e]=Math.max(o[e],pa(l[t+e],0,n).length)}return o}(e,t,n,a),o=t.length,i=ma(e,t,n,a,s),l=["Tensor"];return r&&(l.push(`  dtype: ${n}`),l.push(`  rank: ${o}`),l.push(`  shape: [${t}]`),l.push("  values:")),l.push(i.map((e=>"    "+e)).join("\n")),l.join("\n")}function pa(e,t,n){let r;return r=Array.isArray(e)?`${parseFloat(e[0].toFixed(7))} + ${parseFloat(e[1].toFixed(7))}j`:ee(e)?`'${e}'`:"bool"===n?fa(e):parseFloat(e.toFixed(7)).toString(),L(r,t)}function fa(e){return 0===e?"false":"true"}function ma(e,t,n,r,a,s=!0){const o="complex64"===n?2:1,i=t[0],l=t.length;if(0===l)return"complex64"===n?[pa(ga(e)[0],0,n)]:"bool"===n?[fa(e[0])]:[e[0].toString()];if(1===l){if(i>20){const t=3*o;let r=Array.from(e.slice(0,t)),s=Array.from(e.slice((i-3)*o,i*o));return"complex64"===n&&(r=ga(r),s=ga(s)),["["+r.map(((e,t)=>pa(e,a[t],n))).join(", ")+", ..., "+s.map(((e,t)=>pa(e,a[i-3+t],n))).join(", ")+"]"]}return["["+("complex64"===n?ga(e):Array.from(e)).map(((e,t)=>pa(e,a[t],n))).join(", ")+"]"]}const u=t.slice(1),c=r.slice(1),d=r[0]*o,h=[];if(i>20){for(let t=0;t<3;t++){const r=t*d,s=r+d;h.push(...ma(e.slice(r,s),u,n,c,a,!1))}h.push("...");for(let t=i-3;t<i;t++){const r=t*d,s=r+d;h.push(...ma(e.slice(r,s),u,n,c,a,t===i-1))}}else for(let t=0;t<i;t++){const r=t*d,s=r+d;h.push(...ma(e.slice(r,s),u,n,c,a,t===i-1))}const p=2===l?",":"";h[0]="["+h[0]+p;for(let e=1;e<h.length-1;e++)h[e]=" "+h[e]+p;let f=",\n";for(let e=2;e<l;e++)f+="\n";return h[h.length-1]=" "+h[h.length-1]+"]"+(s?"":f),h}function ga(e){const t=[];for(let n=0;n<e.length;n+=2)t.push([e[n],e[n+1]]);return t}class ba{constructor(e,t,n){if(this.dtype=t,this.shape=e.slice(),this.size=R(e),null!=n){const e=n.length;F(e===this.size,(()=>`Length of values '${e}' does not match the size inferred by the shape '${this.size}'.`))}if("complex64"===t)throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");this.values=n||V(t,this.size),this.strides=oe(e)}set(e,...t){0===t.length&&(t=[0]),F(t.length===this.rank,(()=>`The number of provided coordinates (${t.length}) must match the rank (${this.rank})`));const n=this.locToIndex(t);this.values[n]=e}get(...e){0===e.length&&(e=[0]);let t=0;for(const n of e){if(n<0||n>=this.shape[t]){const t=`Requested out of range element at ${e}.   Buffer shape=${this.shape}`;throw new Error(t)}t++}let n=e[e.length-1];for(let t=0;t<e.length-1;++t)n+=this.strides[t]*e[t];return this.values[n]}locToIndex(e){if(0===this.rank)return 0;if(1===this.rank)return e[0];let t=e[e.length-1];for(let n=0;n<e.length-1;++n)t+=this.strides[n]*e[n];return t}indexToLoc(e){if(0===this.rank)return[];if(1===this.rank)return[e];const t=new Array(this.shape.length);for(let n=0;n<t.length-1;++n)t[n]=Math.floor(e/this.strides[n]),e-=t[n]*this.strides[n];return t[t.length-1]=e,t}get rank(){return this.shape.length}toTensor(){return ka().makeTensor(this.values,this.shape,this.dtype)}}let ka=null,ya=null,wa=null;class Ia{constructor(e,t,n,r){this.kept=!1,this.isDisposedInternal=!1,this.shape=e.slice(),this.dtype=t||"float32",this.size=R(e),this.strides=oe(e),this.dataId=n,this.id=r,this.rankType=this.rank<5?this.rank.toString():"higher"}get rank(){return this.shape.length}async buffer(){const e=await this.data();return ya.buffer(this.shape,this.dtype,e)}bufferSync(){return ya.buffer(this.shape,this.dtype,this.dataSync())}async array(){const e=await this.data();return le(this.shape,e,"complex64"===this.dtype)}arraySync(){return le(this.shape,this.dataSync(),"complex64"===this.dtype)}async data(){this.throwIfDisposed();const e=ka().read(this.dataId);if("string"===this.dtype){const t=await e;try{return t.map((e=>la(e)))}catch(e){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}}return e}dataToGPU(e){return this.throwIfDisposed(),ka().readToGPU(this.dataId,e)}dataSync(){this.throwIfDisposed();const e=ka().readSync(this.dataId);if("string"===this.dtype)try{return e.map((e=>la(e)))}catch(e){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}return e}async bytes(){this.throwIfDisposed();const e=await ka().read(this.dataId);return"string"===this.dtype?e:new Uint8Array(e.buffer)}dispose(){this.isDisposed||(ka().disposeTensor(this),this.isDisposedInternal=!0)}get isDisposed(){return this.isDisposedInternal}throwIfDisposed(){if(this.isDisposed)throw new Error("Tensor is disposed.")}print(e=!1){return ya.print(this,e)}clone(){return this.throwIfDisposed(),ya.clone(this)}toString(e=!1){return ha(this.dataSync(),this.shape,this.dtype,e)}cast(e){return this.throwIfDisposed(),ya.cast(this,e)}variable(e=!0,t,n){return this.throwIfDisposed(),ka().makeVariable(this,e,t,n)}}Object.defineProperty(Ia,Symbol.hasInstance,{value:e=>!!e&&null!=e.data&&null!=e.dataSync&&null!=e.throwIfDisposed}),ve("Tensor",(()=>Ia));class va extends Ia{constructor(e,t,n,r){super(e.shape,e.dtype,e.dataId,r),this.trainable=t,this.name=n}assign(e){if(e.dtype!==this.dtype)throw new Error(`dtype of the new value (${e.dtype}) and previous value (${this.dtype}) must match`);if(!B(e.shape,this.shape))throw new Error(`shape of the new value (${e.shape}) and previous value (${this.shape}) must match`);ka().disposeTensor(this),this.dataId=e.dataId,ka().incRef(this,null)}dispose(){ka().disposeVariable(this),this.isDisposedInternal=!0}}var xa,Sa,Ea,Na,Ta;Object.defineProperty(va,Symbol.hasInstance,{value:e=>e instanceof Ia&&null!=e.assign&&e.assign instanceof Function}),function(e){e.R0="R0",e.R1="R1",e.R2="R2",e.R3="R3",e.R4="R4",e.R5="R5",e.R6="R6"}(xa||(xa={})),function(e){e.float32="float32",e.int32="int32",e.bool="int32",e.complex64="complex64"}(Sa||(Sa={})),function(e){e.float32="float32",e.int32="int32",e.bool="bool",e.complex64="complex64"}(Ea||(Ea={})),function(e){e.float32="float32",e.int32="float32",e.bool="float32",e.complex64="complex64"}(Na||(Na={})),function(e){e.float32="complex64",e.int32="complex64",e.bool="complex64",e.complex64="complex64"}(Ta||(Ta={}));const Aa={float32:Na,int32:Sa,bool:Ea,complex64:Ta};function Ma(e,t){if("string"===e||"string"===t){if("string"===e&&"string"===t)return"string";throw new Error(`Can not upcast ${e} with ${t}`)}return Aa[e][t]}function Fa(e){return Ma(e,"int32")}function $a(e,t){if(e.dtype===t.dtype)return[e,t];const n=Ma(e.dtype,t.dtype);return[e.cast(n),t.cast(n)]}function Da(e,t){F(e.dtype===t.dtype,(()=>`The dtypes of the first(${e.dtype}) and second(${t.dtype}) input must match`))}function _a(e,t){return t.some((t=>t.id===e.id))}function Ra(e){const t=[];return Ca(e,t,new Set),t}function Ca(e,t,n){if(null==e)return;if(e instanceof Ia)return void t.push(e);if(r=e,!Array.isArray(r)&&"object"!=typeof r)return;var r;const a=e;for(const e in a){const r=a[e];n.has(r)||(n.add(r),Ca(r,t,n))}}function Ba(e){return null!=e.kernelName}class Pa{constructor(){this.registeredVariables={},this.nextTapeNodeId=0,this.numBytes=0,this.numTensors=0,this.numStringTensors=0,this.numDataBuffers=0,this.gradientDepth=0,this.kernelDepth=0,this.scopeStack=[],this.numDataMovesStack=[],this.nextScopeId=0,this.tensorInfo=new WeakMap,this.profiling=!1,this.activeProfile={newBytes:0,newTensors:0,peakBytes:0,kernels:[],result:null,get kernelNames(){return Array.from(new Set(this.kernels.map((e=>e.name))))}}}dispose(){for(const e in this.registeredVariables)this.registeredVariables[e].dispose()}}class za{constructor(e){this.ENV=e,this.registry={},this.registryFactory={},this.pendingBackendInitId=0,this.state=new Pa}async ready(){if(null!=this.pendingBackendInit)return this.pendingBackendInit.then((()=>{}));if(null!=this.backendInstance)return;const e=this.getSortedBackends();for(let t=0;t<e.length;t++){const n=e[t];if(await this.initializeBackend(n).success)return void await this.setBackend(n)}throw new Error("Could not initialize any backends, all backend initializations failed.")}get backend(){if(null!=this.pendingBackendInit)throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);if(null==this.backendInstance){const{name:e,asyncInit:t}=this.initializeBackendsAndReturnBest();if(t)throw new Error(`The highest priority backend '${e}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);this.setBackend(e)}return this.backendInstance}backendNames(){return Object.keys(this.registryFactory)}findBackend(e){if(!(e in this.registry)){if(!(e in this.registryFactory))return null;{const{asyncInit:t}=this.initializeBackend(e);if(t)return null}}return this.registry[e]}findBackendFactory(e){return e in this.registryFactory?this.registryFactory[e].factory:null}registerBackend(e,t,n=1){return e in this.registryFactory?(Fr(`${e} backend was already registered. Reusing existing backend factory.`),!1):(this.registryFactory[e]={factory:t,priority:n},!0)}async setBackend(e){if(null==this.registryFactory[e])throw new Error(`Backend name '${e}' not found in registry`);if(this.backendName=e,null==this.registry[e]){this.backendInstance=null;const{success:t,asyncInit:n}=this.initializeBackend(e);if(!(n?await t:t))return!1}return this.backendInstance=this.registry[e],this.setupRegisteredKernels(),this.profiler=new ua(this.backendInstance),!0}setupRegisteredKernels(){Br(this.backendName).forEach((e=>{null!=e.setupFunc&&e.setupFunc(this.backendInstance)}))}disposeRegisteredKernels(e){Br(e).forEach((t=>{null!=t.disposeFunc&&t.disposeFunc(this.registry[e])}))}initializeBackend(e){const t=this.registryFactory[e];if(null==t)throw new Error(`Cannot initialize backend ${e}, no registration found.`);try{const n=t.factory();if(!n||n instanceof w||"function"!=typeof n.then)return this.registry[e]=n,{success:!0,asyncInit:!1};{const t=++this.pendingBackendInitId,r=n.then((n=>!(t<this.pendingBackendInitId||(this.registry[e]=n,this.pendingBackendInit=null,0)))).catch((n=>(t<this.pendingBackendInitId||(this.pendingBackendInit=null,Fr(`Initialization of backend ${e} failed`),Fr(n.stack||n.message)),!1)));return this.pendingBackendInit=r,{success:r,asyncInit:!0}}}catch(t){return Fr(`Initialization of backend ${e} failed`),Fr(t.stack||t.message),{success:!1,asyncInit:!1}}}removeBackend(e){if(!(e in this.registryFactory))throw new Error(`${e} backend not found in registry`);this.backendName===e&&null!=this.pendingBackendInit&&this.pendingBackendInitId++,e in this.registry&&(this.disposeRegisteredKernels(e),this.registry[e].dispose(),delete this.registry[e]),delete this.registryFactory[e],this.backendName===e&&(this.pendingBackendInit=null,this.backendName=null,this.backendInstance=null)}getSortedBackends(){if(0===Object.keys(this.registryFactory).length)throw new Error("No backend found in registry.");return Object.keys(this.registryFactory).sort(((e,t)=>this.registryFactory[t].priority-this.registryFactory[e].priority))}initializeBackendsAndReturnBest(){const e=this.getSortedBackends();for(let t=0;t<e.length;t++){const n=e[t],{success:r,asyncInit:a}=this.initializeBackend(n);if(a||r)return{name:n,asyncInit:a}}throw new Error("Could not initialize any backends, all backend initializations failed.")}moveData(e,t){const n=this.state.tensorInfo.get(t),r=n.backend,a=this.readSync(t),s=r.refCount(t);r.disposeData(t,!0),n.backend=e,e.move(t,a,n.shape,n.dtype,s),this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack[this.state.numDataMovesStack.length-1]++}tidy(e,t){let n,r=null;if(null==t){if("function"!=typeof e)throw new Error("Please provide a function to tidy()");t=e}else{if("string"!=typeof e&&!(e instanceof String))throw new Error("When calling with two arguments, the first argument to tidy() must be a string");if("function"!=typeof t)throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");r=e}return this.scopedRun((()=>this.startScope(r)),(()=>this.endScope(n)),(()=>(n=t(),n instanceof Promise&&console.error("Cannot return a Promise inside of tidy."),n)))}scopedRun(e,t,n){e();try{const e=n();return t(),e}catch(e){throw t(),e}}nextTensorId(){return za.nextTensorId++}nextVariableId(){return za.nextVariableId++}clone(e){const t=Oa.runKernel(Pt,{x:e}),n={x:e};return this.addTapeNode(this.state.activeScope.name,n,[t],(e=>({x:()=>{const t={x:e};return Oa.runKernel(Ue,t,{dtype:"float32"})}})),[],{}),t}runKernel(e,t,n){if(null==this.backendName&&this.backend,null==Rr(e,this.backendName))throw new Error(`Kernel '${e}' not registered for backend '${this.backendName}'`);return this.runKernelFunc({kernelName:e,inputs:t,attrs:n})}shouldCheckForMemLeaks(){return this.ENV.getBool("IS_TEST")}checkKernelForMemLeak(e,t,n){const r=this.backend.numDataIds();let a=0;n.forEach((e=>{a+="complex64"===e.dtype?3:1}));const s=this.state.numDataMovesStack[this.state.numDataMovesStack.length-1],o=r-t-a-s;if(o>0)throw new Error(`Backend '${this.backendName}' has an internal memory leak (${o} data ids) after running '${e}'`)}runKernelFunc(e){let t,n=[];const r=this.isTapeOn(),a=this.state.numBytes,s=this.state.numTensors;let o,i;this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack.push(0),null==this.backendName&&this.backend;const l=Ba(e)?e.kernelName:null!=this.state.activeScope?this.state.activeScope.name:"";if(Ba(e)){const{kernelName:t,inputs:a,attrs:s}=e;null==this.backendName&&this.backend;const l=Rr(t,this.backendName);F(null!=l,(()=>`Cannot find registered kernel '${t}' for backend '${this.backendName}'`)),o=()=>{const e=this.backend.numDataIds();i=l.kernelFunc({inputs:a,attrs:s,backend:this.backend});const o=Array.isArray(i)?i:[i];this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(t,e,o);const u=o.map((e=>{if(null!=e.rank)return e;const{dataId:t,shape:n,dtype:r}=e;return this.makeTensorFromDataId(t,n,r)}));if(r){const e=this.getTensorsForGradient(t,a,u);n=this.saveTensorsForBackwardMode(e)}return u}}else{const{forwardFunc:t}=e,a=e=>{r&&(n=e.map((e=>this.keep(this.clone(e)))))};o=()=>{const e=this.backend.numDataIds();i=this.tidy((()=>t(this.backend,a)));const n=Array.isArray(i)?i:[i];return this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(l,e,n),n}}const{inputs:u,attrs:c}=e,d=Ba(e)?null:e.backwardsFunc;let h;return this.scopedRun((()=>this.state.kernelDepth++),(()=>this.state.kernelDepth--),(()=>{this.ENV.getBool("DEBUG")||this.state.profiling?(h=this.profiler.profileKernel(l,u,(()=>o())),this.ENV.getBool("DEBUG")&&this.profiler.logKernelProfile(h),t=h.outputs):t=o()})),r&&this.addTapeNode(l,u,t,d,n,c),this.state.profiling&&this.state.activeProfile.kernels.push({name:l,bytesAdded:this.state.numBytes-a,totalBytesSnapshot:this.state.numBytes,tensorsAdded:this.state.numTensors-s,totalTensorsSnapshot:this.state.numTensors,inputShapes:Object.keys(u).map((e=>null!=u[e]?u[e].shape:null)),outputShapes:t.map((e=>e.shape)),kernelTimeMs:h.timeMs,extraInfo:h.extraInfo}),Array.isArray(i)?t:t[0]}saveTensorsForBackwardMode(e){const t=e.map((e=>this.keep(this.clone(e))));return t}getTensorsForGradient(e,t,n){const r=Cr(e);if(null!=r){const e=r.inputsToSave||[],a=r.outputsToSave||[];let s;r.saveAllInputs?(F(Array.isArray(t),(()=>"saveAllInputs is true, expected inputs to be an array.")),s=Object.keys(t).map((e=>t[e]))):s=e.map((e=>t[e]));const o=n.filter(((e,t)=>a[t]));return s.concat(o)}return[]}makeTensor(e,t,n,r){if(null==e)throw new Error("Values passed to engine.makeTensor() are null");n=n||"float32",r=r||this.backend;let a=e;"string"===n&&ee(e[0])&&(a=e.map((e=>ia(e))));const s=r.write(a,t,n),o=new Ia(t,n,s,this.nextTensorId());if(this.trackTensor(o,r),"string"===n){const e=this.state.tensorInfo.get(s),t=Q(a);this.state.numBytes+=t-e.bytes,e.bytes=t}return o}makeTensorFromDataId(e,t,n,r){const a=new Ia(t,n=n||"float32",e,this.nextTensorId());return this.trackTensor(a,r),a}makeVariable(e,t=!0,n,r){n=n||this.nextVariableId().toString(),null!=r&&r!==e.dtype&&(e=e.cast(r));const a=new va(e,t,n,this.nextTensorId());if(null!=this.state.registeredVariables[a.name])throw new Error(`Variable with name ${a.name} was already registered`);return this.state.registeredVariables[a.name]=a,this.incRef(a,this.backend),a}trackTensor(e,t){this.state.numTensors++,"string"===e.dtype&&this.state.numStringTensors++;let n=0;"complex64"!==e.dtype&&"string"!==e.dtype&&(n=e.size*X(e.dtype)),this.state.numBytes+=n,this.state.tensorInfo.has(e.dataId)||(this.state.numDataBuffers++,this.state.tensorInfo.set(e.dataId,{backend:t||this.backend,dtype:e.dtype,shape:e.shape,bytes:n})),e instanceof va||this.track(e)}incRef(e,t){this.trackTensor(e,t),this.backend.incRef(e.dataId)}removeDataId(e,t){this.state.tensorInfo.has(e)&&this.state.tensorInfo.get(e).backend===t&&(this.state.tensorInfo.delete(e),this.state.numDataBuffers--)}disposeTensor(e){if(!this.state.tensorInfo.has(e.dataId))return;const t=this.state.tensorInfo.get(e.dataId);if(this.state.numTensors--,"string"===e.dtype&&(this.state.numStringTensors--,this.state.numBytes-=t.bytes),"complex64"!==e.dtype&&"string"!==e.dtype){const t=e.size*X(e.dtype);this.state.numBytes-=t}t.backend.disposeData(e.dataId)&&this.removeDataId(e.dataId,t.backend)}disposeVariables(){for(const e in this.state.registeredVariables){const t=this.state.registeredVariables[e];this.disposeVariable(t)}}disposeVariable(e){this.disposeTensor(e),null!=this.state.registeredVariables[e.name]&&delete this.state.registeredVariables[e.name]}memory(){const e=this.backend.memory();return e.numTensors=this.state.numTensors,e.numDataBuffers=this.state.numDataBuffers,e.numBytes=this.state.numBytes,this.state.numStringTensors>0&&(e.unreliable=!0,null==e.reasons&&(e.reasons=[]),e.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")),e}async profile(e){this.state.profiling=!0;const t=this.state.numBytes,n=this.state.numTensors;this.state.activeProfile.kernels=[],this.state.activeProfile.result=await e(),this.state.profiling=!1,this.state.activeProfile.peakBytes=Math.max(...this.state.activeProfile.kernels.map((e=>e.totalBytesSnapshot))),this.state.activeProfile.newBytes=this.state.numBytes-t,this.state.activeProfile.newTensors=this.state.numTensors-n;for(const e of this.state.activeProfile.kernels)e.kernelTimeMs=await e.kernelTimeMs,e.extraInfo=await e.extraInfo;return this.state.activeProfile}isTapeOn(){return this.state.gradientDepth>0&&0===this.state.kernelDepth}addTapeNode(e,t,n,r,a,s){const o={id:this.state.nextTapeNodeId++,kernelName:e,inputs:t,outputs:n,saved:a},i=Cr(e);null!=i&&(r=i.gradFunc),null!=r&&(o.gradient=e=>(e=e.map(((e,t)=>{if(null==e){const e=n[t],r=ce(e.size,e.dtype);return this.makeTensor(r,e.shape,e.dtype)}return e})),r(e.length>1?e:e[0],a,s))),this.state.activeTape.push(o)}keep(e){return e.kept=!0,e}startTape(){0===this.state.gradientDepth&&(this.state.activeTape=[]),this.state.gradientDepth++}endTape(){this.state.gradientDepth--}startScope(e){const t={track:[],name:"unnamed scope",id:this.state.nextScopeId++};e&&(t.name=e),this.state.scopeStack.push(t),this.state.activeScope=t}endScope(e){const t=Ra(e),n=new Set(t.map((e=>e.id)));for(let e=0;e<this.state.activeScope.track.length;e++){const t=this.state.activeScope.track[e];t.kept||n.has(t.id)||t.dispose()}const r=this.state.scopeStack.pop();this.state.activeScope=0===this.state.scopeStack.length?null:this.state.scopeStack[this.state.scopeStack.length-1],t.forEach((e=>{e.kept||e.scopeId!==r.id||this.track(e)}))}gradients(e,t,n,r=!1){if(F(t.length>0,(()=>"gradients() received an empty list of xs.")),null!=n&&"float32"!==n.dtype)throw new Error(`dy must have 'float32' dtype, but has '${n.dtype}'`);const a=this.scopedRun((()=>this.startTape()),(()=>this.endTape()),(()=>this.tidy("forward",e)));F(a instanceof Ia,(()=>"The result y returned by f() must be a tensor."));const s=function(e,t,n){const r={},a={};for(let e=0;e<t.length;e++)r[t[e].id]=!0;for(let n=0;n<e.length;n++){const s=e[n],o=s.inputs;for(const e in o){const n=o[e];let i=!1;for(let e=0;e<t.length;e++)if(r[n.id]){s.outputs.forEach((e=>r[e.id]=!0)),i=!0,a[s.id]=!0;break}if(i)break}}const s={};s[n.id]=!0;const o={};for(let t=e.length-1;t>=0;t--){const n=e[t],r=n.inputs;for(let e=0;e<n.outputs.length;e++)if(s[n.outputs[e].id]){for(const e in r)s[r[e].id]=!0,o[n.id]=!0;break}}const i=[];for(let t=0;t<e.length;t++){const n=e[t];if(a[n.id]&&o[n.id]){const e={};for(const t in n.inputs){const a=n.inputs[t];r[a.id]&&(e[t]=a)}const t=Object.assign({},n);t.inputs=e,t.outputs=n.outputs,i.push(t)}}return i}(this.state.activeTape,t,a);if(!r&&0===s.length&&t.length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");return this.tidy("backward",(()=>{const e={};e[a.id]=null==n?function(e){const t=ue(R(e),"float32");return Oa.makeTensor(t,e,"float32")}(a.shape):n,function(e,t,n,r){for(let a=t.length-1;a>=0;a--){const s=t[a],o=[];if(s.outputs.forEach((t=>{const n=e[t.id];null!=n?o.push(n):o.push(null)})),null==s.gradient)throw new Error(`Cannot compute gradient: gradient function not found for ${s.kernelName}.`);const i=s.gradient(o);for(const t in s.inputs){if(!(t in i))throw new Error(`Cannot backprop through input ${t}. Available gradients found: ${Object.keys(i)}.`);const a=n((()=>i[t]()));if("float32"!==a.dtype)throw new Error(`Error in gradient for op ${s.kernelName}. The gradient of input ${t} must have 'float32' dtype, but has '${a.dtype}'`);const o=s.inputs[t];if(!B(a.shape,o.shape))throw new Error(`Error in gradient for op ${s.kernelName}. The gradient of input '${t}' has shape '${a.shape}', which does not match the shape of the input '${o.shape}'`);if(null==e[o.id])e[o.id]=a;else{const t=e[o.id];e[o.id]=r(t,a),t.dispose()}}}}(e,s,(e=>this.tidy(e)),La);const r=t.map((t=>e[t.id]));return 0===this.state.gradientDepth&&(this.state.activeTape.forEach((e=>{for(const t of e.saved)t.dispose()})),this.state.activeTape=null),{value:a,grads:r}}))}customGrad(e){return F(ae(e),(()=>"The f passed in customGrad(f) must be a function.")),(...t)=>{let n;F(t.every((e=>e instanceof Ia)),(()=>"The args passed in customGrad(f)(x1, x2,...) must all be tensors"));const r={};return t.forEach(((e,t)=>{r[t]=e})),this.runKernelFunc({forwardFunc:(r,a)=>(n=e(...t,a),F(n.value instanceof Ia,(()=>"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor")),F(ae(n.gradFunc),(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.")),n.value),backwardsFunc:(e,r)=>{const a=n.gradFunc(e,r),s=Array.isArray(a)?a:[a];F(s.length===t.length,(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).")),F(s.every((e=>e instanceof Ia)),(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors."));const o={};return s.forEach(((e,t)=>{o[t]=()=>e})),o},inputs:r})}}readSync(e){return this.state.tensorInfo.get(e).backend.readSync(e)}read(e){return this.state.tensorInfo.get(e).backend.read(e)}readToGPU(e,t){return this.state.tensorInfo.get(e).backend.readToGPU(e,t)}async time(e){const t=sa(),n=await this.backend.time(e);return n.wallMs=sa()-t,n}track(e){return null!=this.state.activeScope&&(e.scopeId=this.state.activeScope.id,this.state.activeScope.track.push(e)),e}get registeredVariables(){return this.state.registeredVariables}reset(){this.pendingBackendInitId++,this.state.dispose(),this.ENV.reset(),this.state=new Pa;for(const e in this.registry)this.disposeRegisteredKernels(e),this.registry[e].dispose(),delete this.registry[e];this.backendName=null,this.backendInstance=null,this.pendingBackendInit=null}}function Wa(){const e=Ie();if(null==e._tfengine){const t=new ge(e);e._tfengine=new za(t)}var t;return t=e._tfengine.ENV,we=t,ka=()=>e._tfengine,e._tfengine}za.nextTensorId=0,za.nextVariableId=0;const Oa=Wa();function La(e,t){const n={a:e,b:t};return Oa.runKernel(Ne,n)}let Ha;function Ga(e){Ha=e}function Ka(e){if(void 0!==Ha)return Ha;if(e||"undefined"!=typeof navigator&&null!=navigator){if(e||(e=navigator),"ReactNative"===e.product)return!0;const t=e.userAgent||e.vendor||("undefined"!=typeof window?window.opera:"");if(!t){const t=e;return t.userAgentData&&t.userAgentData.mobile}return/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0,4))}return!1}function qa(){return"undefined"!=typeof window&&null!=window.document||"undefined"!=typeof WorkerGlobalScope}const Ua=ke();function Va(e,t){let n=e;if(Y(e))return"string"===t?[]:[e.length];if(!Array.isArray(e))return[];const r=[];for(;Array.isArray(n)||Y(n)&&"string"!==t;)r.push(n.length),n=n[0];return Array.isArray(e)&&ke().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")&&ja(e,r,[]),r}function ja(e,t,n){if(n=n||[],!Array.isArray(e)&&!Y(e))return void F(0===t.length,(()=>`Element arr[${n.join("][")}] is a primitive, but should be an array/TypedArray of ${t[0]} elements`));F(t.length>0,(()=>`Element arr[${n.join("][")}] should be a primitive, but is an array of ${e.length} elements`)),F(e.length===t[0],(()=>`Element arr[${n.join("][")}] should have ${t[0]} elements, but has ${e.length} elements`));const r=t.slice(1);for(let t=0;t<e.length;++t)ja(e[t],r,n.concat(t))}function Za(e,t,n,r){if("string_or_numeric"!==e){if(null==e)throw new Error("Expected dtype cannot be null.");if("numeric"!==e&&e!==t||"numeric"===e&&"string"===t)throw new Error(`Argument '${n}' passed to '${r}' must be ${e} tensor, but got ${t} tensor`)}}function Ja(e,t,n,r="numeric"){if(e instanceof Ia)return Za(r,e.dtype,t,n),e;let a=re(e);if("string"!==a&&["bool","int32","float32"].indexOf(r)>=0&&(a=r),Za(r,a,t,n),null==e||!Y(e)&&!Array.isArray(e)&&"number"!=typeof e&&"boolean"!=typeof e&&"string"!=typeof e){const r=null==e?"null":e.constructor.name;throw new Error(`Argument '${t}' passed to '${n}' must be a Tensor or TensorLike, but got '${r}'`)}const s=Va(e,a);Y(e)||Array.isArray(e)||(e=[e]);const o="string"!==a?aa(e,a):_(e,[],!0);return Oa.makeTensor(o,s,a)}function Ya(e,t,n,r="numeric"){if(!Array.isArray(e))throw new Error(`Argument ${t} passed to ${n} must be a \`Tensor[]\` or \`TensorLike[]\``);return e.map(((e,a)=>Ja(e,`${t}[${a}]`,n,r)))}Ua.registerFlag("DEBUG",(()=>!1),(e=>{e&&console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.")})),Ua.registerFlag("IS_BROWSER",(()=>qa())),Ua.registerFlag("IS_NODE",(()=>"undefined"!=typeof process&&void 0!==process.versions&&void 0!==process.versions.node)),Ua.registerFlag("IS_CHROME",(()=>"undefined"!=typeof navigator&&null!=navigator&&null!=navigator.userAgent&&/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor))),Ua.registerFlag("PROD",(()=>!1)),Ua.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY",(()=>Ua.getBool("DEBUG"))),Ua.registerFlag("DEPRECATION_WARNINGS_ENABLED",(()=>!0)),Ua.registerFlag("IS_TEST",(()=>!1)),Ua.registerFlag("CHECK_COMPUTATION_FOR_ERRORS",(()=>!0)),Ua.registerFlag("WRAP_TO_IMAGEBITMAP",(()=>!1)),Ua.registerFlag("ENGINE_COMPILE_ONLY",(()=>!1));const Xa="__op";function Qa(e){const t=Object.keys(e);if(1!==t.length)throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${t.length} keys.`);let n=t[0];const r=e[n];n.endsWith("_")&&(n=n.substring(0,n.length-1)),n+=Xa;const a=(...e)=>{Oa.startScope(n);try{const t=r(...e);return me(t)&&console.error("Cannot return a Promise inside of tidy."),Oa.endScope(t),t}catch(e){throw Oa.endScope(null),e}};return Object.defineProperty(a,"name",{value:n,configurable:!0}),a}const es=Qa({complex_:function(e,t){const n=Ja(e,"real","complex"),r=Ja(t,"imag","complex");$(n.shape,r.shape,`real and imag shapes, ${n.shape} and ${r.shape}, must match in call to tf.complex().`);const a={real:n,imag:r};return Oa.runKernel(Ze,a)}});function ts(e,t,n,r){if(null==r&&(r=re(e)),"complex64"===r)throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");if(!Y(e)&&!Array.isArray(e)&&"number"!=typeof e&&"boolean"!=typeof e&&"string"!=typeof e)throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");if(null!=t){he(t);const e=R(t),r=R(n);F(e===r,(()=>`Based on the provided shape, [${t}], the tensor should have ${e} values but has ${r}`));for(let e=0;e<n.length;++e){const r=n[e],a=e!==n.length-1||r!==R(t.slice(e));F(n[e]===t[e]||!a,(()=>`Error creating a new Tensor. Inferred shape (${n}) does not match the provided shape (${t}). `))}}return Y(e)||Array.isArray(e)||(e=[e]),t=t||n,e="string"!==r?aa(e,r):_(e,[],!0),Oa.makeTensor(e,t,r)}function ns(e,t,n){return ts(e,t,Va(e,n),n)}const rs={float32:4,float16:2,int32:4,uint16:2,uint8:1,bool:1,complex64:8};async function as(e,t){const n=[],r=[],a=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);for(let s=0;s<a.length;++s){const o=a[s],i=Array.isArray(e)?e[s].tensor:e[o];if("float32"!==i.dtype&&"int32"!==i.dtype&&"bool"!==i.dtype&&"string"!==i.dtype&&"complex64"!==i.dtype)throw new Error(`Unsupported dtype in weight '${o}': ${i.dtype}`);const l={name:o,shape:i.shape,dtype:i.dtype};if("string"===i.dtype){const e=new Promise((async e=>{const t=await i.bytes(),n=t.reduce(((e,t)=>e+t.length),0)+4*t.length,r=new Uint8Array(n);let a=0;for(let e=0;e<t.length;e++){const n=t[e],s=new Uint8Array(new Uint32Array([n.length]).buffer);r.set(s,a),a+=4,r.set(n,a),a+=n.length}e(r)}));r.push(e)}else r.push(i.data());null!=t&&(l.group=t),n.push(l)}return{data:os(await Promise.all(r)),specs:n}}function ss(e,t){const n={};let r,a=0;for(const s of t){const t=s.name,o=s.dtype,i=s.shape,l=R(i);let u;if("quantization"in s){const n=s.quantization;if("uint8"===n.dtype||"uint16"===n.dtype){if(!("min"in n)||!("scale"in n))throw new Error(`Weight ${s.name} with quantization ${n.dtype} doesn't have corresponding metadata min and scale.`)}else{if("float16"!==n.dtype)throw new Error(`Weight ${s.name} has unknown quantization dtype ${n.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);if("float32"!==o)throw new Error(`Weight ${s.name} is quantized with ${n.dtype} which only supports weights of type float32 not ${o}.`)}const i=rs[n.dtype],c=e.slice(a,a+l*i),d="uint8"===n.dtype?new Uint8Array(c):new Uint16Array(c);if("float32"===o)if("uint8"===n.dtype||"uint16"===n.dtype){u=new Float32Array(d.length);for(let e=0;e<d.length;e++){const t=d[e];u[e]=t*n.scale+n.min}}else{if("float16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type float32.`);void 0===r&&(r=fs()),u=r(d)}else{if("int32"!==o)throw new Error(`Unsupported dtype in weight '${t}': ${o}`);if("uint8"!==n.dtype&&"uint16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type int32.`);u=new Int32Array(d.length);for(let e=0;e<d.length;e++){const t=d[e];u[e]=Math.round(t*n.scale+n.min)}}a+=l*i}else if("string"===o){const t=R(s.shape);u=[];for(let n=0;n<t;n++){const t=new Uint32Array(e.slice(a,a+4))[0];a+=4;const n=new Uint8Array(e.slice(a,a+t));u.push(n),a+=t}}else{const r=rs[o],s=e.slice(a,a+l*r);if("float32"===o)u=new Float32Array(s);else if("int32"===o)u=new Int32Array(s);else if("bool"===o)u=new Uint8Array(s);else{if("complex64"!==o)throw new Error(`Unsupported dtype in weight '${t}': ${o}`);{u=new Float32Array(s);const e=new Float32Array(u.length/2),r=new Float32Array(u.length/2);for(let t=0;t<e.length;t++)e[t]=u[2*t],r[t]=u[2*t+1];const a=ns(e,i,"float32"),o=ns(r,i,"float32");n[t]=es(a,o),a.dispose(),o.dispose()}}a+=l*r}"complex64"!==o&&(n[t]=ns(u,i,o))}return n}function os(e){if(null===e)throw new Error(`Invalid input value: ${JSON.stringify(e)}`);let t=0;const n=[];e.forEach((e=>{if(t+=e.byteLength,n.push(e.byteLength===e.buffer.byteLength?e:new e.constructor(e)),!(e instanceof Float32Array||e instanceof Int32Array||e instanceof Uint8Array))throw new Error(`Unsupported TypedArray subtype: ${e.constructor.name}`)}));const r=new Uint8Array(t);let a=0;return n.forEach((e=>{r.set(new Uint8Array(e.buffer),a),a+=e.byteLength})),r.buffer}const is="undefined"!=typeof Buffer&&("undefined"==typeof Blob||"undefined"==typeof atob||"undefined"==typeof btoa);function ls(e){return is?Buffer.byteLength(e):new Blob([e]).size}function us(e){if(1===e.length)return e[0];let t=0;e.forEach((e=>{t+=e.byteLength}));const n=new Uint8Array(t);let r=0;return e.forEach((e=>{n.set(new Uint8Array(e),r),r+=e.byteLength})),n.buffer}function cs(e){for(e=e.trim();e.endsWith("/");)e=e.slice(0,e.length-1);const t=e.split("/");return t[t.length-1]}function ds(e,t){const n={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,weightsManifest:t};return null!=e.signature&&(n.signature=e.signature),null!=e.userDefinedMetadata&&(n.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(n.modelInitializer=e.modelInitializer),null!=e.trainingConfig&&(n.trainingConfig=e.trainingConfig),n}async function hs(e,t){const n={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy};if(null!=e.trainingConfig&&(n.trainingConfig=e.trainingConfig),null!=e.weightsManifest){const[r,a]=await t(e.weightsManifest);n.weightSpecs=r,n.weightData=a}return null!=e.signature&&(n.signature=e.signature),null!=e.userDefinedMetadata&&(n.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(n.modelInitializer=e.modelInitializer),n}function ps(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("Expected JSON model topology, received ArrayBuffer.");return{dateSaved:new Date,modelTopologyType:"JSON",modelTopologyBytes:null==e.modelTopology?0:ls(JSON.stringify(e.modelTopology)),weightSpecsBytes:null==e.weightSpecs?0:ls(JSON.stringify(e.weightSpecs)),weightDataBytes:null==e.weightData?0:e.weightData.byteLength}}function fs(){const e=function(){const e=e=>{let t=e<<13,n=0;for(;0==(8388608&t);)n-=8388608,t<<=1;return t&=-8388609,n+=947912704,t|n},t=new Uint32Array(2048);t[0]=0;for(let n=1;n<1024;n++)t[n]=e(n);for(let e=1024;e<2048;e++)t[e]=939524096+(e-1024<<13);return t}(),t=function(){const e=new Uint32Array(64);e[0]=0,e[31]=1199570944,e[32]=2147483648,e[63]=3347054592;for(let t=1;t<31;t++)e[t]=t<<23;for(let t=33;t<63;t++)e[t]=2147483648+(t-32<<23);return e}(),n=function(){const e=new Uint32Array(64);for(let t=0;t<64;t++)e[t]=1024;return e[0]=e[32]=0,e}();return r=>{const a=new ArrayBuffer(4*r.length),s=new Uint32Array(a);for(let a=0;a<r.length;a++){const o=r[a],i=e[n[o>>10]+(1023&o)]+t[o>>10];s[a]=i}return new Float32Array(a)}}class ms{constructor(){this.saveRouters=[],this.loadRouters=[]}static getInstance(){return null==ms.instance&&(ms.instance=new ms),ms.instance}static registerSaveRouter(e){ms.getInstance().saveRouters.push(e)}static registerLoadRouter(e){ms.getInstance().loadRouters.push(e)}static getSaveHandlers(e){return ms.getHandlers(e,"save")}static getLoadHandlers(e,t){return ms.getHandlers(e,"load",t)}static getHandlers(e,t,n){const r=[];return("load"===t?ms.getInstance().loadRouters:ms.getInstance().saveRouters).forEach((t=>{const a=t(e,n);null!==a&&r.push(a)})),r}}const gs=e=>ms.registerSaveRouter(e),bs=e=>ms.registerLoadRouter(e),ks=e=>ms.getSaveHandlers(e),ys=(e,t)=>ms.getLoadHandlers(e,t),ws="tensorflowjs",Is="models_store",vs="model_info_store";function xs(){if(!ke().getBool("IS_BROWSER"))throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");const e="undefined"==typeof window?self:window,t=e.indexedDB||e.mozIndexedDB||e.webkitIndexedDB||e.msIndexedDB||e.shimIndexedDB;if(null==t)throw new Error("The current browser does not appear to support IndexedDB.");return t}function Ss(e){const t=e.result;t.createObjectStore(Is,{keyPath:"modelPath"}),t.createObjectStore(vs,{keyPath:"modelPath"})}class Es{constructor(e){if(this.indexedDB=xs(),null==e||!e)throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");this.modelPath=e}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");return this.databaseAction(this.modelPath,e)}async load(){return this.databaseAction(this.modelPath)}databaseAction(e,t){return new Promise(((e,n)=>{const r=this.indexedDB.open(ws,1);r.onupgradeneeded=()=>Ss(r),r.onsuccess=()=>{const a=r.result;if(null==t){const t=a.transaction(Is,"readonly"),r=t.objectStore(Is).get(this.modelPath);r.onsuccess=()=>{if(null==r.result)return a.close(),n(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));e(r.result.modelArtifacts)},r.onerror=e=>(a.close(),n(r.error)),t.oncomplete=()=>a.close()}else{const r=ps(t),s=a.transaction(vs,"readwrite");let o=s.objectStore(vs);const i=o.put({modelPath:this.modelPath,modelArtifactsInfo:r});let l;i.onsuccess=()=>{l=a.transaction(Is,"readwrite");const i=l.objectStore(Is).put({modelPath:this.modelPath,modelArtifacts:t,modelArtifactsInfo:r});i.onsuccess=()=>e({modelArtifactsInfo:r}),i.onerror=e=>{o=s.objectStore(vs);const t=o.delete(this.modelPath);t.onsuccess=()=>(a.close(),n(i.error)),t.onerror=e=>(a.close(),n(i.error))}},i.onerror=e=>(a.close(),n(i.error)),s.oncomplete=()=>{null==l?a.close():l.oncomplete=()=>a.close()}}},r.onerror=e=>n(r.error)}))}}Es.URL_SCHEME="indexeddb://";const Ns=e=>{return ke().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(Es.URL_SCHEME)?(t=e.slice(Es.URL_SCHEME.length),new Es(t)):null;var t};ms.registerSaveRouter(Ns),ms.registerLoadRouter(Ns);class Ts{constructor(){this.indexedDB=xs()}async listModels(){return new Promise(((e,t)=>{const n=this.indexedDB.open(ws,1);n.onupgradeneeded=()=>Ss(n),n.onsuccess=()=>{const r=n.result,a=r.transaction(vs,"readonly"),s=a.objectStore(vs).getAll();s.onsuccess=()=>{const t={};for(const e of s.result)t[e.modelPath]=e.modelArtifactsInfo;e(t)},s.onerror=e=>(r.close(),t(s.error)),a.oncomplete=()=>r.close()},n.onerror=e=>t(n.error)}))}async removeModel(e){var t;return e=(t=e).startsWith(Es.URL_SCHEME)?t.slice(Es.URL_SCHEME.length):t,new Promise(((t,n)=>{const r=this.indexedDB.open(ws,1);r.onupgradeneeded=()=>Ss(r),r.onsuccess=()=>{const a=r.result,s=a.transaction(vs,"readwrite"),o=s.objectStore(vs),i=o.get(e);let l;i.onsuccess=()=>{if(null==i.result)return a.close(),n(new Error(`Cannot find model with path '${e}' in IndexedDB.`));{const r=o.delete(e),s=()=>{l=a.transaction(Is,"readwrite");const r=l.objectStore(Is).delete(e);r.onsuccess=()=>t(i.result.modelArtifactsInfo),r.onerror=e=>n(i.error)};r.onsuccess=s,r.onerror=e=>(s(),a.close(),n(i.error))}},i.onerror=e=>(a.close(),n(i.error)),s.oncomplete=()=>{null==l?a.close():l.oncomplete=()=>a.close()}},r.onerror=e=>n(r.error)}))}}const As="/",Ms="tensorflowjs_models",Fs="info",$s="model_topology",Ds="weight_specs",_s="weight_data",Rs="model_metadata";function Cs(e){return{info:[Ms,e,Fs].join(As),topology:[Ms,e,$s].join(As),weightSpecs:[Ms,e,Ds].join(As),weightData:[Ms,e,_s].join(As),modelMetadata:[Ms,e,Rs].join(As)}}function Bs(e){for(const t of Object.values(e))window.localStorage.removeItem(t)}function Ps(e){const t=e.split(As);if(t.length<3)throw new Error(`Invalid key format: ${e}`);return t.slice(1,t.length-1).join(As)}class zs{constructor(e){if(!ke().getBool("IS_BROWSER")||"undefined"==typeof window||void 0===window.localStorage)throw new Error("The current environment does not support local storage.");if(this.LS=window.localStorage,null==e||!e)throw new Error("For local storage, modelPath must not be null, undefined or empty.");this.modelPath=e,this.keys=Cs(this.modelPath)}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");{const t=JSON.stringify(e.modelTopology),n=JSON.stringify(e.weightSpecs),r=ps(e);try{this.LS.setItem(this.keys.info,JSON.stringify(r)),this.LS.setItem(this.keys.topology,t),this.LS.setItem(this.keys.weightSpecs,n),this.LS.setItem(this.keys.weightData,function(e){if(is)return Buffer.from(e).toString("base64");const t=new Uint8Array(e);let n="";for(let e=0,r=t.length;e<r;e++)n+=String.fromCharCode(t[e]);return btoa(n)}(e.weightData));const a={format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,signature:null!=e.signature?e.signature:void 0,userDefinedMetadata:null!=e.userDefinedMetadata?e.userDefinedMetadata:void 0,modelInitializer:null!=e.modelInitializer?e.modelInitializer:void 0,trainingConfig:null!=e.trainingConfig?e.trainingConfig:void 0};return this.LS.setItem(this.keys.modelMetadata,JSON.stringify(a)),{modelArtifactsInfo:r}}catch(e){throw Bs(this.keys),new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${r.modelTopologyBytes}, weightSpecsBytes=${r.weightSpecsBytes}, weightDataBytes=${r.weightDataBytes}.`)}}}async load(){const e=JSON.parse(this.LS.getItem(this.keys.info));if(null==e)throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);if("JSON"!==e.modelTopologyType)throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");const t={},n=JSON.parse(this.LS.getItem(this.keys.topology));if(null==n)throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);t.modelTopology=n;const r=JSON.parse(this.LS.getItem(this.keys.weightSpecs));if(null==r)throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);t.weightSpecs=r;const a=this.LS.getItem(this.keys.modelMetadata);if(null!=a){const e=JSON.parse(a);t.format=e.format,t.generatedBy=e.generatedBy,t.convertedBy=e.convertedBy,null!=e.signature&&(t.signature=e.signature),null!=e.userDefinedMetadata&&(t.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(t.modelInitializer=e.modelInitializer),null!=e.trainingConfig&&(t.trainingConfig=e.trainingConfig)}const s=this.LS.getItem(this.keys.weightData);if(null==s)throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);return t.weightData=function(e){if(is){const t=Buffer.from(e,"base64");return t.buffer.slice(t.byteOffset,t.byteOffset+t.byteLength)}const t=atob(e),n=new Uint8Array(t.length);for(let e=0;e<t.length;++e)n.set([t.charCodeAt(e)],e);return n.buffer}(s),t}}zs.URL_SCHEME="localstorage://";const Ws=e=>{return ke().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(zs.URL_SCHEME)?(t=e.slice(zs.URL_SCHEME.length),new zs(t)):null;var t};ms.registerSaveRouter(Ws),ms.registerLoadRouter(Ws);class Os{constructor(){F(ke().getBool("IS_BROWSER"),(()=>"Current environment is not a web browser")),F("undefined"==typeof window||void 0!==window.localStorage,(()=>"Current browser does not appear to support localStorage")),this.LS=window.localStorage}async listModels(){const e={},t=Ms+As,n=As+Fs;for(let r=0;r<this.LS.length;++r){const a=this.LS.key(r);a.startsWith(t)&&a.endsWith(n)&&(e[Ps(a)]=JSON.parse(this.LS.getItem(a)))}return e}async removeModel(e){var t;const n=Cs(e=(t=e).startsWith(zs.URL_SCHEME)?t.slice(zs.URL_SCHEME.length):t);if(null==this.LS.getItem(n.info))throw new Error(`Cannot find model at path '${e}'`);const r=JSON.parse(this.LS.getItem(n.info));return Bs(n),r}}const Ls="://";class Hs{constructor(){this.managers={}}static getInstance(){return null==Hs.instance&&(Hs.instance=new Hs),Hs.instance}static registerManager(e,t){F(null!=e,(()=>"scheme must not be undefined or null.")),e.endsWith(Ls)&&(e=e.slice(0,e.indexOf(Ls))),F(e.length>0,(()=>"scheme must not be an empty string."));const n=Hs.getInstance();F(null==n.managers[e],(()=>`A model store manager is already registered for scheme '${e}'.`)),n.managers[e]=t}static getManager(e){const t=this.getInstance().managers[e];if(null==t)throw new Error(`Cannot find model manager for scheme '${e}'`);return t}static getSchemes(){return Object.keys(this.getInstance().managers)}}function Gs(e){if(-1===e.indexOf(Ls))throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${Hs.getSchemes().join(",")}`);return{scheme:e.split(Ls)[0],path:e.split(Ls)[1]}}async function Ks(e,t,n=!1){F(e!==t,(()=>`Old path and new path are the same: '${e}'`));const r=ms.getLoadHandlers(e);F(r.length>0,(()=>`Copying failed because no load handler is found for source URL ${e}.`)),F(r.length<2,(()=>`Copying failed because more than one (${r.length}) load handlers for source URL ${e}.`));const a=r[0],s=ms.getSaveHandlers(t);F(s.length>0,(()=>`Copying failed because no save handler is found for destination URL ${t}.`)),F(s.length<2,(()=>`Copying failed because more than one (${r.length}) save handlers for destination URL ${t}.`));const o=s[0],i=Gs(e).scheme,l=Gs(e).path,u=i===Gs(e).scheme,c=await a.load();n&&u&&await Hs.getManager(i).removeModel(l);const d=await o.save(c);return n&&!u&&await Hs.getManager(i).removeModel(l),d.modelArtifactsInfo}async function qs(){const e=Hs.getSchemes(),t={};for(const n of e){const e=await Hs.getManager(n).listModels();for(const r in e)t[n+Ls+r]=e[r]}return t}async function Us(e){const t=Gs(e);return Hs.getManager(t.scheme).removeModel(t.path)}async function Vs(e,t){return Ks(e,t,!1)}async function js(e,t){return Ks(e,t,!0)}class Zs{fetch(e,t){return fetch(e,t)}now(){return performance.now()}encode(e,t){if("utf-8"!==t&&"utf8"!==t)throw new Error(`Browser's encoder only supports utf-8, but got ${t}`);return null==this.textEncoder&&(this.textEncoder=new TextEncoder),this.textEncoder.encode(e)}decode(e,t){return new TextDecoder(t).decode(e)}}if(ke().get("IS_BROWSER")){ke().setPlatform("browser",new Zs);try{Hs.registerManager(zs.URL_SCHEME,new Os)}catch(e){}try{Hs.registerManager(Es.URL_SCHEME,new Ts)}catch(e){}}let Js;function Ys(e,t="float32",n){return t=t||"float32",he(e),new ba(e,t,n)}ke().get("IS_NODE")&&!ke().get("IS_BROWSER")&&ke().setPlatform("node",new class{constructor(){this.util=n(8628),this.textEncoder=new this.util.TextEncoder}fetch(e,t){return null!=ke().global.fetch?ke().global.fetch(e,t):(null==Js&&(Js=n(5410)),Js(e,t))}now(){const e=process.hrtime();return 1e3*e[0]+e[1]/1e6}encode(e,t){if("utf-8"!==t&&"utf8"!==t)throw new Error(`Node built-in encoder only supports utf-8, but got ${t}`);return this.textEncoder.encode(e)}decode(e,t){return 0===e.length?"":new this.util.TextDecoder(t).decode(e)}});const Xs=Qa({cast_:function(e,t){const n=Ja(e,"x","cast");if(!Z(t))throw new Error(`Failed to cast to unknown dtype ${t}`);if("string"===t&&"string"!==n.dtype||"string"!==t&&"string"===n.dtype)throw new Error("Only strings can be casted to strings");const r={x:n},a={dtype:t};return Oa.runKernel(Ue,r,a)}}),Qs=Qa({clone_:function(e){const t={x:Ja(e,"x","clone","string_or_numeric")};return Oa.runKernel(Pt,t)}});function eo(e,t=!1){console.log(e.toString(t))}function to(e){return new Promise((e=>setTimeout(e))).then(e)}Wa(),ya={buffer:Ys,cast:Xs,clone:Qs,print:eo};class no{constructor(e){if(!ke().getBool("IS_BROWSER"))throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");e.startsWith(no.URL_SCHEME)&&(e=e.slice(no.URL_SCHEME.length)),null!=e&&0!==e.length||(e="model"),this.modelJsonFileName=e+".json",this.weightDataFileName=e+".weights.bin"}async save(e){if("undefined"==typeof document)throw new Error("Browser downloads are not supported in this environment since `document` is not present");const t=window.URL.createObjectURL(new Blob([e.weightData],{type:"application/octet-stream"}));if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");{const n=ds(e,[{paths:["./"+this.weightDataFileName],weights:e.weightSpecs}]),r=window.URL.createObjectURL(new Blob([JSON.stringify(n)],{type:"application/json"})),a=null==this.modelJsonAnchor?document.createElement("a"):this.modelJsonAnchor;if(a.download=this.modelJsonFileName,a.href=r,await to((()=>a.dispatchEvent(new MouseEvent("click")))),null!=e.weightData){const e=null==this.weightDataAnchor?document.createElement("a"):this.weightDataAnchor;e.download=this.weightDataFileName,e.href=t,await to((()=>e.dispatchEvent(new MouseEvent("click"))))}return{modelArtifactsInfo:ps(e)}}}}no.URL_SCHEME="downloads://";class ro{constructor(e){if(null==e||e.length<1)throw new Error(`When calling browserFiles, at least 1 file is required, but received ${e}`);this.jsonFile=e[0],this.weightsFiles=e.slice(1)}async load(){return new Promise(((e,t)=>{const n=new FileReader;n.onload=n=>{const r=JSON.parse(n.target.result),a=r.modelTopology;if(null==a)return void t(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));if(null==r.weightsManifest)return void t(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));if(0===this.weightsFiles.length)return void e({modelTopology:a});const s=hs(r,(e=>this.loadWeights(e)));e(s)},n.onerror=e=>t(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`),n.readAsText(this.jsonFile)}))}loadWeights(e){const t=[],n=[];for(const r of e)t.push(...r.weights),n.push(...r.paths);const r=this.checkManifestAndWeightFiles(e),a=n.map((e=>this.loadWeightsFile(e,r[e])));return Promise.all(a).then((e=>[t,us(e)]))}loadWeightsFile(e,t){return new Promise(((n,r)=>{const a=new FileReader;a.onload=e=>{const t=e.target.result;n(t)},a.onerror=t=>r(`Failed to weights data from file of path '${e}'.`),a.readAsArrayBuffer(t)}))}checkManifestAndWeightFiles(e){const t=[],n=this.weightsFiles.map((e=>cs(e.name))),r={};for(const a of e)a.paths.forEach((e=>{const a=cs(e);if(-1!==t.indexOf(a))throw new Error(`Duplicate file basename found in weights manifest: '${a}'`);if(t.push(a),-1===n.indexOf(a))throw new Error(`Weight file with basename '${a}' is not provided.`);r[e]=this.weightsFiles[n.indexOf(a)]}));if(t.length!==this.weightsFiles.length)throw new Error(`Mismatch in the number of files in weights manifest (${t.length}) and the number of weight files provided (${this.weightsFiles.length}).`);return r}}function ao(e){return new ro(e)}function so(e,t,n,r){!function(e){F(null!=e&&Array.isArray(e)&&e.length>0,(()=>"promises must be a none empty array"))}(e),function(e,t){F(e>=0&&e<=1,(()=>`Progress fraction must be in range [0, 1], but got startFraction ${e}`)),F(t>=0&&t<=1,(()=>`Progress fraction must be in range [0, 1], but got endFraction ${t}`)),F(t>=e,(()=>`startFraction must be no more than endFraction, but got startFraction ${e} and endFraction ${t}`))}(n=null==n?0:n,r=null==r?1:r);let a=0;return Promise.all(e.map((s=>(s.then((s=>{const o=n+ ++a/e.length*(r-n);return t(o),s})),s))))}async function oo(e,t){null==t&&(t={});const n=null==t.fetchFunc?ke().platform.fetch:t.fetchFunc,r=e.map((e=>n(e,t.requestInit,{isBinary:!0}))),a=(null==t.onProgress?await Promise.all(r):await so(r,t.onProgress,0,.5)).map((e=>e.arrayBuffer()));return null==t.onProgress?await Promise.all(a):await so(a,t.onProgress,.5,1)}async function io(e,t="",n,r){return lo((e=>oo(e,{requestInit:r})))(e,t,n)}function lo(e){return async(t,n="",r)=>{const a=t.map((()=>!1)),s={},o=null!=r?r.map((()=>!1)):[],i=[];if(t.forEach(((e,t)=>{let n=0;e.weights.forEach((e=>{const l="quantization"in e?e.quantization.dtype:e.dtype,u=rs[l]*R(e.shape),c=()=>{a[t]=!0,null==s[t]&&(s[t]=[]),s[t].push({manifestEntry:e,groupOffset:n,sizeBytes:u})};null!=r?r.forEach(((t,n)=>{t===e.name&&(c(),o[n]=!0)})):c(),i.push(e.name),n+=u}))})),!o.every((e=>e))){const e=r.filter(((e,t)=>!o[t]));throw new Error(`Could not find weights in manifest with names: ${e.join(", ")}. \nManifest JSON has weights with names: ${i.join(", ")}.`)}const l=a.reduce(((e,t,n)=>(t&&e.push(n),e)),[]),u=[];l.forEach((e=>{t[e].paths.forEach((e=>{const t=n+(n.endsWith("/")?"":"/")+e;u.push(t)}))}));const c=await e(u),d={};let h=0;return l.forEach((e=>{const n=t[e].paths.length;let r=0;for(let e=0;e<n;e++)r+=c[h+e].byteLength;const a=new ArrayBuffer(r),o=new Uint8Array(a);let i=0;for(let e=0;e<n;e++){const t=new Uint8Array(c[h+e]);o.set(t,i),i+=t.byteLength}s[e].forEach((e=>{const t=ss(a.slice(e.groupOffset,e.groupOffset+e.sizeBytes),[e.manifestEntry]);for(const e in t)d[e]=t[e]})),h+=n})),d}}ms.registerSaveRouter((e=>ke().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(no.URL_SCHEME)?function(e="model"){return new no(e)}(e.slice(no.URL_SCHEME.length)):null));class uo{constructor(e,t){if(this.DEFAULT_METHOD="POST",null==t&&(t={}),this.weightPathPrefix=t.weightPathPrefix,this.onProgress=t.onProgress,this.weightUrlConverter=t.weightUrlConverter,null!=t.fetchFunc?(F("function"==typeof t.fetchFunc,(()=>"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)")),this.fetch=t.fetchFunc):this.fetch=ke().platform.fetch,F(null!=e&&e.length>0,(()=>"URL path for http must not be null, undefined or empty.")),Array.isArray(e)&&F(2===e.length,(()=>`URL paths for http must have a length of 2, (actual length is ${e.length}).`)),this.path=e,null!=t.requestInit&&null!=t.requestInit.body)throw new Error("requestInit is expected to have no pre-existing body, but has one.");this.requestInit=t.requestInit||{}}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");const t=Object.assign({method:this.DEFAULT_METHOD},this.requestInit);t.body=new FormData;const n=ds(e,[{paths:["./model.weights.bin"],weights:e.weightSpecs}]);t.body.append("model.json",new Blob([JSON.stringify(n)],{type:"application/json"}),"model.json"),null!=e.weightData&&t.body.append("model.weights.bin",new Blob([e.weightData],{type:"application/octet-stream"}),"model.weights.bin");const r=await this.fetch(this.path,t);if(r.ok)return{modelArtifactsInfo:ps(e),responses:[r]};throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${r.status}.`)}async load(){const e=await this.fetch(this.path,this.requestInit);if(!e.ok)throw new Error(`Request to ${this.path} failed with status code ${e.status}. Please verify this URL points to the model JSON of the model to load.`);let t;try{t=await e.json()}catch(e){let t=`Failed to parse model JSON of response from ${this.path}.`;throw this.path.endsWith(".pb")?t+=" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.":t+=" Please make sure the server is serving valid JSON for this request.",new Error(t)}const n=t.modelTopology,r=t.weightsManifest;if(null==n&&null==r)throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);return hs(t,(e=>this.loadWeights(e)))}async loadWeights(e){const t=Array.isArray(this.path)?this.path[1]:this.path,[n,r]=function(e){const t=e.lastIndexOf("/"),n=e.lastIndexOf("?");return[e.substring(0,t)+"/",n>t?e.substring(n):""]}(t),a=this.weightPathPrefix||n,s=[];for(const t of e)s.push(...t.weights);const o=[],i=[];for(const t of e)for(const e of t.paths)null!=this.weightUrlConverter?i.push(this.weightUrlConverter(e)):o.push(a+e+r);return this.weightUrlConverter&&o.push(...await Promise.all(i)),[s,us(await oo(o,{requestInit:this.requestInit,fetchFunc:this.fetch,onProgress:this.onProgress}))]}}function co(e){return null!=e.match(uo.URL_SCHEME_REGEX)}uo.URL_SCHEME_REGEX=/^https?:\/\//;const ho=(e,t)=>{if("undefined"==typeof fetch&&(null==t||null==t.fetchFunc))return null;{let n=!0;if(n=Array.isArray(e)?e.every((e=>co(e))):co(e),n)return po(e,t)}return null};function po(e,t){return new uo(e,t)}function fo(e,t){return po(e,t)}ms.registerSaveRouter(ho),ms.registerLoadRouter(ho);class mo{constructor(e){this.modelArtifacts=e}async load(){return this.modelArtifacts}}class go{constructor(e){this.saveHandler=e}async save(e){return this.saveHandler(e)}}function bo(e,t,n,r){return 1===arguments.length?null!=e.modelTopology||null!=e.weightSpecs?new mo(e):(console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),new mo({modelTopology:e})):(console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),new mo({modelTopology:e,weightSpecs:t,weightData:n,trainingConfig:r}))}function ko(e){return new go(e)}const yo=Qa({matMul_:function(e,t,n=!1,r=!1){let a=Ja(e,"a","matMul"),s=Ja(t,"b","matMul");[a,s]=$a(a,s);const o={a,b:s},i={transposeA:n,transposeB:r};return Oa.runKernel(Le,o,i)}}),wo=Qa({oneHot_:function(e,t,n=1,r=0){if(t<2)throw new Error(`Error in oneHot: depth must be >=2, but it is ${t}`);const a={indices:Ja(e,"indices","oneHot","int32")},s={depth:t,onValue:n,offValue:r};return Oa.runKernel(vn,a,s)}}),Io=Qa({transpose_:function(e,t){const n=Ja(e,"x","transpose");if(null==t&&(t=n.shape.map(((e,t)=>t)).reverse()),F(n.rank===t.length,(()=>`Error in transpose: rank of input ${n.rank} must match length of perm ${t}.`)),t.forEach((e=>{F(e>=0&&e<n.rank,(()=>"All entries in 'perm' must be between 0 and "+(n.rank-1)+` but got ${t}`))})),n.rank<=1)return n.clone();const r={x:n},a={perm:t};return Oa.runKernel(yr,r,a)}}),vo=Qa({confusionMatrix_:function(e,t,n){const r=Ja(e,"labels","confusionMatrix"),a=Ja(t,"predictions","confusionMatrix");F(null==n||n>0&&Number.isInteger(n),(()=>`If provided, numClasses must be a positive integer, but got ${n}`)),F(1===r.rank,(()=>`Expected the rank of labels to be 1, but got ${r.rank}`)),F(1===a.rank,(()=>`Expected the rank of predictions to be 1, but got ${a.rank}`)),F(r.shape[0]===a.shape[0],(()=>`Mismatch in the number of examples: ${r.shape[0]} vs. ${a.shape[0]}. Labels and predictions should have the same number of elements.`)),F(n>0&&Number.isInteger(n),(()=>`numClasses is required to be a positive integer, but got ${n}`));const s=wo(Xs(r,"int32"),n),o=wo(Xs(a,"int32"),n),i=Io(s),l=yo(i,o);return Xs(l,"int32")}});function xo(e,t){const n=e.length,r=[];for(let a=0;a<n;a++){const s=n-1-a,o=e[s]||1;(t[t.length-1-a]||1)>1&&1===o&&r.unshift(s)}return r}function So(e,t){const n=[];for(let r=0;r<t.length;r++){const a=e[e.length-r-1],s=t.length-r-1,o=t[s];(null==a||1===a&&o>1)&&n.unshift(s)}return n}function Eo(e,t){const n=[],r=Math.max(e.length,t.length);for(let a=0;a<r;a++){let r=e[e.length-a-1];null==r&&(r=1);let s=t[t.length-a-1];if(null==s&&(s=1),1===r)n.unshift(s);else if(1===s)n.unshift(r);else{if(r!==s)throw Error(`Operands could not be broadcast together with shapes ${e} and ${t}.`);n.unshift(r)}}return n}function No(e,t,n){if(D(e),null!=t&&3!==t.length)throw new Error("tensor3d() requires shape to have three numbers");const r=Va(e,n);if(3!==r.length&&1!==r.length)throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");return ts(e,t,r,n)}let To;function Ao(e,t=3){if(t>4)throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");if(null==e)throw new Error("pixels passed to tf.browser.fromPixels() can not be null");let n=!1,r=!1,a=!1,s=!1,o=!1,i=!1;if(e.data instanceof Uint8Array)n=!0;else if("undefined"!=typeof ImageData&&e instanceof ImageData)r=!0;else if("undefined"!=typeof HTMLVideoElement&&e instanceof HTMLVideoElement)a=!0;else if("undefined"!=typeof HTMLImageElement&&e instanceof HTMLImageElement)s=!0;else if(null!=e.getContext)o=!0;else{if(!("undefined"!=typeof ImageBitmap&&e instanceof ImageBitmap))throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${e.constructor.name}`);i=!0}if(a){const t=2;if(a&&e.readyState<t)throw new Error("The video element has not loaded data yet. Please wait for `loadeddata` event on the <video> element.")}if(null!=Rr(Er,Oa.backendName)){const n={pixels:e},r={numChannels:t};return Oa.runKernel(Er,n,r)}const[l,u]=a?[e.videoWidth,e.videoHeight]:[e.width,e.height];let c,d;if(o)c=e.getContext("2d").getImageData(0,0,l,u).data;else if(r||n)c=e.data;else if(s||a||i){if(null==To)if("undefined"==typeof document){if("undefined"==typeof OffscreenCanvas||"undefined"==typeof OffscreenCanvasRenderingContext2D)throw new Error("Cannot parse input in current context. Reason: OffscreenCanvas Context2D rendering is not supported.");To=new OffscreenCanvas(1,1).getContext("2d")}else To=document.createElement("canvas").getContext("2d");To.canvas.width=l,To.canvas.height=u,To.drawImage(e,0,0,l,u),c=To.getImageData(0,0,l,u).data}if(4===t)d=new Int32Array(c);else{const e=l*u;d=new Int32Array(e*t);for(let n=0;n<e;n++)for(let e=0;e<t;++e)d[n*t+e]=c[4*n+e]}return No(d,[u,l,t],"int32")}async function Mo(e,t=3){let n=null;if(ke().getBool("WRAP_TO_IMAGEBITMAP")&&function(e){return"undefined"!=typeof window&&"undefined"!=typeof ImageBitmap&&window.hasOwnProperty("createImageBitmap")&&!(e instanceof ImageBitmap)&&function(e){return null!=e&&0!==e.width&&0!==e.height}(e)&&!function(e){return null!=e&&e.data instanceof Uint8Array}(e)}(e)){let t;try{t=await createImageBitmap(e,{premultiplyAlpha:"none"})}catch(e){t=null}n=null!=t&&t.width===e.width&&t.height===e.height?t:e}else n=e;return Ao(n,t)}async function Fo(e,t){let n=Ja(e,"img","toPixels");if(!(e instanceof Ia)){const e=n;n=Xs(e,"int32"),e.dispose()}if(2!==n.rank&&3!==n.rank)throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${n.rank}.`);const[r,a]=n.shape.slice(0,2),s=2===n.rank?1:n.shape[2];if(s>4||2===s)throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${s}`);if("float32"!==n.dtype&&"int32"!==n.dtype)throw new Error(`Unsupported type for toPixels: ${n.dtype}. Please use float32 or int32 tensors.`);const o=await n.data(),i="float32"===n.dtype?255:1,l=new Uint8ClampedArray(a*r*4);for(let e=0;e<r*a;++e){const t=[0,0,0,255];for(let r=0;r<s;r++){const a=o[e*s+r];if("float32"===n.dtype){if(a<0||a>1)throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${a}.`)}else if("int32"===n.dtype&&(a<0||a>255))throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${a}.`);1===s?(t[0]=a*i,t[1]=a*i,t[2]=a*i):t[r]=a*i}const r=4*e;l[r+0]=Math.round(t[0]),l[r+1]=Math.round(t[1]),l[r+2]=Math.round(t[2]),l[r+3]=Math.round(t[3])}if(null!=t){t.width=a,t.height=r;const e=t.getContext("2d"),n=new ImageData(l,a,r);e.putImageData(n,0,0)}return n!==e&&n.dispose(),l}const $o=Qa({fromPixels_:Ao});function Do(e,t){const n=e.shape.length,r=t.shape.length;if(n<1)throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${n}.`);if(r<1)throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${r}.`);if("int32"!==t.dtype)throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${t.dtype}.`);if(t.shape[r-1]>n)throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${t.shape[r-1]} vs. ${n}`);if(0===R(e.shape))throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${e.shape}.`);const a=t.shape,s=a[a.length-1];let o=1;for(let e=0;e<a.length-1;++e)o*=a[e];const i=e.shape,l=a.slice();l.pop();let u=1;for(let e=s;e<n;++e)u*=i[e],l.push(i[e]);const c=[...oe(e.shape).map((e=>e/u)),1].slice(0,s);return[l,o,u,c]}function _o(e,t,n){const r=t.rank>1?t.shape[t.rank-1]:1,a=t.rank>1?t.rank-1:1,s=`Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${n.shape}, indices.shape: ${t.shape}, shape: ${e}, sliceDim: ${r}, and batchDim: ${a}.`;if(n.rank<a)throw new Error(s+` update.rank < ${a}. `);if(e.length<r+(n.rank-a))throw new Error(s+` Output shape length < ${r+(n.rank-a)}`);if(n.rank!==a+e.length-r)throw new Error(s+" update.rank != "+(a+e.length-r));for(let e=0;e<a;++e)if(n.shape[e]!==t.shape[e])throw new Error(s+` updates.shape[${e}] (${n.shape[e]}) != indices.shape[${e}] (${t.shape[e]}).`);for(let t=0;t<n.rank-a;++t)if(n.shape[t+a]!==e[t+r])throw new Error(s+` updates.shape[${t+a}] (${n.shape[t+a]}) != shape[${t+a}] (${e[t+a]})`)}function Ro(e,t,n){if(t.rank<1)throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${t.rank}.`);if(e.rank<1)throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${e.rank}.`);if("int32"!==t.dtype)throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${t.dtype}`);if(n.length<1)throw new Error(`Output rank must be greater or equal to 1, but got shape: ${n}`);if(0===n.length){if(0===t.size)throw new Error(`Indices specified for empty output. indices shape: ${t.shape}`);if(0===e.size)throw new Error(`Updates specified for empty output. updates shape: ${e.shape}`)}_o(n,t,e)}function Co(e,t,n){const r=t.shape.length,a=r>1?t.shape[r-1]:1,s=n.length;let o=1;for(let e=a;e<s;++e)o*=n[e];const i=a<1?1:a;return{sliceRank:a,numUpdates:R(t.shape)/i,sliceSize:o,strides:[...oe(n.slice(0,a)),1],outputSize:R(n)}}function Bo(e,t,n){const r=e.shape.length;F(r===t.length,(()=>`Error in slice${r}D: Length of begin ${t} must match the rank of the array (${r}).`)),F(r===n.length,(()=>`Error in slice${r}D: Length of size ${n} must match the rank of the array (${r}).`));for(let a=0;a<r;++a)F(t[a]+n[a]<=e.shape[a],(()=>`Error in slice${r}D: begin[${a}] + size[${a}] (${t[a]+n[a]}) would overflow input.shape[${a}] (${e.shape[a]})`))}function Po(e){const t=[];let n=0;for(;e>0;)1&e&&t.push(n),e/=2,n++;return t}function zo(e,t,n){const r=[];for(let a=0;a<e.length;a++)r[a]=Math.ceil((t[a]-e[a])/n[a]);return r}function Wo(e,t,n,r){const a=[...e];for(let e=a.length;e<r.length;e++)a.push(1);for(let e=0;e<n;e++)0===e?a[t]=1:(a.splice(t,0,1),a.pop());return a}function Oo(e,t,n){return n<=e?n:n-(t-1)}function Lo(e,t){const n=[];for(let r=0;r<e;r++)n.push(t+r);return n}function Ho(e,t,n,r,a,s,o,i,l){const u=e.length;let c=new Array(u),d=new Array(u),h=new Array(u);if(t.length&&n>0){const l=t[0],u=n+1;c=Go(o,l,u,r,e),d=Ko(i,l,u,a,e),h=Wo(s,l,u,e)}else for(let t=0;t<u;t++)c[t]=Uo(o,r,s,e,t,l),d[t]=Vo(i,a,s,e,t,l),h[t]=qo(s,t,l);return{begin:c,end:d,strides:h}}function Go(e,t,n,r,a){const s=[...a],o=Lo(n,t);for(let a=0;a<s.length;a++)if(o.indexOf(a)>-1)s[a]=0;else{const o=Oo(t,n,a);let i=r[o];e&1<<o&&(i=0),s[a]=i}return s}function Ko(e,t,n,r,a){const s=[...a],o=Lo(n,t);for(let a=0;a<s.length;a++)if(o.indexOf(a)>-1)s[a]=Number.MAX_SAFE_INTEGER;else{const o=Oo(t,n,a);let i=r[o];e&1<<o&&(i=Number.MAX_SAFE_INTEGER),s[a]=i}for(let e=0;e<s.length;e++){const t=a[e];s[e]<0&&(s[e]+=t),s[e]=S(0,s[e],a[e])}return s}function qo(e,t,n){let r=e[t];return(n&1<<t||null==r)&&(r=1),r}function Uo(e,t,n,r,a,s){let o=t[a];const i=n[a]||1;(e&1<<a||s&1<<a||null==o)&&(o=i>0?Number.MIN_SAFE_INTEGER:Number.MAX_SAFE_INTEGER);const l=r[a];return o<0&&(o+=l),o=S(0,o,l-1),o}function Vo(e,t,n,r,a,s){let o=t[a];const i=n[a]||1;(e&1<<a||s&1<<a||null==o)&&(o=i>0?Number.MAX_SAFE_INTEGER:Number.MIN_SAFE_INTEGER);const l=r[a];return o<0&&(o+=l),o=i>0?S(0,o,l):S(-1,o,l-1),o}function jo(e,t,n){let r=n.length;for(let e=0;e<n.length;e++)if(n[e]>1){r=e;break}for(let a=r+1;a<n.length;a++)if(t[a]>0||n[a]!==e[a])return!1;return!0}function Zo(e,t){let n=e.length>0?e[e.length-1]:1;for(let r=0;r<e.length-1;r++)n+=e[r]*t[r];return n}function Jo(e,t,n){let r;const a=e.shape.length;let s;return r="number"==typeof t?[t,...new Array(a-1).fill(0)]:t.length<a?t.concat(new Array(a-t.length).fill(0)):t.slice(),r.forEach((e=>{F(-1!==e,(()=>"slice() does not support negative begin indexing."))})),s=null==n?new Array(a).fill(-1):"number"==typeof n?[n,...new Array(a-1).fill(-1)]:n.length<a?n.concat(new Array(a-n.length).fill(-1)):n,s=s.map(((t,n)=>t>=0?t:(F(-1===t,(()=>`Negative size values should be exactly -1 but got ${t} for the slice() size at index ${n}.`)),e.shape[n]-r[n]))),[r,s]}function Yo(e,t,n,r,a,s,o,i,l){let u;if(null==r?(u=new Array(t.length),u.fill(1)):u=r,null!=o&&0!=(o&o-1))throw new Error("Multiple ellipses in slice is not allowed.");let c=!1;const d={dims:u.length,numAddAxisAfterEllipsis:0,begin:t.slice(),end:n.slice(),strides:u.slice(),beginMask:a,endMask:s,ellipsisMask:o,newAxisMask:i,shrinkAxisMask:l};for(let e=0;e<d.dims;e++)c&&0!=(1<<e&i)&&d.numAddAxisAfterEllipsis++,1<<e&o&&(c=!0);c||(d.ellipsisMask|=1<<d.dims,d.dims++);const h={dims:e.length,beginMask:0,endMask:0,beginValid:!1,endValid:!1};!function(e,t){t.beginMask=0,t.endMask=0,t.shrinkAxisMask=0;let n=0;t.beginValid=null!=e.begin,t.endValid=null!=e.end,t.begin=new Array(t.dims),t.end=new Array(t.dims),t.strides=new Array(t.dims),t.finalShapeGatherIndices=[],t.finalShapeGatherIndicesSparse=[],t.inputShapeGatherIndicesSparse=new Array(t.dims);for(let r=0;r<e.dims;r++)if(1<<r&e.ellipsisMask){const a=Math.min(t.dims-(e.dims-r)+1+e.numAddAxisAfterEllipsis,t.dims);for(;n<a;n++)t.begin[n]=0,t.end[n]=0,t.strides[n]=1,t.beginMask|=1<<n,t.endMask|=1<<n,t.finalShapeGatherIndices.push(n),t.finalShapeGatherIndicesSparse.push(-1),t.inputShapeGatherIndicesSparse[n]=r}else if(1<<r&e.newAxisMask)t.finalShapeGatherIndices.push(-2),t.finalShapeGatherIndicesSparse.push(-1);else{if(n===t.begin.length)throw Error(`Index out of range using input dim ${n}; input has only ${t.dims} dims, ${t.begin.length}.`);null!=e.begin&&(t.begin[n]=e.begin[r]),null!=e.end&&(t.end[n]=e.end[r]),t.strides[n]=e.strides[r],e.beginMask&1<<r&&(t.beginMask|=1<<n),e.endMask&1<<r&&(t.endMask|=1<<n),e.shrinkAxisMask&1<<r?(t.finalShapeGatherIndices.push(-1),t.finalShapeGatherIndicesSparse.push(-1),t.shrinkAxisMask|=1<<n):(t.finalShapeGatherIndices.push(n),t.finalShapeGatherIndicesSparse.push(r)),t.inputShapeGatherIndicesSparse[n]=r,n++}}(d,h);let p=!0,f=!0,m=!0;const g=[],b=[];for(let t=0;t<e.length;++t){if(0===h.strides[t])throw Error(`strides[${t}] must be non-zero`);const n=!!(h.shrinkAxisMask&1<<t),r=e[t];if(-1===r){g.push(n?1:-1);continue}const a=[h.beginMask&1<<t,h.endMask&1<<t],s=[h.strides[t]>0?0:-1,h.strides[t]>0?r:r-1];if(n&&h.strides[t]<=0)throw Error("only stride 1 allowed on non-range indexing.");m=m&&1===h.strides[t];const o=!!(h.beginMask&1<<t&&h.endMask&1<<t);if(h.beginValid&&h.endValid){if(n){const e=h.begin[t]<0?r+h.begin[t]:h.begin[t];if(h.begin[t]=e,h.end[t]=h.begin[t]+1,e<0||e>=r)throw Error(`slice index ${h.begin[t]} of dimension ${t} out of bounds.`)}else h.begin[t]=Xo(h.begin[t],0,h.strides[t],r,a,s),h.end[t]=Xo(h.end[t],1,h.strides[t],r,a,s);const e=1===h.strides[t]&&0===h.begin[t]&&h.end[t]===r;p=p&&e,f=f&&(0===t&&1===h.strides[t]||e)}else p=p&&1===h.strides[t]&&o,f=f&&(0===t&&1===h.strides[t]||o);let i,l=!1;if(h.beginValid&&h.endValid?(i=h.end[t]-h.begin[t],l=!0):n?(i=1,l=!0):o&&r>=0&&(i=h.strides[t]<0?-r:r,l=!0),l){let e;e=0===i||i<0!=h.strides[t]<0?0:Math.trunc(i/h.strides[t])+(i%h.strides[t]!=0?1:0),g.push(e)}else g.push(-1)}for(let e=0;e<h.finalShapeGatherIndices.length;++e){const t=h.finalShapeGatherIndices[e];t>=0?b.push(g[t]):-2===t&&b.push(1)}return{finalShapeSparse:b.filter(((e,t)=>-2!==h.finalShapeGatherIndices[t])),finalShape:b,isIdentity:p,sliceDim0:f,isSimpleSlice:m,begin:h.begin,end:h.end,strides:h.strides}}function Xo(e,t,n,r,a,s){if(a[t])return n>0?s[t]:s[t+1&1];{const t=e<0?r+e:e;return t<s[0]?s[0]:t>s[1]?s[1]:t}}class Qo{getClassName(){return this.constructor.className}static fromConfig(e,t){return new e(t)}}class ei{constructor(){this.classNameMap={}}static getMap(){return null==ei.instance&&(ei.instance=new ei),ei.instance}static register(e){ei.getMap().classNameMap[e.className]=[e,e.fromConfig]}}function ti(e){F(null!=e.className,(()=>"Class being registered does not have the static className property defined.")),F("string"==typeof e.className,(()=>"className is required to be a string, but got type "+typeof e.className)),F(e.className.length>0,(()=>"Class being registered has an empty-string as its className, which is disallowed.")),ei.register(e)}const ni=.1;function ri(e,t,n){return null==n&&(n=ai()),si(e,t,((e,t)=>ui(e,t,n)))}function ai(){return 32===Oa.backend.floatPrecision()?.001:ni}function si(e,t,n){let r=!0;if((Y(e)||Y(t))&&(r=!1),Y(e)&&Y(t)&&(r=!0),r){const n=e.constructor.name,r=t.constructor.name;if(n!==r)throw new Error(`Arrays are of different type. Actual: ${n}. Expected: ${r}`)}if(Array.isArray(e)&&Array.isArray(t)){const n=Va(e),r=Va(t);if(!B(n,r))throw new Error(`Arrays have different shapes. Actual: [${n}]. Expected: [${r}]`)}const a=Y(e)?e:_(e),s=Y(t)?t:_(t);if(a.length!==s.length)throw new Error(`Arrays have different lengths actual: ${a.length} vs expected: ${s.length}.\nActual:   ${a}.\nExpected: ${s}.`);for(let e=0;e<s.length;++e){const t=a[e],r=s[e];if(!n(t,r))throw new Error(`Arrays differ: actual[${e}] = ${t}, expected[${e}] = ${r}.\nActual:   ${a}.\nExpected: ${s}.`)}}function oi(e,t){e().then((()=>t.fail()),(()=>t()))}function ii(e,t){const n="string"==typeof t||"number"==typeof t||"boolean"==typeof t?[t]:t;return ee(e)||ee(e[0])||ee(t)||ee(t[0])?si(e,n,((e,t)=>e==t)):si(e,t,((e,t)=>ui(e,t,0)))}function li(e,t,n){if(null==n&&(n=ai()),!ui(e,t,n))throw new Error(`Numbers differ: actual === ${e}, expected === ${t}`)}function ui(e,t,n){return!isFinite(e)&&!isFinite(t)||!(isNaN(e)||isNaN(t)||Math.abs(e-t)>n)}function ci(e,t,n){for(let r=0;r<e.length;r++)if(e[r]<t||e[r]>n)throw new Error(`Value out of range:${e[r]} low: ${t}, high: ${n}`)}function di(e,t){const n=new Float32Array(e),r=new Float32Array(t);if(n.length!==r.length)throw new Error(`Expected ArrayBuffer to be of length ${r.length}, but it was ${n.length}`);for(let e=0;e<r.length;e++)if(n[e]!==r[e])throw new Error(`Expected ArrayBuffer value at ${e} to be ${r[e]} but got ${n[e]} instead`)}function hi(e){for(let t=0;t<e.length;t++){const n=e[t];Array.isArray(n)?hi(n):e[t]=ia(n)}return e}const pi="3.15.0";function fi(){ke().set("PROD",!0)}function mi(){ke().set("DEBUG",!0)}function gi(){ke().set("DEPRECATION_WARNINGS_ENABLED",!1),console.warn("TensorFlow.js deprecation warnings have been disabled.")}function bi(e){ke().getBool("DEPRECATION_WARNINGS_ENABLED")&&console.warn(e+" You can disable deprecation warnings with tf.disableDeprecationWarnings().")}function ki(){Oa.disposeVariables()}function yi(){return Oa}function wi(){return Oa.memory()}function Ii(e){return Oa.profile(e)}function vi(e,t){return Oa.tidy(e,t)}function xi(e){Ra(e).forEach((e=>e.dispose()))}function Si(e){return Oa.keep(e)}function Ei(e){return Oa.time(e)}function Ni(e){return Oa.setBackend(e)}function Ti(){return Oa.ready()}function Ai(){return Oa.backendName}function Mi(e){Oa.removeBackend(e)}function Fi(e){return Oa.findBackend(e)}function $i(e){return Oa.findBackendFactory(e)}function Di(e,t,n=1){return Oa.registerBackend(e,t,n)}function _i(){return Oa.backend}function Ri(e,t){ke().setPlatform(e,t)}wa=bi;const Ci=Qa({add_:function(e,t){let n=Ja(e,"a","add"),r=Ja(t,"b","add");[n,r]=$a(n,r);const a={a:n,b:r};return Oa.runKernel(Ne,a)}}),Bi=Qa({floorDiv_:function(e,t){let n=Ja(e,"a","floorDiv"),r=Ja(t,"b","floorDiv");[n,r]=$a(n,r);const a={a:n,b:r};return Oa.runKernel($t,a)}}),Pi=Qa({div_:function(e,t){let n=Ja(e,"a","div"),r=Ja(t,"b","div");if([n,r]=$a(n,r),"int32"===n.dtype&&"int32"===r.dtype)return Bi(n,r);const a={a:n,b:r};return Oa.runKernel(kt,a,{})}}),zi=Qa({mul_:function(e,t){let n=Ja(e,"a","mul"),r=Ja(t,"b","mul");[n,r]=$a(n,r);const a={a:n,b:r};return Oa.runKernel(mn,a)}}),Wi=Qa({sqrt_:function(e){const t={x:Ja(e,"x","sqrt","float32")};return Oa.runKernel(Yn,t)}}),Oi=Qa({square_:function(e){const t=Ja(e,"x","square");return Oa.runKernel("Square",{x:t},{})}}),Li=Qa({zerosLike_:function(e){const t={x:Ja(e,"x","zerosLike")};return Oa.runKernel(xr,t)}});function Hi(e){return F(ae(e),(()=>"The f passed in grad(f) must be a function")),(t,n)=>{const r=Ja(t,"x","tf.grad","string_or_numeric"),a=null!=n?Ja(n,"dy","tf.grad"):null;return Oa.tidy((()=>{const{value:t,grads:n}=Oa.gradients((()=>e(r)),[r],a);return null!=a&&$(t.shape,a.shape,"The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)"),ji(n),n[0]}))}}function Gi(e){return F(ae(e),(()=>"The f passed in grads(f) must be a function")),(t,n)=>{F(Array.isArray(t),(()=>"The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s"));const r=Ya(t,"args","tf.grads","string_or_numeric"),a=null!=n?Ja(n,"dy","tf.grads"):null;return Oa.tidy((()=>{const{value:t,grads:n}=Oa.gradients((()=>e(...r)),r,a);return null!=a&&$(t.shape,a.shape,"The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])"),ji(n),n}))}}function Ki(e){return F(ae(e),(()=>"The f passed in valueAndGrad(f) must be a function")),(t,n)=>{F(t instanceof Ia,(()=>"The x passed in valueAndGrad(f)(x) must be a tensor")),F(null==n||n instanceof Ia,(()=>"The dy passed in valueAndGrad(f)(x, dy) must be a tensor"));const{grads:r,value:a}=Oa.gradients((()=>e(t)),[t],n);return ji(r),{grad:r[0],value:a}}}function qi(e){return F(ae(e),(()=>"The f passed in valueAndGrads(f) must be a function")),(t,n)=>{F(Array.isArray(t)&&t.every((e=>e instanceof Ia)),(()=>"The args passed in valueAndGrads(f)(args) must be array of tensors")),F(null==n||n instanceof Ia,(()=>"The dy passed in valueAndGrads(f)(args, dy) must be a tensor"));const r=Oa.gradients((()=>e(...t)),t,n);return null!=n&&$(r.value.shape,n.shape,"The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])"),ji(r.grads),r}}function Ui(e,t){F(ae(e),(()=>"The f passed in variableGrads(f) must be a function")),F(null==t||Array.isArray(t)&&t.every((e=>e instanceof va)),(()=>"The varList passed in variableGrads(f, varList) must be an array of variables"));const n=null!=t;if(!n){t=[];for(const e in Oa.registeredVariables)t.push(Oa.registeredVariables[e])}const r=n?t.filter((e=>!e.trainable)):null,a=t.length;t=t.filter((e=>e.trainable)),F(t.length>0,(()=>`variableGrads() expects at least one of the input variables to be trainable, but none of the ${a} variables is trainable.`));const{value:s,grads:o}=Oa.gradients(e,t,null,!0);F(o.some((e=>null!=e)),(()=>"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().")),F(0===s.rank,(()=>`The f passed in variableGrads(f) must return a scalar, but it returned a rank-${s.rank} tensor`));const i={};return t.forEach(((e,t)=>{null!=o[t]&&(i[e.name]=o[t])})),null!=r&&r.forEach((e=>i[e.name]=null)),{value:s,grads:i}}function Vi(e){return Oa.customGrad(e)}function ji(e){if(e.filter((e=>null==e)).length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that\n    the f you passed encloses all operations that lead from x to y.")}function Zi(e,t){if((Y(e)&&"string"!==t||Array.isArray(e))&&"complex64"!==t)throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");if("string"===t&&Y(e)&&!(e instanceof Uint8Array))throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");return ts(e,[],[],t)}class Ji extends Qo{minimize(e,t=!1,n){const{value:r,grads:a}=this.computeGradients(e,n);if(null!=n){const e=n.map((e=>({name:e.name,tensor:a[e.name]})));this.applyGradients(e)}else this.applyGradients(a);return xi(a),t?r:(r.dispose(),null)}get iterations(){return null==this.iterations_&&(this.iterations_=0),this.iterations_}incrementIterations(){this.iterations_=this.iterations+1}computeGradients(e,t){return Ui(e,t)}dispose(){null!=this.iterations_&&xi(this.iterations_)}async saveIterations(){return null==this.iterations_&&(this.iterations_=0),{name:"iter",tensor:Zi(this.iterations_,"int32")}}async getWeights(){throw new Error("getWeights() is not implemented for this optimizer yet.")}async setWeights(e){throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`)}async extractIterations(e){return this.iterations_=(await e[0].tensor.data())[0],e.slice(1)}}Object.defineProperty(Ji,Symbol.hasInstance,{value:e=>null!=e.minimize&&null!=e.computeGradients&&null!=e.applyGradients});class Yi extends Ji{constructor(e,t,n=null){super(),this.learningRate=e,this.rho=t,this.epsilon=n,this.accumulatedGrads=[],this.accumulatedUpdates=[],null==n&&(this.epsilon=Oa.backend.epsilon())}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const r=Oa.registeredVariables[t];null==this.accumulatedGrads[n]&&(this.accumulatedGrads[n]={originalName:`${t}/accum_grad`,variable:vi((()=>Li(r).variable(!1)))}),null==this.accumulatedUpdates[n]&&(this.accumulatedUpdates[n]={originalName:`${t}/accum_var`,variable:vi((()=>Li(r).variable(!1)))});const a=Array.isArray(e)?e[n].tensor:e[t];if(null==a)return;const s=this.accumulatedGrads[n].variable,o=this.accumulatedUpdates[n].variable;vi((()=>{const e=Ci(zi(s,this.rho),zi(Oi(a),1-this.rho)),t=zi(Pi(Wi(Ci(o,this.epsilon)),Wi(Ci(s,this.epsilon))),a),n=Ci(zi(o,this.rho),zi(Oi(t),1-this.rho));s.assign(e),o.assign(n);const i=Ci(zi(t,-this.learningRate),r);r.assign(i)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedUpdates&&(xi(this.accumulatedGrads.map((e=>e.variable))),xi(this.accumulatedUpdates.map((e=>e.variable))))}async getWeights(){const e=[...this.accumulatedGrads,...this.accumulatedUpdates];return[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){const t=(e=await this.extractIterations(e)).length/2;this.accumulatedGrads=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(!1)}))),this.accumulatedUpdates=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.rho,t.epsilon)}}function Xi(e,t,n){const r={shape:e,value:t,dtype:n};return Oa.runKernel(At,{},r)}Yi.className="Adadelta",ti(Yi);class Qi extends Ji{constructor(e,t=.1){super(),this.learningRate=e,this.initialAccumulatorValue=t,this.accumulatedGrads=[]}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const r=Oa.registeredVariables[t];if(null==this.accumulatedGrads[n]){const e=!1;this.accumulatedGrads[n]={originalName:`${t}/accumulator`,variable:vi((()=>Xi(r.shape,this.initialAccumulatorValue).variable(e)))}}const a=Array.isArray(e)?e[n].tensor:e[t];if(null==a)return;const s=this.accumulatedGrads[n].variable;vi((()=>{const e=Ci(s,Oi(a));s.assign(e);const t=Ci(zi(Pi(a,Wi(Ci(e,Oa.backend.epsilon()))),-this.learningRate),r);r.assign(t)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedGrads&&xi(this.accumulatedGrads.map((e=>e.variable)))}async getWeights(){return[await this.saveIterations()].concat(this.accumulatedGrads.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e),this.accumulatedGrads=e.map((e=>({originalName:e.name,variable:e.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}}static fromConfig(e,t){return new e(t.learningRate,t.initialAccumulatorValue)}}Qi.className="Adagrad",ti(Qi);const el=Qa({pow_:function(e,t){let n=Ja(e,"base","pow"),r=Ja(t,"exp","pow");[n,r]=$a(n,r);const a={a:n,b:r};return Oa.runKernel(Nn,a)}}),tl=Qa({sub_:function(e,t){let n=Ja(e,"a","sub"),r=Ja(t,"b","sub");[n,r]=$a(n,r);const a={a:n,b:r};return Oa.runKernel(pr,a)}});class nl extends Ji{constructor(e,t,n,r=null){super(),this.learningRate=e,this.beta1=t,this.beta2=n,this.epsilon=r,this.accumulatedFirstMoment=[],this.accumulatedSecondMoment=[],vi((()=>{this.accBeta1=Zi(t).variable(),this.accBeta2=Zi(n).variable()})),null==r&&(this.epsilon=Oa.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);vi((()=>{const n=tl(1,this.accBeta1),r=tl(1,this.accBeta2);t.forEach(((t,a)=>{const s=Oa.registeredVariables[t];null==this.accumulatedFirstMoment[a]&&(this.accumulatedFirstMoment[a]={originalName:`${t}/m`,variable:vi((()=>Li(s).variable(!1)))}),null==this.accumulatedSecondMoment[a]&&(this.accumulatedSecondMoment[a]={originalName:`${t}/v`,variable:vi((()=>Li(s).variable(!1)))});const o=Array.isArray(e)?e[a].tensor:e[t];if(null==o)return;const i=this.accumulatedFirstMoment[a].variable,l=this.accumulatedSecondMoment[a].variable,u=Ci(zi(i,this.beta1),zi(o,1-this.beta1)),c=Ci(zi(l,this.beta2),zi(Oi(o),1-this.beta2)),d=Pi(u,n),h=Pi(c,r);i.assign(u),l.assign(c);const p=Ci(zi(Pi(d,Ci(Wi(h),this.epsilon)),-this.learningRate),s);s.assign(p)})),this.accBeta1.assign(zi(this.accBeta1,this.beta1)),this.accBeta2.assign(zi(this.accBeta2,this.beta2))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.accBeta2.dispose(),null!=this.accumulatedFirstMoment&&xi(this.accumulatedFirstMoment.map((e=>e.variable))),null!=this.accumulatedSecondMoment&&xi(this.accumulatedSecondMoment.map((e=>e.variable)))}async getWeights(){const e=[...this.accumulatedFirstMoment,...this.accumulatedSecondMoment];return[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e),vi((()=>{this.accBeta1.assign(el(this.beta1,this.iterations_+1)),this.accBeta2.assign(el(this.beta2,this.iterations_+1))}));const t=e.length/2;this.accumulatedFirstMoment=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(!1)}))),this.accumulatedSecondMoment=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon)}}nl.className="Adam",ti(nl);const rl=Qa({abs_:function(e){const t=Ja(e,"x","abs");if("complex64"===t.dtype){const e={x:t};return Oa.runKernel(Je,e)}{const e={x:t};return Oa.runKernel(xe,e)}}}),al=Qa({maximum_:function(e,t){let n=Ja(e,"a","maximum"),r=Ja(t,"b","maximum");[n,r]=$a(n,r),"bool"===n.dtype&&(n=Xs(n,"int32"),r=Xs(r,"int32")),Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(nn,a)}});class sl extends Ji{constructor(e,t,n,r=null,a=0){super(),this.learningRate=e,this.beta1=t,this.beta2=n,this.epsilon=r,this.decay=a,this.accumulatedFirstMoment=[],this.accumulatedWeightedInfNorm=[],vi((()=>{this.iteration=Zi(0).variable(),this.accBeta1=Zi(t).variable()})),null==r&&(this.epsilon=Oa.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);vi((()=>{const n=tl(1,this.accBeta1),r=Pi(-this.learningRate,Ci(zi(this.iteration,this.decay),1));t.forEach(((t,a)=>{const s=Oa.registeredVariables[t];null==this.accumulatedFirstMoment[a]&&(this.accumulatedFirstMoment[a]={originalName:`${t}/m`,variable:Li(s).variable(!1)}),null==this.accumulatedWeightedInfNorm[a]&&(this.accumulatedWeightedInfNorm[a]={originalName:`${t}/v`,variable:Li(s).variable(!1)});const o=Array.isArray(e)?e[a].tensor:e[t];if(null==o)return;const i=this.accumulatedFirstMoment[a].variable,l=this.accumulatedWeightedInfNorm[a].variable,u=Ci(zi(i,this.beta1),zi(o,1-this.beta1)),c=zi(l,this.beta2),d=rl(o),h=al(c,d);i.assign(u),l.assign(h);const p=Ci(zi(Pi(r,n),Pi(u,Ci(h,this.epsilon))),s);s.assign(p)})),this.iteration.assign(Ci(this.iteration,1)),this.accBeta1.assign(zi(this.accBeta1,this.beta1))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.iteration.dispose(),null!=this.accumulatedFirstMoment&&xi(this.accumulatedFirstMoment.map((e=>e.variable))),null!=this.accumulatedWeightedInfNorm&&xi(this.accumulatedWeightedInfNorm.map((e=>e.variable)))}async getWeights(){throw new Error("getWeights() is not implemented for Adamax yet.")}async setWeights(e){throw new Error("setWeights() is not implemented for Adamax yet.")}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon,t.decay)}}sl.className="Adamax",ti(sl);class ol extends Ji{constructor(e){super(),this.learningRate=e,this.setLearningRate(e)}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const r=Array.isArray(e)?e[n].tensor:e[t];if(null==r)return;const a=Oa.registeredVariables[t];vi((()=>{const e=Ci(zi(this.c,r),a);a.assign(e)}))})),this.incrementIterations()}setLearningRate(e){this.learningRate=e,null!=this.c&&this.c.dispose(),this.c=Si(Zi(-e))}dispose(){this.c.dispose()}async getWeights(){return[await this.saveIterations()]}async setWeights(e){if(0!==(e=await this.extractIterations(e)).length)throw new Error("SGD optimizer does not have settable weights.")}getConfig(){return{learningRate:this.learningRate}}static fromConfig(e,t){return new e(t.learningRate)}}ol.className="SGD",ti(ol);class il extends ol{constructor(e,t,n=!1){super(e),this.learningRate=e,this.momentum=t,this.useNesterov=n,this.accumulations=[],this.m=Zi(this.momentum)}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const r=Oa.registeredVariables[t];if(null==this.accumulations[n]){const e=!1;this.accumulations[n]={originalName:`${t}/momentum`,variable:vi((()=>Li(r).variable(e)))}}const a=this.accumulations[n].variable,s=Array.isArray(e)?e[n].tensor:e[t];null!=s&&vi((()=>{let e;const t=Ci(zi(this.m,a),s);e=this.useNesterov?Ci(zi(this.c,Ci(s,zi(t,this.m))),r):Ci(zi(this.c,t),r),a.assign(t),r.assign(e)}))})),this.incrementIterations()}dispose(){this.m.dispose(),null!=this.accumulations&&xi(this.accumulations.map((e=>e.variable)))}setMomentum(e){this.momentum=e}async getWeights(){return[await this.saveIterations()].concat(this.accumulations.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e),this.accumulations=e.map((e=>({originalName:e.name,variable:e.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}}static fromConfig(e,t){return new e(t.learningRate,t.momentum,t.useNesterov)}}il.className="Momentum",ti(il);class ll extends Ji{constructor(e,t=.9,n=0,r=null,a=!1){if(super(),this.learningRate=e,this.decay=t,this.momentum=n,this.epsilon=r,this.accumulatedMeanSquares=[],this.accumulatedMoments=[],this.accumulatedMeanGrads=[],this.centered=a,null==r&&(this.epsilon=Oa.backend.epsilon()),null==e)throw new Error("learningRate for RMSPropOptimizer must be defined.")}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const r=Oa.registeredVariables[t],a=!1;null==this.accumulatedMeanSquares[n]&&(this.accumulatedMeanSquares[n]={originalName:`${t}/rms`,variable:vi((()=>Li(r).variable(a)))}),null==this.accumulatedMoments[n]&&(this.accumulatedMoments[n]={originalName:`${t}/momentum`,variable:vi((()=>Li(r).variable(a)))}),null==this.accumulatedMeanGrads[n]&&this.centered&&(this.accumulatedMeanGrads[n]={originalName:`${t}/mg`,variable:vi((()=>Li(r).variable(a)))});const s=Array.isArray(e)?e[n].tensor:e[t];if(null==s)return;const o=this.accumulatedMeanSquares[n].variable,i=this.accumulatedMoments[n].variable;vi((()=>{const e=Ci(zi(o,this.decay),zi(Oi(s),1-this.decay));if(this.centered){const t=this.accumulatedMeanGrads[n].variable,a=Ci(zi(t,this.decay),zi(s,1-this.decay)),l=Pi(zi(s,this.learningRate),Wi(tl(e,Ci(Oi(a),this.epsilon)))),u=Ci(zi(i,this.momentum),l);o.assign(e),t.assign(a),i.assign(u);const c=tl(r,u);r.assign(c)}else{const e=Ci(zi(o,this.decay),zi(Oi(s),1-this.decay)),t=Ci(zi(i,this.momentum),Pi(zi(s,this.learningRate),Wi(Ci(e,this.epsilon))));o.assign(e),i.assign(t);const n=tl(r,t);r.assign(n)}}))})),this.incrementIterations()}dispose(){null!=this.accumulatedMeanSquares&&xi(this.accumulatedMeanSquares.map((e=>e.variable))),null!=this.accumulatedMeanGrads&&this.centered&&xi(this.accumulatedMeanGrads.map((e=>e.variable))),null!=this.accumulatedMoments&&xi(this.accumulatedMoments.map((e=>e.variable)))}async getWeights(){const e=[...this.accumulatedMeanSquares,...this.accumulatedMoments];return this.centered&&e.push(...this.accumulatedMeanGrads),[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e);const t=this.centered?e.length/3:e.length/2,n=!1;this.accumulatedMeanSquares=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))),this.accumulatedMoments=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))),this.centered&&(this.accumulatedMeanGrads=e.slice(2*t,3*t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))))}getConfig(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}}static fromConfig(e,t){return new e(t.learningRate,t.decay,t.momentum,t.epsilon,t.centered)}}ll.className="RMSProp",ti(ll);class ul{static sgd(e){return new ol(e)}static momentum(e,t,n=!1){return new il(e,t,n)}static rmsprop(e,t=.9,n=0,r=null,a=!1){return new ll(e,t,n,r,a)}static adam(e=.001,t=.9,n=.999,r=null){return new nl(e,t,n,r)}static adadelta(e=.001,t=.95,n=null){return new Yi(e,t,n)}static adamax(e=.002,t=.9,n=.999,r=null,a=0){return new sl(e,t,n,r,a)}static adagrad(e,t=.1){return new Qi(e,t)}}const cl=Qa({acos_:function(e){const t={x:Ja(e,"x","acos")};return Oa.runKernel(Se,t)}}),dl=Qa({acosh_:function(e){const t={x:Ja(e,"x","acosh")};return Oa.runKernel(Ee,t)}}),hl=Qa({addN_:function(e){F(Array.isArray(e),(()=>"The argument passed to tf.addN() must be a list of tensors")),F(e.length>=1,(()=>`Must pass at least one tensor to tf.addN(), but got ${e.length}`));const t=e.map(((e,t)=>Ja(e,`tensors${t}`,"addN"))),n=t[0];t.forEach((e=>{if(e.dtype!==n.dtype)throw new Error("All tensors passed to tf.addN() must have the same dtype")})),t.forEach((e=>{if(!B(e.shape,n.shape))throw new Error("All tensors passed to tf.addN() must have the same shape")}));const r=t;return Oa.runKernel(Te,r)}}),pl=Qa({all_:function(e,t=null,n=!1){const r={x:Ja(e,"x","all","bool")},a={axis:t,keepDims:n};return Oa.runKernel(Ae,r,a)}}),fl=Qa({any_:function(e,t=null,n=!1){const r={x:Ja(e,"x","any","bool")},a={axis:t,keepDims:n};return Oa.runKernel(Me,r,a)}}),ml=Qa({argMax_:function(e,t=0){const n={x:Ja(e,"x","argMax")},r={axis:t};return Oa.runKernel(Fe,n,r)}}),gl=Qa({argMin_:function(e,t=0){const n={x:Ja(e,"x","argMin")},r={axis:t};return Oa.runKernel($e,n,r)}}),bl=Qa({asin_:function(e){const t={x:Ja(e,"x","asin")};return Oa.runKernel(De,t)}}),kl=Qa({asinh_:function(e){const t={x:Ja(e,"x","asinh")};return Oa.runKernel(_e,t)}}),yl=Qa({atan_:function(e){const t={x:Ja(e,"x","atan")};return Oa.runKernel(Re,t)}}),wl=Qa({atan2_:function(e,t){let n=Ja(e,"a","atan2"),r=Ja(t,"b","atan2");[n,r]=$a(n,r);const a={a:n,b:r};return Oa.runKernel(Be,a)}}),Il=Qa({atanh_:function(e){const t={x:Ja(e,"x","atanh")};return Oa.runKernel(Ce,t)}});function vl(e,t,n,r,a="NHWC",s){return El(e,[...t,e[3]],n,s,r,null,null,Rl(a))}function xl(e,t,n,r,a,s,o="channelsLast"){const[i,l]=Al(t);let u;if("channelsLast"===o)u=[i,l,e[3],e[3]];else{if("channelsFirst"!==o)throw new Error(`Unknown dataFormat ${o}`);u=[i,l,e[1],e[1]]}return El(e,u,n,r,a,s,!1,o)}function Sl(e,t,n,r,a,s,o="NDHWC"){const[i,l,u]=Ml(t);let c,d;if("NDHWC"===o)d="channelsLast",c=[i,l,u,e[4],e[4]];else{if("NCDHW"!==o)throw new Error(`Unknown dataFormat ${o}`);d="channelsFirst",c=[i,l,u,e[1],e[1]]}return Nl(e,c,n,r,a,!1,d,s)}function El(e,t,n,r,a,s,o=!1,i="channelsLast"){let[l,u,c,d]=[-1,-1,-1,-1];if("channelsLast"===i)[l,u,c,d]=e;else{if("channelsFirst"!==i)throw new Error(`Unknown dataFormat ${i}`);[l,d,u,c]=e}const[h,p,,f]=t,[m,g]=Al(n),[b,k]=Al(r),y=Fl(h,b),w=Fl(p,k),{padInfo:I,outHeight:v,outWidth:x}=function(e,t,n,r,a,s,o,i,l){let u,c,d;if("number"==typeof e){u={top:e,bottom:e,left:e,right:e,type:0===e?"VALID":"NUMBER"};const a=function(e,t,n,r,a){null==r&&(r=Tl(e,t,n));const s=e[1];return[$l((e[0]-t+2*r)/n+1,a),$l((s-t+2*r)/n+1,a)]}([t,n],s,r,e,i);c=a[0],d=a[1]}else if("same"===e){c=Math.ceil(t/r),d=Math.ceil(n/a);const e=Math.max(0,(c-1)*r+s-t),i=Math.max(0,(d-1)*a+o-n),l=Math.floor(e/2),h=e-l,p=Math.floor(i/2);u={top:l,bottom:h,left:p,right:i-p,type:"SAME"}}else if("valid"===e)u={top:0,bottom:0,left:0,right:0,type:"VALID"},c=Math.ceil((t-s+1)/r),d=Math.ceil((n-o+1)/a);else{if("object"!=typeof e)throw Error(`Unknown padding parameter: ${e}`);{const h="channelsLast"===l?e[1][0]:e[2][0],p="channelsLast"===l?e[1][1]:e[2][1],f="channelsLast"===l?e[2][0]:e[3][0],m="channelsLast"===l?e[2][1]:e[3][1];u={top:h,bottom:p,left:f,right:m,type:0===h&&0===p&&0===f&&0===m?"VALID":"EXPLICIT"},c=$l((t-s+h+p)/r+1,i),d=$l((n-o+f+m)/a+1,i)}}return{padInfo:u,outHeight:c,outWidth:d}}(a,u,c,m,g,y,w,s,i),S=o?f*d:f;let E;return"channelsFirst"===i?E=[l,S,v,x]:"channelsLast"===i&&(E=[l,v,x,S]),{batchSize:l,dataFormat:i,inHeight:u,inWidth:c,inChannels:d,outHeight:v,outWidth:x,outChannels:S,padInfo:I,strideHeight:m,strideWidth:g,filterHeight:h,filterWidth:p,effectiveFilterHeight:y,effectiveFilterWidth:w,dilationHeight:b,dilationWidth:k,inShape:e,outShape:E,filterShape:t}}function Nl(e,t,n,r,a,s=!1,o="channelsLast",i){let[l,u,c,d,h]=[-1,-1,-1,-1,-1];if("channelsLast"===o)[l,u,c,d,h]=e;else{if("channelsFirst"!==o)throw new Error(`Unknown dataFormat ${o}`);[l,h,u,c,d]=e}const[p,f,m,,g]=t,[b,k,y]=Ml(n),[w,I,v]=Ml(r),x=Fl(p,w),S=Fl(f,I),E=Fl(m,v),{padInfo:N,outDepth:T,outHeight:A,outWidth:M}=function(e,t,n,r,a,s,o,i,l,u,c){let d,h,p,f;if("number"==typeof e){d={top:e,bottom:e,left:e,right:e,front:e,back:e,type:0===e?"VALID":"NUMBER"};const s=function(e,t,n,r,a,s){null==a&&(a=Tl(e,t,r));const o=e[1],i=e[2];return[$l((e[0]-t+2*a)/r+1,s),$l((o-t+2*a)/r+1,s),$l((i-t+2*a)/r+1,s),1]}([t,n,r,1],i,0,a,e,c);h=s[0],p=s[1],f=s[2]}else if("same"===e){h=Math.ceil(t/a),p=Math.ceil(n/s),f=Math.ceil(r/o);const e=(h-1)*a+i-t,c=(p-1)*s+l-n,m=(f-1)*o+u-r,g=Math.floor(e/2),b=e-g,k=Math.floor(c/2),y=c-k,w=Math.floor(m/2);d={top:k,bottom:y,left:w,right:m-w,front:g,back:b,type:"SAME"}}else{if("valid"!==e)throw Error(`Unknown padding parameter: ${e}`);d={top:0,bottom:0,left:0,right:0,front:0,back:0,type:"VALID"},h=Math.ceil((t-i+1)/a),p=Math.ceil((n-l+1)/s),f=Math.ceil((r-u+1)/o)}return{padInfo:d,outDepth:h,outHeight:p,outWidth:f}}(a,u,c,d,b,k,y,x,S,E,i),F=s?g*h:g;let $;return"channelsFirst"===o?$=[l,F,T,A,M]:"channelsLast"===o&&($=[l,T,A,M,F]),{batchSize:l,dataFormat:o,inDepth:u,inHeight:c,inWidth:d,inChannels:h,outDepth:T,outHeight:A,outWidth:M,outChannels:F,padInfo:N,strideDepth:b,strideHeight:k,strideWidth:y,filterDepth:p,filterHeight:f,filterWidth:m,effectiveFilterDepth:x,effectiveFilterHeight:S,effectiveFilterWidth:E,dilationDepth:w,dilationHeight:I,dilationWidth:v,inShape:e,outShape:$,filterShape:t}}function Tl(e,t,n,r=1){const a=Fl(t,r);return Math.floor((e[0]*(n-1)-n+a)/2)}function Al(e){return"number"==typeof e?[e,e,e]:2===e.length?[e[0],e[1],1]:e}function Ml(e){return"number"==typeof e?[e,e,e]:e}function Fl(e,t){return t<=1?e:e+(e-1)*(t-1)}function $l(e,t){if(!t)return Math.trunc(e);switch(t){case"round":return Math.round(e);case"ceil":return Math.ceil(e);case"floor":return Math.floor(e);default:throw new Error(`Unknown roundingMode ${t}`)}}function Dl(e){const[t,n,r]=Al(e);return 1===t&&1===n&&1===r}function _l(e,t){return Dl(e)||Dl(t)}function Rl(e){if("NHWC"===e)return"channelsLast";if("NCHW"===e)return"channelsFirst";throw new Error(`Unknown dataFormat ${e}`)}function Cl(e,t,n){if(null!=n){if("string"==typeof t)throw Error(`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`);if("number"==typeof t)F(P(t),(()=>`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`));else{if("object"!=typeof t)throw Error(`Error in ${e}: Unknown padding parameter: ${t}`);t.forEach((t=>{t.forEach((t=>{F(P(t),(()=>`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`))}))}))}}}const Bl=Qa({reshape_:function(e,t){const n={x:Ja(e,"x","reshape","string_or_numeric")},r={shape:t};return Oa.runKernel(_n,n,r)}}),Pl=Qa({avgPool_:function(e,t,n,r,a){const s=Ja(e,"x","avgPool","float32");F(_l(n,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`));let o=s,i=!1;3===s.rank&&(i=!0,o=Bl(s,[1,s.shape[0],s.shape[1],s.shape[2]])),F(4===o.rank,(()=>`Error in avgPool: x must be rank 4 but got rank ${o.rank}.`)),Cl("avgPool",r,a);const l={x:o},u={filterSize:t,strides:n,pad:r,dimRoundingMode:a};let c=Oa.runKernel(Pe,l,u);return c=Xs(c,s.dtype),i?Bl(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),zl=Qa({avgPool3d_:function(e,t,n,r,a,s="NDHWC"){const o=Ja(e,"x","avgPool3d","float32");let i=o,l=!1;4===o.rank&&(l=!0,i=Bl(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),F(5===i.rank,(()=>`Error in avgPool3d: x must be rank 5 but got rank ${i.rank}.`)),F("NDHWC"===s,(()=>`Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${s}`)),Cl("avgPool3d",r,a);const u={x:i},c={filterSize:t,strides:n,pad:r,dimRoundingMode:a,dataFormat:s};let d=Oa.runKernel(We,u,c);return d=Xs(d,i.dtype),l?Bl(d,[d.shape[1],d.shape[2],d.shape[3],d.shape[4]]):d}}),Wl=Qa({concat_:function(e,t=0){F(e.length>=1,(()=>"Pass at least one tensor to concat"));const n=Ya(e,"tensors","concat","string_or_numeric");if("complex64"===n[0].dtype&&n.forEach((e=>{if("complex64"!==e.dtype)throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${e.dtype}. `)})),1===n.length)return Qs(n[0]);const r=n,a={axis:t};return Oa.runKernel(Ye,r,a)}}),Ol=Qa({sigmoid_:function(e){const t={x:Ja(e,"x","sigmoid","float32")};return Oa.runKernel(Zn,t)}}),Ll=Qa({slice_:function(e,t,n){const r=Ja(e,"x","slice","string_or_numeric");if(0===r.rank)throw new Error("Slicing scalar is not possible");const a={x:r},s={begin:t,size:n};return Oa.runKernel(qn,a,s)}}),Hl=Qa({tanh_:function(e){const t={x:Ja(e,"x","tanh","float32")};return Oa.runKernel(mr,t)}}),Gl=Qa({basicLSTMCell_:function(e,t,n,r,a,s){const o=Ja(e,"forgetBias","basicLSTMCell"),i=Ja(t,"lstmKernel","basicLSTMCell"),l=Ja(n,"lstmBias","basicLSTMCell"),u=Ja(r,"data","basicLSTMCell"),c=Ja(a,"c","basicLSTMCell"),d=Ja(s,"h","basicLSTMCell"),h=Wl([u,d],1),p=yo(h,i),f=Ci(p,l),m=f.shape[0],g=f.shape[1]/4,b=[m,g],k=Ll(f,[0,0],b),y=Ll(f,[0,g],b),w=Ll(f,[0,2*g],b),I=Ll(f,[0,3*g],b),v=Ci(zi(Ol(k),Hl(y)),zi(c,Ol(Ci(o,w))));return[v,zi(Hl(v),Ol(I))]}}),Kl=Qa({batchToSpaceND_:function(e,t,n){const r=Ja(e,"x","batchToSpaceND"),a=t.reduce(((e,t)=>e*t));F(r.rank>=1+t.length,(()=>`input rank is ${r.rank} but should be > than blockShape.length ${t.length}`)),F(n.length===t.length,(()=>`crops.length is ${n.length} but should be equal to blockShape.length  ${t.length}`)),F(r.shape[0]%a==0,(()=>`input tensor batch is ${r.shape[0]} but is not divisible by the product of the elements of blockShape ${t.join(" * ")} === ${a}`));const s={x:r},o={blockShape:t,crops:n};return Oa.runKernel(He,s,o)}}),ql=Qa({batchNorm_:function(e,t,n,r,a,s){null==s&&(s=.001);const o=Ja(e,"x","batchNorm"),i=Ja(t,"mean","batchNorm"),l=Ja(n,"variance","batchNorm");let u,c;null!=a&&(u=Ja(a,"scale","batchNorm")),null!=r&&(c=Ja(r,"offset","batchNorm")),F(i.rank===l.rank,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),F(null==c||i.rank===c.rank,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),F(null==u||i.rank===u.rank,(()=>"Batch normalization gradient requires mean and scale to have equal ranks."));const d=function(e){let t;return t=0===e.rank||1===e.rank?Bl(e,[1,1,1,e.size]):2===e.rank?Bl(e,[1,1,e.shape[0],e.shape[1]]):3===e.rank?Bl(e,[1,e.shape[0],e.shape[1],e.shape[2]]):e,t}(o),h={x:d,scale:u,offset:c,mean:i,variance:l},p={varianceEpsilon:s},f=Oa.runKernel(Dt,h,p);return Bl(f,o.shape)}}),Ul=Qa({batchNorm2d_:function(e,t,n,r,a,s){const o=Ja(e,"x","batchNorm"),i=Ja(t,"mean","batchNorm"),l=Ja(n,"variance","batchNorm");let u,c;return null!=a&&(u=Ja(a,"scale","batchNorm")),null!=r&&(c=Ja(r,"offset","batchNorm")),F(2===o.rank,(()=>`Error in batchNorm2D: x must be rank 2 but got rank ${o.rank}.`)),F(2===i.rank||1===i.rank,(()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${i.rank}.`)),F(2===l.rank||1===l.rank,(()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`)),null!=u&&F(2===u.rank||1===u.rank,(()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${u.rank}.`)),null!=c&&F(2===c.rank||1===c.rank,(()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${c.rank}.`)),ql(o,i,l,c,u,s)}}),Vl=Qa({batchNorm3d_:function(e,t,n,r,a,s){const o=Ja(e,"x","batchNorm"),i=Ja(t,"mean","batchNorm"),l=Ja(n,"variance","batchNorm");let u,c;return null!=a&&(u=Ja(a,"scale","batchNorm")),null!=r&&(c=Ja(r,"offset","batchNorm")),F(3===o.rank,(()=>`Error in batchNorm3D: x must be rank 3 but got rank ${o.rank}.`)),F(3===i.rank||1===i.rank,(()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${i.rank}.`)),F(3===l.rank||1===l.rank,(()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`)),null!=u&&F(3===u.rank||1===u.rank,(()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${u.rank}.`)),null!=c&&F(3===c.rank||1===c.rank,(()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${c.rank}.`)),ql(o,i,l,c,u,s)}}),jl=Qa({batchNorm4d_:function(e,t,n,r,a,s){const o=Ja(e,"x","batchNorm"),i=Ja(t,"mean","batchNorm"),l=Ja(n,"variance","batchNorm");let u,c;return null!=a&&(u=Ja(a,"scale","batchNorm")),null!=r&&(c=Ja(r,"offset","batchNorm")),F(4===o.rank,(()=>`Error in batchNorm4D: x must be rank 4 but got rank ${o.rank}.`)),F(4===i.rank||1===i.rank,(()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${i.rank}.`)),F(4===l.rank||1===l.rank,(()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`)),null!=u&&F(4===u.rank||1===u.rank,(()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${u.rank}.`)),null!=c&&F(4===c.rank||1===c.rank,(()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${c.rank}.`)),ql(o,i,l,c,u,s)}}),Zl=Qa({bincount_:function(e,t,n){const r=Ja(e,"x","bincount"),a=Ja(t,"weights","bincount");F("int32"===r.dtype,(()=>`Error in bincount: input dtype must be int32, but got ${r.dtype}`)),F(n>=0,(()=>`size must be non-negative, but got ${n}.`)),F(a.size===r.size||0===a.size,(()=>`Error in bincount: weights must have the same size as input or0-length, but got input shape: ${r.shape}, weights shape: ${a.shape}.`));const s={x:r,weights:a},o={size:n};return Oa.runKernel(Ge,s,o)}}),Jl=Qa({broadcastArgs_:function(e,t){const n=Ja(e,"s0","broadcastArgs","int32"),r=Ja(t,"s1","broadcastArgs","int32");if(1!==n.rank)throw new Error(`broadcastArgs(): first input must be a vector (rank=1). Has rank ${n.rank}`);if(1!==r.rank)throw new Error(`broadcastArgs(): second input must be a vector (rank=1). Has rank ${r.rank}`);const a={s0:n,s1:r};return Oa.runKernel(qe,a)}}),Yl=Qa({broadcastTo_:function(e,t){let n=Ja(e,"broadcastTo","x");const r=n.shape;if(t.some((e=>!(e>0)||e%1!=0)))throw new Error(`broadcastTo(): Invalid broadcast shape [${t}].`);if(t.length<n.rank)throw new Error(`broadcastTo(): shape.length=${t.length} < input.rank=${n.rank}.`);if(t.length>n.rank){const e=n.shape.slice();for(;e.length<t.length;)e.unshift(1);n=Bl(n,e)}const a=n.shape,s=Array.from(t);for(let e=t.length-1;e>=0;e--)if(a[e]===t[e])s[e]=1;else if(1!==n.shape[e])throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${t}].`);if(0===s.map(((e,t)=>e>1?t:-1)).filter((e=>e>=0)).length)return Qs(n);const o={x:n},i={reps:s};return Oa.runKernel(gr,o,i)}}),Xl=Qa({ceil_:function(e){const t={x:Ja(e,"x","ceil","float32")};return Oa.runKernel(Ve,t)}}),Ql=Qa({clipByValue_:function(e,t,n){const r=Ja(e,"x","clipByValue");F(t<=n,(()=>`Error in clip: min (${t}) must be less than or equal to max (${n}).`));const a={x:r},s={clipValueMin:t,clipValueMax:n};return Oa.runKernel(je,a,s)}}),eu=Qa({concat1d_:function(e){return Wl(e,0)}}),tu=Qa({concat2d_:function(e,t){return Wl(e,t)}}),nu=Qa({concat3d_:function(e,t){return Wl(e,t)}}),ru=Qa({concat4d_:function(e,t){return Wl(e,t)}}),au=Qa({conv2d_:function(e,t,n,r,a="NHWC",s=[1,1],o){const i=Ja(e,"x","conv2d","float32"),l=Ja(t,"filter","conv2d","float32");let u=i,c=!1;3===i.rank&&(c=!0,u=Bl(i,[1,i.shape[0],i.shape[1],i.shape[2]])),F(4===u.rank,(()=>`Error in conv2d: input must be rank 4, but got rank ${u.rank}.`)),F(4===l.rank,(()=>`Error in conv2d: filter must be rank 4, but got rank ${l.rank}.`)),Cl("conv2d",r,o);const d="NHWC"===a?u.shape[3]:u.shape[1];F(d===l.shape[2],(()=>`Error in conv2d: depth of input (${d}) must match input depth for filter ${l.shape[2]}.`)),F(_l(n,s),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`));const h={x:u,filter:l},p={strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o},f=Oa.runKernel(Xe,h,p);return c?Bl(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),su=Qa({conv1d_:function(e,t,n,r,a="NWC",s=1,o){const i=Ja(e,"x","conv1d"),l=Ja(t,"filter","conv1d");let u=i,c=!1;2===i.rank&&(c=!0,u=Bl(i,[1,i.shape[0],i.shape[1]])),F(3===u.rank,(()=>`Error in conv1d: input must be rank 3, but got rank ${u.rank}.`)),F(3===l.rank,(()=>`Error in conv1d: filter must be rank 3, but got rank ${l.rank}.`)),Cl("conv1d",r,o),F(u.shape[2]===l.shape[1],(()=>`Error in conv1d: depth of input (${u.shape[2]}) must match input depth for filter ${l.shape[1]}.`)),F(_l(n,s),(()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${n} and dilation '${s}'`)),F("NWC"===a,(()=>`Error in conv1d: got dataFormat of ${a} but only NWC is currently supported.`));const d=Bl(l,[1,l.shape[0],l.shape[1],l.shape[2]]),h=Bl(u,[u.shape[0],1,u.shape[1],u.shape[2]]),p=au(h,d,[1,n],r,"NHWC",[1,s],o);return Bl(p,c?[p.shape[2],p.shape[3]]:[p.shape[0],p.shape[2],p.shape[3]])}}),ou=Qa({conv2DBackpropInput_:function(e,t,n,r,a,s="NHWC",o){F(e.length===t.rank,(()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`));let i=e,l=t,u=!1;3===t.rank&&(u=!0,l=Bl(t,[1,t.shape[0],t.shape[1],t.shape[2]]),i=[1,e[0],e[1],e[2]]),F(4===i.length,(()=>`Error in conv2dDerInput: inShape must be length 4, but got length ${i.length}.`)),F(4===l.rank,(()=>`Error in conv2dDerInput: dy must be rank 4, but got rank ${l.rank}`)),F(4===n.rank,(()=>`Error in conv2dDerInput: filter must be rank 4, but got rank ${n.rank}`));const c="NHWC"===s?i[3]:i[1],d="NHWC"===s?l.shape[3]:l.shape[1];F(c===n.shape[2],(()=>`Error in conv2dDerInput: depth of input (${c}) must match input depth for filter ${n.shape[2]}.`)),F(d===n.shape[3],(()=>`Error in conv2dDerInput: depth of output (${d}) must match output depth for filter ${n.shape[3]}.`)),Cl("conv2dDerInput",a,o);const h={dy:l,filter:n},p={strides:r,pad:a,dataFormat:s,dimRoundingMode:o,inputShape:i},f=Oa.runKernel(et,h,p);return u?Bl(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),iu=Qa({conv2dTranspose_:function(e,t,n,r,a,s){const o=Ja(e,"x","conv2dTranspose"),i=Ja(t,"filter","conv2dTranspose");return ou(n,o,i,r,a,"NHWC",s)}}),lu=Qa({conv3d_:function(e,t,n,r,a="NDHWC",s=[1,1,1]){const o=Ja(e,"x","conv3d"),i=Ja(t,"filter","conv3d");let l=o,u=!1;4===o.rank&&(u=!0,l=Bl(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),F(5===l.rank,(()=>`Error in conv3d: input must be rank 5, but got rank ${l.rank}.`)),F(5===i.rank,(()=>`Error in conv3d: filter must be rank 5, but got rank ${i.rank}.`)),F(l.shape[4]===i.shape[3],(()=>`Error in conv3d: depth of input (${l.shape[4]}) must match input depth for filter ${i.shape[3]}.`)),F(_l(n,s),(()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`)),F("NDHWC"===a,(()=>`Error in conv3d: got dataFormat of ${a} but only NDHWC is currently supported.`));const c={x:l,filter:i},d={strides:n,pad:r,dataFormat:a,dilations:s},h=Oa.runKernel(tt,c,d);return u?Bl(h,[h.shape[1],h.shape[2],h.shape[3],h.shape[4]]):h}}),uu=Qa({conv3DBackpropInput_:function(e,t,n,r,a){F(e.length===t.rank,(()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`));let s=e,o=t,i=!1;4===t.rank&&(i=!0,o=Bl(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]]),s=[1,e[0],e[1],e[2],e[3]]);const l=s[4],u=o.shape[4];F(5===s.length,(()=>`Error in conv3dDerInput: inShape must be length 5, but got length ${s.length}.`)),F(5===o.rank,(()=>`Error in conv3dDerInput: dy must be rank 5, but got rank ${o.rank}`)),F(5===n.rank,(()=>`Error in conv3dDerInput: filter must be rank 5, but got rank ${n.rank}`)),F(l===n.shape[3],(()=>`Error in conv3dDerInput: depth of input (${l}) must match input depth for filter ${n.shape[3]}.`)),F(u===n.shape[4],(()=>`Error in conv3dDerInput: depth of output (${u}) must match output depth for filter ${n.shape[4]}.`));const c={dy:o,filter:n},d={pad:a,strides:r,inputShape:s},h=Oa.runKernel(rt,c,d);return i?Bl(h,[h.shape[1],h.shape[2],h.shape[3],h.shape[4]]):h}}),cu=Qa({conv3dTranspose_:function(e,t,n,r,a){const s=Ja(e,"x","conv3dTranspose"),o=Ja(t,"filter","conv3dTranspose");return uu(n,s,o,r,a)}}),du=Qa({cos_:function(e){const t={x:Ja(e,"x","cos","float32")};return Oa.runKernel(at,t)}}),hu=Qa({cosh_:function(e){const t={x:Ja(e,"x","cosh","float32")};return Oa.runKernel(st,t)}}),pu=Qa({cumprod_:function(e,t=0,n=!1,r=!1){const a={x:Ja(e,"x","cumprod")},s={axis:t,exclusive:n,reverse:r};return Oa.runKernel(ot,a,s)}}),fu=Qa({cumsum_:function(e,t=0,n=!1,r=!1){const a={x:Ja(e,"x","cumsum")},s={axis:t,exclusive:n,reverse:r};return Oa.runKernel(it,a,s)}}),mu=Qa({denseBincount_:function(e,t,n,r=!1){const a=Ja(e,"x","denseBincount"),s=Ja(t,"weights","denseBincount");F("int32"===a.dtype,(()=>`Error in denseBincount: input dtype must be int32, but got ${a.dtype}`)),F(a.rank<=2,(()=>`Error in denseBincount: input must be at most rank 2, but got rank ${a.rank}.`)),F(n>=0,(()=>`size must be non-negative, but got ${n}.`)),F(s.size===a.size||0===s.size,(()=>`Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${a.shape}, weights shape: ${s.shape}.`));const o={x:a,weights:s},i={size:n,binaryOutput:r};return Oa.runKernel(ut,o,i)}}),gu=Qa({depthToSpace_:function(e,t,n="NHWC"){const r=Ja(e,"x","depthToSpace","float32"),a="NHWC"===n?r.shape[1]:r.shape[2],s="NHWC"===n?r.shape[2]:r.shape[3],o="NHWC"===n?r.shape[3]:r.shape[1];F(t>1,(()=>`blockSize should be > 1 for depthToSpace, but was: ${t}`)),F(a*t>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${a} and ${t}  for depthToSpace with input shape\n    ${r.shape}`)),F(s*t>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${s} and ${t} for depthToSpace with input shape\n        ${r.shape}`)),F(o%(t*t)==0,(()=>`Dimension size must be evenly divisible by ${t*t} but is ${o} for depthToSpace with input shape ${r.shape}`));const i={x:r},l={blockSize:t,dataFormat:n};return Oa.runKernel(ct,i,l)}}),bu=Qa({depthwiseConv2d_:function(e,t,n,r,a="NHWC",s=[1,1],o){const i=Ja(e,"x","depthwiseConv2d","float32"),l=Ja(t,"filter","depthwiseConv2d","float32");let u=i,c=!1;3===i.rank&&(c=!0,u=Bl(i,[1,i.shape[0],i.shape[1],i.shape[2]])),F(4===u.rank,(()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${u.rank}.`)),F(4===l.rank,(()=>`Error in depthwiseConv2d: filter must be rank 4, but got rank ${l.rank}.`)),F(u.shape[3]===l.shape[2],(()=>`Error in depthwiseConv2d: number of input channels (${u.shape[3]}) must match the inChannels dimension in filter ${l.shape[2]}.`)),Cl("depthwiseConv2d",r,o);const d={x:u,filter:l},h={strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o},p=Oa.runKernel(dt,d,h);return c?Bl(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),ku=Qa({diag_:function(e){const t={x:Ja(e,"x","diag")};return Oa.runKernel(ft,t)}}),yu=Qa({dilation2d_:function(e,t,n,r,a=[1,1],s="NHWC"){const o=Ja(e,"x","dilation2d"),i=Ja(t,"filter","dilation2d");F(3===o.rank||4===o.rank,(()=>`Error in dilation2d: input must be rank 3 or 4, but got rank ${o.rank}.`)),F(3===i.rank,(()=>`Error in dilation2d: filter must be rank 3, but got rank ${i.rank}.`)),F("NHWC"===s,(()=>`Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${s}`));let l=o,u=!1;3===o.rank&&(l=Bl(o,[1,o.shape[0],o.shape[1],o.shape[2]]),u=!0);const c={x:l,filter:i},d={strides:n,pad:r,dilations:a},h=Oa.runKernel(mt,c,d);return u?Bl(h,[h.shape[1],h.shape[2],h.shape[3]]):h}}),wu=Qa({equal_:function(e,t){let n=Ja(e,"a","equal","string_or_numeric"),r=Ja(t,"b","equal","string_or_numeric");[n,r]=$a(n,r),Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(xt,a)}}),Iu=Qa({where_:function(e,t,n){const r=Ja(t,"a","where"),a=Ja(n,"b","where"),s=Ja(e,"condition","where","bool"),o=Eo(Eo(s.shape,r.shape),a.shape),i={condition:Yl(s,o),t:Yl(r,o),e:Yl(a,o)};return Oa.runKernel(Gn,i)}}),vu=Qa({divNoNan_:function(e,t){let n=Ja(e,"a","div"),r=Ja(t,"b","div");[n,r]=$a(n,r);const a=Pi(n,r),s=Li(a),o=wu(r,s);return Iu(o,s,a)}}),xu=Qa({dot_:function(e,t){const n=Ja(e,"t1","dot"),r=Ja(t,"t2","dot");F(!(1!==n.rank&&2!==n.rank||1!==r.rank&&2!==r.rank),(()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks ${n.rank} and ${r.rank}.`));const a=1===n.rank?n.size:n.shape[1],s=1===r.rank?r.size:r.shape[0];if(F(a===s,(()=>`Error in dot: inner dimensions of inputs must match, but got ${a} and ${s}.`)),1===n.rank&&1===r.rank){const e=Bl(n,[1,-1]),t=Bl(r,[-1,1]),a=yo(e,t);return Bl(a,[])}if(1===n.rank&&2===r.rank){const e=Bl(n,[1,-1]),t=Bl(r,[r.shape[0],r.shape[1]]),a=yo(e,t);return Bl(a,[a.size])}if(2===n.rank&&1===r.rank){const e=Bl(r,[-1,1]),t=yo(n,e);return Bl(t,[t.size])}{const e=Bl(r,[r.shape[0],r.shape[1]]);return yo(n,e)}}}),Su=Qa({einsum_:function(e,...t){const n=t.map(((e,t)=>Ja(e,`tensors${t}`,"einsum"))),r={equation:e};return Oa.runKernel(yt,n,r)}}),Eu=Qa({elu_:function(e){const t={x:Ja(e,"x","elu","float32")};return Oa.runKernel(wt,t)}}),Nu=Qa({erf_:function(e){let t=Ja(e,"x","erf");F("int32"===t.dtype||"float32"===t.dtype,(()=>"Input dtype must be `int32` or `float32`.")),"int32"===t.dtype&&(t=Xs(t,"float32"));const n={x:t};return Oa.runKernel(vt,n)}}),Tu=Qa({exp_:function(e){const t={x:Ja(e,"x","exp")};return Oa.runKernel(St,t)}}),Au=Qa({expandDims_:function(e,t=0){const n=Ja(e,"x","expandDims","string_or_numeric");F(t<=n.rank,(()=>"Axis must be <= rank of the tensor"));const r={input:n},a={dim:t};return Oa.runKernel(Et,r,a)}}),Mu=Qa({expm1_:function(e){const t={x:Ja(e,"x","expm1")};return Oa.runKernel(Nt,t)}}),Fu=Qa({tile_:function(e,t){const n=Ja(e,"x","tile","string_or_numeric");F(n.rank===t.length,(()=>`Error in transpose: rank of input ${n.rank} must match length of reps ${t}.`));const r={x:n},a={reps:t};return Oa.runKernel(gr,r,a)}}),$u=Qa({eye_:function(e,t,n,r="float32"){null==t&&(t=e);const a=Ys([e,t],r),s=e<=t?e:t;for(let e=0;e<s;++e)a.set(1,e,e);const o=Bl(a.toTensor(),[e,t]);if(null==n)return o;if(1===n.length)return Fu(Au(o,0),[n[0],1,1]);if(2===n.length)return Fu(Au(Au(o,0),0),[n[0],n[1],1,1]);if(3===n.length)return Fu(Au(Au(Au(o,0),0),0),[n[0],n[1],n[2],1,1]);throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${n.length}D.`)}}),Du=Qa({floor_:function(e){const t={x:Ja(e,"x","floor","float32")};return Oa.runKernel(Ft,t)}}),_u=Qa({gather_:function(e,t,n=0,r=0){const a={x:Ja(e,"x","gather"),indices:Ja(t,"indices","gather","int32")},s={axis:n,batchDims:r};return Oa.runKernel(_t,a,s)}}),Ru=Qa({greater_:function(e,t){let n=Ja(e,"a","greater","string_or_numeric"),r=Ja(t,"b","greater","string_or_numeric");[n,r]=$a(n,r),Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(Ct,a)}}),Cu=Qa({greaterEqual_:function(e,t){let n=Ja(e,"a","greaterEqual","string_or_numeric"),r=Ja(t,"b","greaterEqual","string_or_numeric");[n,r]=$a(n,r),Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(Bt,a)}}),Bu=Qa({imag_:function(e){const t={input:Ja(e,"input","imag")};return Oa.runKernel(Wt,t)}}),Pu=Qa({isFinite_:function(e){const t={x:Ja(e,"x","isFinite")};return Oa.runKernel(Ot,t)}}),zu=Qa({isInf_:function(e){const t={x:Ja(e,"x","isInf")};return Oa.runKernel(Lt,t)}}),Wu=Qa({isNaN_:function(e){const t={x:Ja(e,"x","isNaN")};return Oa.runKernel(Ht,t)}}),Ou=Qa({leakyRelu_:function(e,t=.2){const n={x:Ja(e,"x","leakyRelu")},r={alpha:t};return Oa.runKernel(Gt,n,r)}}),Lu=Qa({less_:function(e,t){let n=Ja(e,"a","less","string_or_numeric"),r=Ja(t,"b","less","string_or_numeric");[n,r]=$a(n,r),Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(Kt,a)}}),Hu=Qa({lessEqual_:function(e,t){let n=Ja(e,"a","lessEqual","string_or_numeric"),r=Ja(t,"b","lessEqual","string_or_numeric");[n,r]=$a(n,r),Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(qt,a)}});function Gu(e,t,n){if(n<=0)throw new Error("The number of values should be positive.");const r={start:e,stop:t,num:n};return Oa.runKernel(Ut,{},r)}const Ku=Qa({localResponseNormalization_:function(e,t=5,n=1,r=1,a=.5){const s=Ja(e,"x","localResponseNormalization");F(4===s.rank||3===s.rank,(()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${s.rank}.`)),F(P(t),(()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${t}.`));let o=s,i=!1;3===s.rank&&(i=!0,o=Bl(s,[1,s.shape[0],s.shape[1],s.shape[2]]));const l={x:o},u={depthRadius:t,bias:n,alpha:r,beta:a},c=Oa.runKernel(Qt,l,u);return i?Bl(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),qu=Qa({log_:function(e){const t={x:Ja(e,"x","log","float32")};return Oa.runKernel(Vt,t)}}),Uu=Qa({log1p_:function(e){const t={x:Ja(e,"x","log1p")};return Oa.runKernel(jt,t)}}),Vu=Qa({neg_:function(e){const t={x:Ja(e,"x","neg")};return Oa.runKernel(gn,t)}}),ju=Qa({softplus_:function(e){const t={x:Ja(e,"x","softplus")};return Oa.runKernel(Jn,t)}}),Zu=Qa({logSigmoid_:function(e){const t=Ja(e,"x","logSigmoid"),n=Vi((e=>({value:Vu(ju(Vu(e))),gradFunc:t=>zi(t,Ol(Vu(e)))})));return n(t)}}),Ju=Qa({max_:function(e,t=null,n=!1){const r={x:Ja(e,"x","max")},a={reductionIndices:t,keepDims:n};return Oa.runKernel(tn,r,a)}}),Yu=Qa({sum_:function(e,t=null,n=!1){let r=Ja(e,"x","sum");"bool"===r.dtype&&(r=Xs(r,"int32"));const a={x:r},s={axis:t,keepDims:n};return Oa.runKernel(Xn,a,s)}}),Xu=Qa({logSoftmax_:function(e,t=-1){const n=Ja(e,"logits","logSoftmax");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and axis was ${t}`);const r=Vi(((e,n)=>{const r=Ju(e,t,!0),a=tl(e,r),s=tl(Xs(a,"float32"),qu(Yu(Tu(a),t,!0)));return n([s]),{value:s,gradFunc:(e,n)=>{const[r]=n,a=Tu(r);return tl(e,zi(Yu(e,t,!0),a))}}}));return r(n)}});function Qu(e,t){for(let n=0;n<e.length;++n)if(e[e.length-n-1]!==t-1-n)return!1;return!0}function ec(e,t,n){const r=e.length+t.length,a=[];let s=0,o=0;for(let i=0;i<r;i++)-1===n.indexOf(i)?a.push(e[s++]):a.push(t[o++]);return a}function tc(e,t){const n=[],r=e.length;for(let a=0;a<r;a++)-1===t.indexOf(a)&&n.push(e[a]);return[n,t.map((t=>e[t]))]}function nc(e,t){return ec(e,t.map((e=>1)),t)}function rc(e,t,n){F(Qu(t,n),(()=>`${e} supports only inner-most axes for now. Got axes ${t} and rank-${n} input.`))}function ac(e,t){if(Qu(e,t))return null;const n=[];for(let r=0;r<t;++r)-1===e.indexOf(r)&&n.push(r);return e.forEach((e=>n.push(e))),n}function sc(e){return e.map(((e,t)=>[t,e])).sort(((e,t)=>e[1]-t[1])).map((e=>e[0]))}function oc(e,t){const n=[];for(let r=t-e;r<t;++r)n.push(r);return n}const ic=Qa({logSumExp_:function(e,t=null,n=!1){const r=Ja(e,"x","logSumExp"),a=K(t,r.shape),s=Ju(r,a,!0),o=tl(r,s),i=Tu(o),l=Yu(i,a),u=qu(l),c=Ci(Bl(s,u.shape),u);if(n){const e=nc(c.shape,a);return Bl(c,e)}return c}}),lc=Qa({logicalAnd_:function(e,t){const n=Ja(e,"a","logicalAnd","bool"),r=Ja(t,"b","logicalAnd","bool");Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(Zt,a)}}),uc=Qa({logicalNot_:function(e){const t={x:Ja(e,"x","logicalNot","bool")};return Oa.runKernel(Jt,t)}}),cc=Qa({logicalOr_:function(e,t){const n=Ja(e,"a","logicalOr","bool"),r=Ja(t,"b","logicalOr","bool");Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(Yt,a)}}),dc=Qa({logicalXor_:function(e,t){const n=Ja(e,"a","logicalXor","bool"),r=Ja(t,"b","logicalXor","bool");return Eo(n.shape,r.shape),lc(cc(e,t),uc(lc(e,t)))}}),hc=Qa({maxPool_:function(e,t,n,r,a){const s=Ja(e,"x","maxPool");let o=s,i=!1;3===s.rank&&(i=!0,o=Bl(s,[1,s.shape[0],s.shape[1],s.shape[2]])),F(4===o.rank,(()=>`Error in maxPool: input must be rank 4 but got rank ${o.rank}.`)),F(_l(n,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`)),Cl("maxPool",r,a);const l={x:o},u={filterSize:t,strides:n,pad:r,dimRoundingMode:a},c=Oa.runKernel(rn,l,u);return i?Bl(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),pc=Qa({maxPool3d_:function(e,t=[1,1,1],n,r,a,s="NDHWC"){const o=Ja(e,"x","maxPool3d");let i=o,l=!1;4===o.rank&&(l=!0,i=Bl(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),F(5===i.rank,(()=>`Error in maxPool3d: x must be rank 5 but got rank ${i.rank}.`)),F("NDHWC"===s,(()=>`Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${s}`)),Cl("maxPool3d",r,a);const u={x:i},c={filterSize:t,strides:n,pad:r,dimRoundingMode:a,dataFormat:s},d=Oa.runKernel(sn,u,c);return l?Bl(d,[d.shape[1],d.shape[2],d.shape[3],d.shape[4]]):d}}),fc=Qa({maxPoolWithArgmax_:function(e,t,n,r,a=!1){const s={x:Ja(e,"x","maxPoolWithArgmax")},o={filterSize:t,strides:n,pad:r,includeBatchInIndex:a},i=Oa.runKernel(ln,s,o);return{result:i[0],indexes:i[1]}}}),mc=Qa({mean_:function(e,t=null,n=!1){const r={x:Ja(e,"x","mean")},a={axis:t,keepDims:n};return Oa.runKernel(un,r,a)}});function gc(e,t="float32"){if("complex64"===t){const t=gc(e,"float32"),n=gc(e,"float32");return es(t,n)}const n=ce(R(e),t);return Oa.makeTensor(n,e,t)}function bc(e,t="float32"){if("complex64"===t){const t=bc(e,"float32"),n=gc(e,"float32");return es(t,n)}const n=ue(R(e),t);return Oa.makeTensor(n,e,t)}function kc(e,t,{indexing:n="xy"}={}){if("xy"!==n&&"ij"!==n)throw new TypeError(`${n} is not a valid third argument to meshgrid`);if(void 0===e)return[];let r=Ja(e,"x","meshgrid",e instanceof Ia?e.dtype:"float32");if(void 0===t)return[r];let a=Ja(t,"y","meshgrid",t instanceof Ia?t.dtype:"float32");const s=R(r.shape),o=R(a.shape);return"xy"===n?(r=Bl(r,[1,-1]),a=Bl(a,[-1,1]),[yo(bc([o,1],r.dtype),r),yo(a,bc([1,s],a.dtype))]):(r=Bl(r,[-1,1]),a=Bl(a,[1,-1]),[yo(r,bc([1,o],r.dtype)),yo(bc([s,1],a.dtype),a)])}const yc=Qa({min_:function(e,t=null,n=!1){const r={x:Ja(e,"x","min")},a={axis:t,keepDims:n};return Oa.runKernel(cn,r,a)}}),wc=Qa({minimum_:function(e,t){let n=Ja(e,"a","minimum"),r=Ja(t,"b","minimum");[n,r]=$a(n,r),"bool"===n.dtype&&(n=Xs(n,"int32"),r=Xs(r,"int32")),Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(dn,a)}}),Ic=Qa({mirrorPad_:function(e,t,n){F("reflect"===n||"symmetric"===n,(()=>`Invalid mode. Mode must be either reflect or symmetric. Got ${n}.`));const r=Ja(e,"x","mirrorPad");if(0===r.rank)throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");F(t.length===r.rank,(()=>`Padding doesn't match input. Must be ${r.rank}. Got ${t.length}.`));const a="reflect"===n?1:0;for(let e=0;e<r.rank;e++)F(2===t[e].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),F(t[e][0]>=0&&t[e][0]<=r.shape[e]-a&&t[e][1]>=0&&t[e][1]<=r.shape[e]-a,(()=>`Padding in dimension ${e} cannot be greater than or equal to ${r.shape[e]-a} or less than 0 for input of shape ${r.shape}`));const s={paddings:t,mode:n},o={x:r};return Oa.runKernel(hn,o,s)}}),vc=Qa({mod_:function(e,t){let n=Ja(e,"a","mod"),r=Ja(t,"b","mod");[n,r]=$a(n,r);const a={a:n,b:r};return Oa.runKernel(pn,a)}}),xc=Qa({moments_:function(e,t=null,n=!1){const r=K(t,(e=Ja(e,"x","moments")).shape),a=mc(e,r,n);let s=a.shape;n||(s=nc(a.shape,r));const o=Oi(tl(Xs(e,"float32"),Bl(a,s)));return{mean:a,variance:mc(o,r,n)}}}),Sc=Qa({multiRNNCell_:function(e,t,n,r){const a=Ja(t,"data","multiRNNCell"),s=Ya(n,"c","multiRNNCell"),o=Ya(r,"h","multiRNNCell");let i=a;const l=[];for(let t=0;t<e.length;t++){const n=e[t](i,s[t],o[t]);l.push(n[0]),l.push(n[1]),i=n[1]}const u=[],c=[];for(let e=0;e<l.length;e+=2)u.push(l[e]),c.push(l[e+1]);return[u,c]}}),Ec=Qa({multinomial_:function(e,t,n,r=!1){const a=Ja(e,"logits","multinomial"),s=a.size,o=a.rank;if(s<2)throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${s}.`);if(o>2)throw new Error(`Rank of probabilities must be 1 or 2, but is ${o}`);n=n||Math.random();const i={logits:1===o?Bl(a,[1,-1]):a},l={numSamples:t,seed:n,normalized:r},u=Oa.runKernel(fn,i,l);return 1===o?Bl(u,[u.size]):u}}),Nc=Qa({notEqual_:function(e,t){let n=Ja(e,"a","notEqual","string_or_numeric"),r=Ja(t,"b","notEqual","string_or_numeric");[n,r]=$a(n,r),Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(bn,a)}}),Tc=Qa({onesLike_:function(e){const t={x:Ja(e,"x","onesLike")};return Oa.runKernel(In,t)}}),Ac=Qa({outerProduct_:function(e,t){const n=Ja(e,"v1","outerProduct"),r=Ja(t,"v2","outerProduct");F(1===n.rank&&1===r.rank,(()=>`Error in outerProduct: inputs must be rank 1, but got ranks ${n.rank} and ${r.rank}.`));const a=Bl(n,[-1,1]),s=Bl(r,[1,-1]);return yo(a,s)}}),Mc=Qa({pad_:function(e,t,n=0){const r=Ja(e,"x","pad");if(0===r.rank)throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");const a={paddings:t,constantValue:n},s={x:r};return Oa.runKernel(Sn,s,a)}}),Fc=Qa({pad1d_:function(e,t,n=0){return F(2===t.length,(()=>"Invalid number of paddings. Must be length of 2.")),Mc(e,[t],n)}}),$c=Qa({pad2d_:function(e,t,n=0){return F(2===t.length&&2===t[0].length&&2===t[1].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),Mc(e,t,n)}}),Dc=Qa({pad3d_:function(e,t,n=0){return F(3===t.length&&2===t[0].length&&2===t[1].length&&2===t[2].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),Mc(e,t,n)}}),_c=Qa({pad4d_:function(e,t,n=0){return F(4===t.length&&2===t[0].length&&2===t[1].length&&2===t[2].length&&2===t[3].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),Mc(e,t,n)}}),Rc=Qa({spaceToBatchND_:function(e,t,n){const r=Ja(e,"x","spaceToBatchND");F(r.rank>=1+t.length,(()=>`input rank ${r.rank} should be > than [blockShape] ${t.length}`)),F(n.length===t.length,(()=>`paddings.shape[0] ${n.length} must be equal to [blockShape] ${t.length}`)),F(r.shape.reduce(((e,r,a)=>a>0&&a<=t.length?e&&(r+n[a-1][0]+n[a-1][1])%t[a-1]==0:e),!0),(()=>`input spatial dimensions ${r.shape.slice(1)} with paddings ${n.toString()} must be divisible by blockShapes ${t.toString()}`));const a={x:r},s={blockShape:t,paddings:n};return Oa.runKernel(Qn,a,s)}}),Cc=Qa({pool_:function(e,t,n,r,a,s,o){null==a&&(a=[1,1]),null==s&&(s=1),0===r&&(r="valid");const i=Ja(e,"x","maxPool");let l=i,u=!1;3===i.rank&&(u=!0,l=Bl(i,[1,i.shape[0],i.shape[1],i.shape[2]])),F(_l(s,a),(()=>`Error in pool: Either strides or dilations must be 1. Got strides ${s} and dilations '${a}'`));const c=xl(l.shape,t,s,a,r),d=[c.dilationHeight,c.dilationWidth];let h;h="same"===r?function(e,t){const n=e.map(((e,n)=>e+(e-1)*(t[n]-1))).map((e=>e-1)),r=n.map((e=>Math.floor(e/2))),a=n.map(((e,t)=>e-r[t]));return n.map(((e,t)=>[r[t],a[t]]))}([c.filterHeight,c.filterWidth],d):[[0,0],[0,0]];const p=1===d[0]&&1===d[1],[f,m]=function(e,t,n){const r=n.map((e=>e[0])),a=n.map((e=>e[1])),s=e.concat(r,a),o=t.map(((e,t)=>(e-s[t]%e)%e)),i=a.map(((e,t)=>e+o[t]));return[t.map(((e,t)=>[r[t],i[t]])),t.map(((e,t)=>[0,o[t]]))]}([c.inHeight,c.inWidth],d,h),g=p?r:"valid",b=p?l:Rc(l,d,f),k=("avg"===n?()=>Pl(b,t,s,g,o):()=>hc(b,t,s,g,o))(),y=p?k:Kl(k,d,m);return u?Bl(y,[y.shape[1],y.shape[2],y.shape[3]]):y}}),Bc=Qa({prelu_:function(e,t){const n={x:Ja(e,"x","prelu"),alpha:Ja(t,"alpha","prelu")};return Oa.runKernel(Tn,n)}}),Pc=Qa({prod_:function(e,t=null,n=!1){let r=Ja(e,"x","prod");"bool"===r.dtype&&(r=Xs(r,"int32"));const a={x:r},s={axis:t,keepDims:n};return Oa.runKernel(An,a,s)}}),zc=Qa({rand_:function(e,t,n){const r=R(e);let a=null;if(null==n||"float32"===n)a=new Float32Array(r);else if("int32"===n)a=new Int32Array(r);else{if("bool"!==n)throw new Error(`Unknown data type ${n}`);a=new Uint8Array(r)}for(let e=0;e<r;e++)a[e]=t();return Oa.makeTensor(a,e,n)}});var Wc=n(6377);class Oc{constructor(e,t,n,r,a){this.mean=e,this.stdDev=t,this.dtype=n,this.nextVal=NaN,this.truncated=r,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);const s=a||Math.random();this.random=Wc.alea(s.toString())}nextValue(){if(!isNaN(this.nextVal)){const e=this.nextVal;return this.nextVal=NaN,e}let e,t,n=!1;for(;!n;){let r,a,s;do{r=2*this.random()-1,a=2*this.random()-1,s=r*r+a*a}while(s>=1||0===s);const o=Math.sqrt(-2*Math.log(s)/s);e=this.mean+this.stdDev*r*o,t=this.mean+this.stdDev*a*o,this.truncated&&!this.isValidTruncated(e)||(n=!0)}return this.truncated&&!this.isValidTruncated(t)||(this.nextVal=this.convertValue(t)),this.convertValue(e)}convertValue(e){return null==this.dtype||"float32"===this.dtype?e:Math.round(e)}isValidTruncated(e){return e<=this.upper&&e>=this.lower}}class Lc{constructor(e,t,n,r){this.alpha=e,this.beta=1/t,this.dtype=n;const a=r||Math.random();this.randu=Wc.alea(a.toString()),this.randn=new Oc(0,1,n,!1,this.randu()),this.d=e<1?e+2/3:e-1/3,this.c=1/Math.sqrt(9*this.d)}nextValue(){let e,t,n,r,a,s;for(;;){do{r=this.randn.nextValue(),s=1+this.c*r}while(s<=0);if(s*=s*s,e=r*r,t=1-.331*e*e,n=.5*e+this.d*(1-s+Math.log(s)),a=this.randu(),a<t||Math.log(a)<n)break}return s=1/this.beta*this.d*s,this.alpha<1&&(s*=Math.pow(this.randu(),1/this.alpha)),this.convertValue(s)}convertValue(e){return"float32"===this.dtype?e:Math.round(e)}}class Hc{constructor(e=0,t=1,n,r){if(this.canReturnFloat=()=>null==this.dtype||"float32"===this.dtype,this.min=e,this.range=t-e,this.dtype=n,null==r&&(r=Math.random()),"number"==typeof r&&(r=r.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(`The difference between ${e} - ${t} <= 1 and dtype is not float`);this.random=Wc.alea(r)}convertValue(e){return this.canReturnFloat()?e:Math.round(e)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}const Gc=Qa({randomGamma_:function(e,t,n=1,r="float32",a){if(null==n&&(n=1),null==r&&(r="float32"),"float32"!==r&&"int32"!==r)throw new Error(`Unsupported data type ${r}`);const s=new Lc(t,n,r,a),o=Ys(e,r);for(let e=0;e<o.values.length;e++)o.values[e]=s.nextValue();return o.toTensor()}}),Kc=Qa({randomNormal_:function(e,t=0,n=1,r,a){if(null!=r&&"bool"===r)throw new Error(`Unsupported data type ${r}`);const s=new Oc(t,n,r,!1,a),o=Ys(e,r);for(let e=0;e<o.values.length;e++)o.values[e]=s.nextValue();return o.toTensor()}}),qc=Qa({randomUniform_:function(e,t=0,n=1,r="float32",a){const s=Ys(e,r),o=new Hc(t,n,null,a);for(let e=0;e<s.values.length;e++)s.values[e]=o.nextValue();return s.toTensor()}});function Uc(e,t,n=1,r="float32"){if(0===n)throw new Error("Cannot have a step of zero");const a={start:e,stop:t,step:n,dtype:r};return Oa.runKernel(Mn,{},a)}const Vc=Qa({real_:function(e){const t={input:Ja(e,"input","real")};return Oa.runKernel(Fn,t)}}),jc=Qa({reciprocal_:function(e){const t={x:Ja(e,"x","reciprocal")};return Oa.runKernel($n,t)}}),Zc=Qa({relu_:function(e){const t={x:Ja(e,"x","relu")};return Oa.runKernel(Dn,t)}}),Jc=Qa({relu6_:function(e){const t={x:Ja(e,"x","relu6")};return Oa.runKernel(zn,t)}}),Yc=Qa({reverse_:function(e,t){const n={x:Ja(e,"x","reverse")},r={dims:t};return Oa.runKernel(Wn,n,r)}}),Xc=Qa({reverse1d_:function(e){const t=Ja(e,"x","reverse");return F(1===t.rank,(()=>`Error in reverse1D: x must be rank 1 but got rank ${t.rank}.`)),Yc(t,0)}}),Qc=Qa({reverse2d_:function(e,t){const n=Ja(e,"x","reverse");return F(2===n.rank,(()=>`Error in reverse2D: x must be rank 2 but got rank ${n.rank}.`)),Yc(n,t)}}),ed=Qa({reverse3d_:function(e,t){const n=Ja(e,"x","reverse");return F(3===n.rank,(()=>`Error in reverse3D: x must be rank 3 but got rank ${n.rank}.`)),Yc(n,t)}}),td=Qa({reverse4d_:function(e,t){const n=Ja(e,"x","reverse");return F(4===n.rank,(()=>`Error in reverse4D: x must be rank 4 but got rank ${n.rank}.`)),Yc(n,t)}}),nd=Qa({round_:function(e){const t={x:Ja(e,"x","round")};return Oa.runKernel(On,t)}}),rd=Qa({rsqrt_:function(e){const t={x:Ja(e,"x","rsqrt","float32")};return Oa.runKernel(Ln,t)}}),ad=Qa({selu_:function(e){const t={x:Ja(e,"x","selu")};return Oa.runKernel(Kn,t)}}),sd=Qa({separableConv2d_:function(e,t,n,r,a,s=[1,1],o="NHWC"){const i=Ja(e,"x","separableConv2d"),l=Ja(t,"depthwiseFilter","separableConv2d"),u=Ja(n,"pointwiseFilter","separableConv2d");let c=i,d=!1;if(3===i.rank&&(d=!0,c=Bl(i,[1,i.shape[0],i.shape[1],i.shape[2]])),"NCHW"===o)throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");F(4===c.rank,(()=>`Error in separableConv2d: input must be rank 4, but got rank ${c.rank}.`)),F(4===l.rank,(()=>`Error in separableConv2d: depthwise filter must be rank 4, but got rank ${l.rank}.`)),F(4===u.rank,(()=>`Error in separableConv2d: pointwise filter must be rank 4, but got rank ${l.rank}.`)),F(1===u.shape[0],(()=>`Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${u.shape[0]}.`)),F(1===u.shape[1],(()=>`Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${u.shape[1]}.`));const h=l.shape[2],p=l.shape[3];F(u.shape[2]===h*p,(()=>`Error in separableConv2d: the third dimension of pointwise filter must be ${h*p}, but got ${u.shape[2]}.`));const f=bu(c,l,r,a,o,s),m=au(f,u,1,"valid",o);return d?Bl(m,[m.shape[1],m.shape[2],m.shape[3]]):m}}),od=async function(e,t){const n=Ja(e,"x","setdiff1d"),r=Ja(t,"y","setdiff1d");F(n.dtype===r.dtype,(()=>`x and y should have the same dtype, but got x (${n.dtype}) and y (${r.dtype}).`)),F(1===n.rank,(()=>`x should be 1D tensor, but got x (${n.shape}).`)),F(1===r.rank,(()=>`y should be 1D tensor, but got y (${r.shape}).`));const a=await n.data(),s=await r.data(),o=new Set(s);let i=0;for(let e=0;e<a.length;e++)o.has(a[e])||i++;const l=new ba([i],n.dtype),u=new ba([i],"int32");for(let e=0,t=0;e<a.length;e++)o.has(a[e])||(l.values[t]=a[e],u.values[t]=e,t++);return[l.toTensor(),u.toTensor()]},id=Qa({sign_:function(e){const t={x:Ja(e,"x","sign")};return Oa.runKernel(jn,t)}}),ld=Qa({sin_:function(e){const t={x:Ja(e,"x","sin","float32")};return Oa.runKernel(Un,t)}}),ud=Qa({sinh_:function(e){const t={x:Ja(e,"x","sinh")};return Oa.runKernel(Vn,t)}}),cd=Qa({slice1d_:function(e,t,n){const r=Ja(e,"x","slice1d");return F(1===r.rank,(()=>`slice1d expects a rank-1 tensor, but got a rank-${r.rank} tensor`)),Ll(r,[t],[n])}}),dd=Qa({slice2d_:function(e,t,n){const r=Ja(e,"x","slice2d");return F(2===r.rank,(()=>`slice2d expects a rank-2 tensor, but got a rank-${r.rank} tensor`)),Ll(r,t,n)}}),hd=Qa({slice3d_:function(e,t,n){const r=Ja(e,"x","slice3d");return F(3===r.rank,(()=>`slice3d expects a rank-3 tensor, but got a rank-${r.rank} tensor`)),Ll(r,t,n)}}),pd=Qa({slice4d_:function(e,t,n){const r=Ja(e,"x","slice4d");return F(4===r.rank,(()=>`slice4d expects a rank-4 tensor, but got a rank-${r.rank} tensor`)),Ll(r,t,n)}}),fd=Qa({softmax_:function(e,t=-1){const n=Ja(e,"logits","softmax","float32");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and dim was ${t}`);const r={logits:n},a={dim:t};return Oa.runKernel(tr,r,a)}}),md=Qa({fft_:function(e){F("complex64"===e.dtype,(()=>`The dtype for tf.spectral.fft() must be complex64 but got ${e.dtype}.`));const t={input:e};return Oa.runKernel(Tt,t)}}),gd=Qa({ifft_:function(e){F("complex64"===e.dtype,(()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${e.dtype}.`));const t={input:e};return Oa.runKernel(zt,t)}}),bd=Qa({irfft_:function(e){const t=e.shape[e.shape.length-1],n=e.size/t;let r;if(t<=2){const a=Bl(e,[n,t]);r=gd(a)}else{const a=[n,2*(t-1)],s=Bl(Vc(e),[n,t]),o=Bl(Bu(e),[n,t]),i=Yc(Ll(s,[0,1],[n,t-2]),1),l=zi(Yc(Ll(o,[0,1],[n,t-2]),1),Zi(-1)),u=Wl([s,i],1),c=Wl([o,l],1),d=Bl(es(u,c),[a[0],a[1]]);r=gd(d)}if(r=Vc(r),3===e.rank&&0!==e.shape[0]){const t=r,n=e.shape[0];r=Bl(r,[n,r.shape[0]/n,r.shape[1]]),t.dispose()}return r}}),kd=Qa({split_:function(e,t,n=0){const r={x:Ja(e,"x","split")},a={numOrSizeSplits:t,axis:n};return Oa.runKernel(er,r,a)}}),yd=Qa({rfft_:function(e,t){F("float32"===e.dtype,(()=>`The dtype for rfft() must be real value but got ${e.dtype}`));let n=e.shape[e.shape.length-1];const r=e.size/n;let a;if(null!=t&&t<n){const r=e.shape.map((e=>0)),s=e.shape.map((e=>e));s[e.shape.length-1]=t,a=Ll(e,r,s),n=t}else if(null!=t&&t>n){const r=e.shape.map((e=>e));r[e.shape.length-1]=t-n,a=Wl([e,gc(r)],e.shape.length-1),n=t}else a=e;const s=Li(a),o=Bl(es(a,s),[r,n]),i=md(o),l=Math.floor(n/2)+1,u=Vc(i),c=Bu(i),d=kd(u,[l,n-l],u.shape.length-1),h=kd(c,[l,n-l],c.shape.length-1),p=a.shape.slice();return p[a.shape.length-1]=l,Bl(es(d[0],h[0]),p)}}),wd=Qa({squaredDifference_:function(e,t){let n=Ja(e,"a","squaredDifference"),r=Ja(t,"b","squaredDifference");[n,r]=$a(n,r),Eo(n.shape,r.shape);const a={a:n,b:r};return Oa.runKernel(ir,a,{})}}),Id=Qa({squeeze_:function(e,t){const n=Ja(e,"x","squeeze");return Bl(n,q(n.shape,t).newShape)}}),vd=Qa({stack_:function(e,t=0){const n=Ya(e,"tensors","stack","string_or_numeric");F(n.length>=1,(()=>"Pass at least one tensor to tf.stack")),n.length>0&&F(t<=n[0].rank,(()=>"Axis must be <= rank of the tensor"));const r=n,a={axis:t};return Oa.runKernel(xn,r,a)}}),xd=Qa({step_:function(e,t=0){const n={x:Ja(e,"x","step")},r={alpha:t};return Oa.runKernel(Sr,n,r)}}),Sd=Qa({stridedSlice_:function(e,t,n,r,a=0,s=0,o=0,i=0,l=0){const u={x:Ja(e,"x","stridedSlice","string_or_numeric")},c={begin:t,end:n,strides:r,beginMask:a,endMask:s,ellipsisMask:o,newAxisMask:i,shrinkAxisMask:l};return Oa.runKernel(ur,u,c)}}),Ed=Qa({tan_:function(e){const t={x:Ja(e,"x","tan","float32")};return Oa.runKernel(fr,t)}});function Nd(e,t){D(e);const n=Va(e,t);if(1!==n.length)throw new Error("tensor1d() requires values to be a flat/TypedArray");return ts(e,null,n,t)}function Td(e,t,n){if(D(e),null!=t&&2!==t.length)throw new Error("tensor2d() requires shape to have two numbers");const r=Va(e,n);if(2!==r.length&&1!==r.length)throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");return ts(e,t,r,n)}function Ad(e,t,n){if(D(e),null!=t&&4!==t.length)throw new Error("tensor4d() requires shape to have four numbers");const r=Va(e,n);if(4!==r.length&&1!==r.length)throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");return ts(e,t,r,n)}function Md(e,t,n){if(D(e),null!=t&&5!==t.length)throw new Error("tensor5d() requires shape to have five numbers");const r=Va(e,n);if(5!==r.length&&1!==r.length)throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");return ts(e,t,r,n)}function Fd(e,t,n){if(D(e),null!=t&&6!==t.length)throw new Error("tensor6d() requires shape to have six numbers");const r=Va(e,n);if(6!==r.length&&1!==r.length)throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");return ts(e,t=t||r,r,n)}const $d=Qa({topk_:function(e,t=1,n=!0){const r=Ja(e,"x","topk");if(0===r.rank)throw new Error("topk() expects the input to be of rank 1 or higher");const a=r.shape[r.shape.length-1];if(t<0)throw new Error(`'k' passed to topk() must be >= 0 but got ${t}`);if(t>a)throw new Error(`'k' passed to topk() must be <= the last dimension (${a}) but got ${t}`);const s={x:r},o={k:t,sorted:n},[i,l]=Oa.runKernel(br,s,o);return{values:i,indices:l}}}),Dd=Qa({truncatedNormal_:function(e,t=0,n=1,r,a){if(null!=r&&"bool"===r)throw new Error("Unsupported data type $ { dtype }");const s=new Oc(t,n,r,!0,a),o=Ys(e,r);for(let e=0;e<o.values.length;e++)o.values[e]=s.nextValue();return o.toTensor()}}),_d=Qa({unique_:function(e,t=0){const n=Ja(e,"x","unique","string_or_numeric");F(n.rank>0,(()=>"The input tensor must be at least 1D"));const r={x:n},a={axis:t},[s,o]=Oa.runKernel(wr,r,a);return{values:s,indices:o}}}),Rd=Qa({unsortedSegmentSum_:function(e,t,n){const r=Ja(e,"x","unsortedSegmentSum"),a=Ja(t,"segmentIds","unsortedSegmentSum","int32");F(P(n),(()=>"numSegments must be of dtype int"));const s={x:r,segmentIds:a},o={numSegments:n};return Oa.runKernel(vr,s,o)}}),Cd=Qa({unstack_:function(e,t=0){const n=Ja(e,"x","unstack","string_or_numeric");F(t>=-n.shape.length&&t<n.shape.length,(()=>`Axis = ${t} is not in [-${n.shape.length}, ${n.shape.length})`));const r={value:n},a={axis:t};return Oa.runKernel(Ir,r,a)}});function Bd(e,t=!0,n,r){return Oa.makeVariable(e,t,n,r)}function Pd(e,t){const n=[];for(let e=0;e<t.length;e++)t[e]&&n.push(e);const r=Ys(e,"int32"),a=Ys([n.length,e.length],"int32");for(let t=0;t<n.length;t++){const s=r.indexToLoc(n[t]),o=t*e.length;a.values.set(s,o)}return a.toTensor()}const zd=async function(e){const t=Ja(e,"condition","whereAsync","bool"),n=await t.data(),r=Pd(t.shape,n);return e!==t&&t.dispose(),r},Wd=async function(e,t,n){const r=Ja(e,"tensor","boolMask"),a=Ja(t,"mask","boolMask","bool"),s=null==n?0:n,o=a.rank,i=r.shape;F(o>0,(()=>"mask cannot be scalar")),$(i.slice(s,s+o),a.shape,"mask's shape must match the first K dimensions of tensor's shape,");let l=1;for(let e=s;e<s+o;e++)l*=i[e];const u=i.slice(0,s).concat([l],i.slice(s+o)),c=Bl(r,u),d=Bl(a,[-1]),h=await zd(d),p=Id(h,[1]),f=_u(c,p,s);return e!==r&&r.dispose(),t!==a&&a.dispose(),p.dispose(),c.dispose(),d.dispose(),h.dispose(),f};function Od(e,t,n=null){if(0===e.rank)return rl(e);if(1!==e.rank&&null===n)return Od(Bl(e,[-1]),t,n);if(1===e.rank||"number"==typeof n||Array.isArray(n)&&1===n.length){if(1===t)return Yu(rl(e),n);if(t===1/0)return Ju(rl(e),n);if(t===-1/0)return yc(rl(e),n);if("euclidean"===t||2===t)return Wi(Yu(el(rl(e),Zi(2,"int32")),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}if(Array.isArray(n)&&2===n.length){if(1===t)return Ju(Yu(rl(e),n[0]),n[1]-1);if(t===1/0)return Ju(Yu(rl(e),n[1]),n[0]);if(t===-1/0)return yc(Yu(rl(e),n[1]),n[0]);if("fro"===t||"euclidean"===t)return Wi(Yu(Oi(e),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}throw new Error(`Error in norm: invalid axis: ${n}`)}const Ld=Qa({norm_:function(e,t="euclidean",n=null,r=!1){const a=Od(e=Ja(e,"x","norm"),t,n);let s=a.shape;if(r){const t=K(n,e.shape);s=nc(a.shape,t)}return Bl(a,s)}}),Hd=Qa({movingAverage_:function(e,t,n,r,a=!0){const s=Ja(e,"v","movingAverage"),o=Ja(t,"x","movingAverage"),i=Ja(n,"decay","movingAverage");Da(s,o),F(B(s.shape,o.shape),(()=>"Shape mismatch in v and x"));const l=Zi(1),u=tl(l,i);let c=zi(tl(o,s),u);if(a){F(null!=r,(()=>"When using zeroDebias: true, step is required."));const e=Ja(r,"step","movingAverage");c=Pi(c,tl(l,el(i,e)))}return Ci(s,c)}}),Gd=Qa({scatterND_:function(e,t,n){const r=Ja(e,"indices","scatterND","int32"),a=Ja(t,"updates","scatterND");Ro(a,r,n);const s={indices:r,updates:a},o={shape:n};return Oa.runKernel(Hn,s,o)}}),Kd=Qa({sparseToDense_:function(e,t,n,r=0){const a=Ja(e,"sparseIndices","sparseToDense","int32"),s=Ja(t,"sparseValues","sparseToDense"),o=Ja(r,"defaultValue","sparseToDense",s.dtype);!function(e,t,n,r){if("int32"!==e.dtype)throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${e.dtype}.`);if(e.rank>2)throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${e.shape}.`);const a=e.rank>0?e.shape[0]:1,s=e.rank>1?e.shape[1]:1;if(n.length!==s)throw new Error(`outputShape has incorrect number of elements:, ${n.length}, should be: ${s}.`);const o=t.size;if(0!==t.rank&&(1!==t.rank||o!==a))throw new Error(`sparseValues has incorrect shape ${t.shape}, should be [] or [${a}]`);if(t.dtype!==r.dtype)throw new Error("sparseValues.dtype must match defaultValues.dtype")}(a,s,n,o);const i={sparseIndices:a,sparseValues:s,defaultValue:o},l={outputShape:n};return Oa.runKernel(or,i,l)}}),qd=Qa({gatherND_:function(e,t){const n=Ja(t,"indices","gatherND","int32"),r={params:Ja(e,"x","gatherND","string_or_numeric"),indices:n};return Oa.runKernel(Rt,r)}}),Ud=Qa({dropout_:function(e,t,n,r){const a=Ja(e,"x","dropout");if(F("float32"===a.dtype,(()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${a.dtype} tensor instead.`)),F(t>=0&&t<1,(()=>`rate must be a float in the range [0, 1), but got ${t}.`)),0===t)return e instanceof Ia?a.clone():a;const s=function(e,t){if(null==t)return e.shape.slice();if(B(e.shape,t))return t;if(e.shape.length===t.length){const n=[];for(let r=0;r<e.shape.length;r++)null==t[r]&&null!=e.shape[r]?n.push(e.shape[r]):n.push(t[r]);return n}return t}(a,n),o=1-t,i=Pi(Du(Ci(qc(s,0,1,"float32",r),o)),o);return zi(a,i)}});function Vd(e){return Math.floor(Math.pow(2,Math.ceil(Math.log(e)/Math.log(2))))}function jd(e,t,n){const r=1-e%2,a=new Float32Array(e);for(let s=0;s<e;++s){const o=2*Math.PI*s/(e+r-1);a[s]=t-n*Math.cos(o)}return Nd(a,"float32")}const Zd=async function(e,t,n=1){const r=Ja(e,"predictions","inTopK"),a=Ja(t,"targets","inTopK");F(r.rank>1,(()=>`inTopK() expects the predictions to be of rank 2 or higher, but got ${r.rank}`)),F(r.rank-1===a.rank,(()=>`predictions rank should be 1 larger than targets rank, but got predictions rank ${r.rank} and targets rank ${a.rank}`)),$(r.shape.slice(0,r.shape.length-1),a.shape,"predictions's shape should be align with the targets' shape, except the last dimension.");const s=r.shape[r.shape.length-1];F(n>0&&n<=s,(()=>`'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${s}), but got ${n}`));const o=await r.data(),i=await a.data(),[l,u]=[o.length/s,s],c=U("bool",l);for(let e=0;e<l;e++){const t=e*u,r=o.subarray(t,t+u),a=[];for(let e=0;e<r.length;e++)a.push({value:r[e],index:e});a.sort(((e,t)=>t.value-e.value)),c[e]=0;for(let t=0;t<n;t++)if(a[t].index===i[e]){c[e]=1;break}}return e!==r&&r.dispose(),t!==a&&a.dispose(),ns(c,a.shape,"bool")},Jd=Qa({conv2DBackpropFilter_:function(e,t,n,r,a,s="NHWC",o){let i=e;3===e.rank&&(i=Bl(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=t;3===l.rank&&(l=Bl(t,[1,t.shape[0],t.shape[1],t.shape[2]])),F(4===i.rank,(()=>`Error in conv2dDerFilter: input must be rank 4, but got shape ${i.shape}.`)),F(4===l.rank,(()=>`Error in conv2dDerFilter: dy must be rank 4, but got shape ${l.shape}.`)),F(4===n.length,(()=>`Error in conv2dDerFilter: filterShape must be length 4, but got ${n}.`));const u="NHWC"===s?i.shape[3]:i.shape[1],c="NHWC"===s?l.shape[3]:l.shape[1];F(u===n[2],(()=>`Error in conv2dDerFilter: depth of input ${u}) must match input depth in filter (${n[2]}.`)),F(c===n[3],(()=>`Error in conv2dDerFilter: depth of dy (${c}) must match output depth for filter (${n[3]}).`)),Cl("conv2dDerFilter",a,o);const d={x:i,dy:l},h={strides:r,pad:a,dataFormat:s,dimRoundingMode:o,filterShape:n};return Oa.runKernel(Qe,d,h)}});function Yd(e,t,n){if(null==n||"linear"===n)return e;if("relu"===n)return zi(e,xd(t));throw new Error(`Cannot compute gradient for fused activation ${n}.`)}function Xd(e,t){let n=t;const r=So(e.shape,t.shape);return r.length>0&&(n=Yu(n,r)),Bl(n,e.shape)}function Qd(e,t,n,r){if("linear"===t)return e;if("relu"===t)return Zc(e);if("elu"===t)return Eu(e);if("relu6"===t)return Jc(e);if("prelu"===t)return Bc(e,n);if("leakyrelu"===t)return Ou(e,r);if("sigmoid"===t)return Ol(e);throw new Error(`Unknown fused activation ${t}.`)}const eh=(e,t)=>!(e>0)||"linear"===t,th=Qa({fusedConv2d_:function({x:e,filter:t,strides:n,pad:r,dataFormat:a="NHWC",dilations:s=[1,1],dimRoundingMode:o,bias:i,activation:l="linear",preluActivationWeights:u,leakyreluAlpha:c}){if(l=l||"linear",!1===eh(Oa.state.gradientDepth,l)){let d=au(e,t,n,r,a,s,o);return null!=i&&(d=Ci(d,i)),Qd(d,l,u,c)}const d=Ja(e,"x","conv2d","float32"),h=Ja(t,"filter","conv2d","float32");let p=d,f=!1;3===d.rank&&(f=!0,p=Bl(d,[1,d.shape[0],d.shape[1],d.shape[2]])),F(4===p.rank,(()=>`Error in fused conv2d: input must be rank 4, but got rank ${p.rank}.`)),F(4===h.rank,(()=>`Error in fused conv2d: filter must be rank 4, but got rank ${h.rank}.`)),Cl("fused conv2d",r,o),F(p.shape[3]===h.shape[2],(()=>`Error in conv2d: depth of input (${p.shape[3]}) must match input depth for filter ${h.shape[2]}.`)),F(_l(n,s),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`)),F("NHWC"===a,(()=>`Error in conv2d: got dataFormat of ${a} but only NHWC is currently supported.`));const m=El(p.shape,h.shape,n,s,r,o);let g,b;null!=i&&(g=Ja(i,"bias","fused conv2d"),[g]=$a(g,d),Eo(m.outShape,g.shape)),null!=u&&(b=Ja(u,"prelu weights","fused conv2d"));const k=(e,t)=>{const[a,o,i,u]=t,c=Yd(e,i,l);F(Dl(s),(()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`));const d=[ou(o.shape,c,a,n,r),Jd(o,c,a.shape,n,r)];if(null!=u){const e=Xd(u,c);d.push(e)}return d},y={x:p,filter:h,bias:g,preluActivationWeights:b},w={strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o,activation:l,leakyreluAlpha:c};if(null==i){const e=Vi(((e,t,n)=>{let r=Oa.runKernel(Ar,y,w);return n([t,e,r]),f&&(r=Bl(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:k}}));return e(p,h)}{const e=Vi(((e,t,n,r)=>{let a=Oa.runKernel(Ar,y,w);return r([t,e,a,n]),f&&(a=Bl(a,[a.shape[1],a.shape[2],a.shape[3]])),{value:a,gradFunc:k}}));return e(p,h,g)}}}),nh=Qa({depthwiseConv2dNativeBackpropFilter_:function(e,t,n,r,a,s=[1,1],o){let i=e;3===e.rank&&(i=Bl(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=t;3===l.rank&&(l=Bl(t,[1,t.shape[0],t.shape[1],t.shape[2]]));const u={x:i,dy:l},c={strides:r,pad:a,dimRoundingMode:o,dilations:s,filterShape:n};return Oa.runKernel(ht,u,c)}}),rh=Qa({depthwiseConv2dNativeBackpropInput_:function(e,t,n,r,a,s=[1,1],o){let i=t,l=!1;3===t.rank&&(l=!0,i=Bl(t,[1,t.shape[0],t.shape[1],t.shape[2]]));const u={dy:i,filter:n},c={strides:r,pad:a,dimRoundingMode:o,dilations:s,inputShape:e},d=Oa.runKernel(pt,u,c);return l?Bl(d,[d.shape[1],d.shape[2],d.shape[3]]):d}}),ah=Qa({fusedDepthwiseConv2d_:function({x:e,filter:t,strides:n,pad:r,dataFormat:a="NHWC",dilations:s=[1,1],dimRoundingMode:o,bias:i,activation:l="linear",preluActivationWeights:u,leakyreluAlpha:c}){if(!1===eh(Oa.state.gradientDepth,l)){let d=bu(e,t,n,r,a,s,o);return null!=i&&(d=Ci(d,i)),Qd(d,l,u,c)}const d=Ja(e,"x","depthwiseConv2d","float32"),h=Ja(t,"filter","depthwiseConv2d","float32");let p=d,f=!1;3===d.rank&&(f=!0,p=Bl(d,[1,d.shape[0],d.shape[1],d.shape[2]])),F(4===p.rank,(()=>`Error in fused depthwiseConv2d: input must be rank 4, but got rank ${p.rank}.`)),F(4===h.rank,(()=>`Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${h.rank}.`)),F(p.shape[3]===h.shape[2],(()=>`Error in fused depthwiseConv2d: number of input channels (${p.shape[3]}) must match the inChannels dimension in filter ${h.shape[2]}.`)),null==s&&(s=[1,1]),F(_l(n,s),(()=>`Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`)),Cl("fused depthwiseConv2d",r,o);const m=El(p.shape,h.shape,n,s,r,o,!0);let g,b;null!=i&&(g=Ja(i,"bias","fused conv2d"),[g]=$a(g,d),Eo(m.outShape,g.shape)),null!=u&&(b=Ja(u,"prelu weights","fused depthwiseConv2d"));const k=(e,t)=>{F(Dl(s),(()=>`Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${s}'`));const[a,i,u,c]=t,d=Yd(e,u,l),h=rh(i.shape,d,a,n,r,s,o),p=nh(i,d,a.shape,n,r,s,o);return null!=c?[h,p,Xd(g,d)]:[h,p]},y={x:p,filter:h,bias:g,preluActivationWeights:b},w={strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o,activation:l,leakyreluAlpha:c};if(null==i){const e=Vi(((e,t,n)=>{let r=Oa.runKernel(Mr,y,w);return n([t,e,r]),f&&(r=Bl(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:k}}));return e(p,h)}{const e=Vi(((e,t,n,r)=>{let a=Oa.runKernel(Mr,y,w);return r([t,e,a,n]),f&&(a=Bl(a,[a.shape[1],a.shape[2],a.shape[3]])),{value:a,gradFunc:k}}));return e(p,h,g)}}}),sh=Qa({fusedMatMul_:function({a:e,b:t,transposeA:n=!1,transposeB:r=!1,bias:a,activation:s="linear",preluActivationWeights:o,leakyreluAlpha:i}){if(!1===eh(Oa.state.gradientDepth,s)){let l=yo(e,t,n,r);return null!=a&&(l=Ci(l,a)),Qd(l,s,o,i)}let l=Ja(e,"a","fused matMul"),u=Ja(t,"b","fused matMul");[l,u]=$a(l,u);const c=n?l.shape[l.rank-2]:l.shape[l.rank-1],d=r?u.shape[u.rank-1]:u.shape[u.rank-2],h=n?l.shape[l.rank-1]:l.shape[l.rank-2],p=r?u.shape[u.rank-2]:u.shape[u.rank-1],f=l.shape.slice(0,-2),m=u.shape.slice(0,-2),g=R(f),b=R(m);F(c===d,(()=>`Error in fused matMul: inner shapes (${c}) and (${d}) of Tensors with shapes ${l.shape} and ${u.shape} and transposeA=${n} and transposeB=${r} must match.`));const k=Eo(l.shape.slice(0,-2),u.shape.slice(0,-2)).concat([h,p]),y=Bl(l,n?[g,c,h]:[g,h,c]),w=Bl(u,r?[b,p,d]:[b,d,p]);let I,v;null!=a&&(I=Ja(a,"bias","fused matMul"),[I]=$a(I,l),Eo(k,I.shape)),null!=o&&(v=Ja(o,"prelu weights","fused matMul"));const x=(e,t)=>{const[o,i,l,u]=t,c=Yd(Bl(e,l.shape),l,s);let d,h;return n||r?!n&&r?(d=yo(c,i,!1,!1),h=yo(c,o,!0,!1)):n&&!r?(d=yo(i,c,!1,!0),h=yo(o,c,!1,!1)):(d=yo(i,c,!0,!0),h=yo(c,o,!0,!0)):(d=yo(c,i,!1,!0),h=yo(o,c,!0,!1)),null!=a?[d,h,Xd(u,c)]:[d,h]},S={a:y,b:w,bias:I,preluActivationWeights:v},E={transposeA:n,transposeB:r,activation:s,leakyreluAlpha:i};if(null==a){const e=Vi(((e,t,n)=>{const r=Oa.runKernel(Tr,S,E);return n([e,t,r]),{value:Bl(r,k),gradFunc:x}}));return e(y,w)}{const e=Vi(((e,t,n,r)=>{const a=Oa.runKernel(Tr,S,E);return r([e,t,a,n]),{value:Bl(a,k),gradFunc:x}}));return e(y,w,I)}}}),oh=Qa({hammingWindow_:function(e){return jd(e,.54,.46)}}),ih=Qa({hannWindow_:function(e){return jd(e,.5,.5)}}),lh=Qa({frame_:function(e,t,n,r=!1,a=0){let s=0;const o=[];for(;s+t<=e.size;)o.push(Ll(e,s,t)),s+=n;if(r)for(;s<e.size;){const r=s+t-e.size,i=Wl([Ll(e,s,t-r),Xi([r],a)]);o.push(i),s+=n}return 0===o.length?Td([],[0,t]):Bl(Wl(o),[o.length,t])}}),uh=Qa({stft_:function(e,t,n,r,a=ih){null==r&&(r=Vd(t));const s=lh(e,t,n),o=zi(s,a(t));return yd(o,r)}}),ch=Qa({cropAndResize_:function(e,t,n,r,a="bilinear",s=0){const o=Ja(e,"image","cropAndResize"),i=Ja(t,"boxes","cropAndResize","float32"),l=Ja(n,"boxInd","cropAndResize","int32"),u=i.shape[0];F(4===o.rank,(()=>`Error in cropAndResize: image must be rank 4,but got rank ${o.rank}.`)),F(2===i.rank&&4===i.shape[1],(()=>`Error in cropAndResize: boxes must be have size [${u},4] but had shape ${i.shape}.`)),F(1===l.rank&&l.shape[0]===u,(()=>`Error in cropAndResize: boxInd must be have size [${u}] but had shape ${i.shape}.`)),F(2===r.length,(()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${r.length}.`)),F(r[0]>=1&&r[1]>=1,(()=>`cropSize must be atleast [1,1], but was ${r}`)),F("bilinear"===a||"nearest"===a,(()=>`method must be bilinear or nearest, but was ${a}`));const c={image:o,boxes:i,boxInd:l},d={method:a,extrapolationValue:s,cropSize:r};return Oa.runKernel(lt,c,d)}}),dh=Qa({flipLeftRight_:function(e){const t=Ja(e,"image","flipLeftRight","float32");F(4===t.rank,(()=>`Error in flipLeftRight: image must be rank 4,but got rank ${t.rank}.`));const n={image:t};return Oa.runKernel(Mt,n,{})}}),hh=Qa({grayscaleToRGB_:function(e){const t=Ja(e,"image","grayscaleToRGB"),n=t.rank-1,r=t.shape[n];F(t.rank>=2,(()=>`Error in grayscaleToRGB: images must be at least rank 2, but got rank ${t.rank}.`)),F(1===r,(()=>`Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${r}.`));const a=new Array(t.rank);return a.fill(1,0,n),a[n]=3,Fu(t,a)}}),ph=Qa({rotateWithOffset_:function(e,t,n=0,r=.5){const a=Ja(e,"image","rotateWithOffset","float32");F(4===a.rank,(()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${a.rank}.`));const s={image:a},o={radians:t,fillValue:n,center:r};return Oa.runKernel(Nr,s,o)}});function fh(e,t,n,r,a,s){null==r&&(r=.5),null==a&&(a=Number.NEGATIVE_INFINITY),null==s&&(s=0);const o=e.shape[0];return n=Math.min(n,o),F(0<=r&&r<=1,(()=>`iouThreshold must be in [0, 1], but was '${r}'`)),F(2===e.rank,(()=>`boxes must be a 2D tensor, but was of rank '${e.rank}'`)),F(4===e.shape[1],(()=>`boxes must have 4 columns, but 2nd dimension was ${e.shape[1]}`)),F(1===t.rank,(()=>"scores must be a 1D tensor")),F(t.shape[0]===o,(()=>`scores has incompatible shape with boxes. Expected ${o}, but was ${t.shape[0]}`)),F(0<=s&&s<=1,(()=>`softNmsSigma must be in [0, 1], but was '${s}'`)),{maxOutputSize:n,iouThreshold:r,scoreThreshold:a,softNmsSigma:s}}const mh=Qa({nonMaxSuppression_:function(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY){const s=Ja(e,"boxes","nonMaxSuppression","float32"),o=Ja(t,"scores","nonMaxSuppression","float32"),i=fh(s,o,n,r,a),l={maxOutputSize:n=i.maxOutputSize,iouThreshold:r=i.iouThreshold,scoreThreshold:a=i.scoreThreshold};return Oa.runKernel(kn,{boxes:s,scores:o},l)}});function gh(e,t,n){const r=function(e,t,n){return function(e,t,n){let r=0,a=e.length,s=0,o=!1;for(;r<a;){s=r+(a-r>>>1);const i=n(t,e[s]);i>0?r=s+1:(a=s,o=!i)}return o?r:-r-1}(e,t,n||bh)}(e,t,n),a=r<0?-(r+1):r;e.splice(a,0,t)}function bh(e,t){return e>t?1:e<t?-1:0}function kh(e,t,n,r,a){return Ih(e,t,n,r,a,0)}function yh(e,t,n,r,a,s){return Ih(e,t,n,r,a,0,!1,s,!0)}function wh(e,t,n,r,a,s){return Ih(e,t,n,r,a,s,!0)}function Ih(e,t,n,r,a,s,o=!1,i=!1,l=!1){const u=[];for(let e=0;e<t.length;e++)t[e]>a&&u.push({score:t[e],boxIndex:e,suppressBeginIndex:0});u.sort(Sh);const c=s>0?-.5/s:0,d=[],h=[];for(;d.length<n&&u.length>0;){const t=u.pop(),{score:n,boxIndex:s,suppressBeginIndex:o}=t;if(n<a)break;let i=!1;for(let n=d.length-1;n>=o;--n){const o=vh(e,s,d[n]);if(o>=r){i=!0;break}if(t.score=t.score*xh(r,c,o),t.score<=a)break}t.suppressBeginIndex=d.length,i||(t.score===n?(d.push(s),h.push(t.score)):t.score>a&&gh(u,t,Sh))}const p=d.length,f=n-p;i&&f>0&&(d.push(...new Array(f).fill(0)),h.push(...new Array(f).fill(0)));const m={selectedIndices:d};return o&&(m.selectedScores=h),l&&(m.validOutputs=p),m}function vh(e,t,n){const r=e.subarray(4*t,4*t+4),a=e.subarray(4*n,4*n+4),s=Math.min(r[0],r[2]),o=Math.min(r[1],r[3]),i=Math.max(r[0],r[2]),l=Math.max(r[1],r[3]),u=Math.min(a[0],a[2]),c=Math.min(a[1],a[3]),d=Math.max(a[0],a[2]),h=Math.max(a[1],a[3]),p=(i-s)*(l-o),f=(d-u)*(h-c);if(p<=0||f<=0)return 0;const m=Math.max(s,u),g=Math.max(o,c),b=Math.min(i,d),k=Math.min(l,h),y=Math.max(b-m,0)*Math.max(k-g,0);return y/(p+f-y)}function xh(e,t,n){const r=Math.exp(t*n*n);return n<=e?r:0}function Sh(e,t){return e.score-t.score||e.score===t.score&&t.boxIndex-e.boxIndex}const Eh=Qa({nonMaxSuppressionWithScore_:function(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=0){const o=Ja(e,"boxes","nonMaxSuppression"),i=Ja(t,"scores","nonMaxSuppression"),l=fh(o,i,n,r,a,s),u={boxes:o,scores:i},c={maxOutputSize:n=l.maxOutputSize,iouThreshold:r=l.iouThreshold,scoreThreshold:a=l.scoreThreshold,softNmsSigma:s=l.softNmsSigma},d=Oa.runKernel(wn,u,c);return{selectedIndices:d[0],selectedScores:d[1]}}}),Nh=Qa({nonMaxSuppressionPadded_:function(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=!1){const o=Ja(e,"boxes","nonMaxSuppression"),i=Ja(t,"scores","nonMaxSuppression"),l=fh(o,i,n,r,a,null),u={boxes:o,scores:i},c={maxOutputSize:l.maxOutputSize,iouThreshold:l.iouThreshold,scoreThreshold:l.scoreThreshold,padToMaxOutputSize:s},d=Oa.runKernel(yn,u,c);return{selectedIndices:d[0],validOutputs:d[1]}}}),Th=Qa({resizeBilinear_:function(e,t,n=!1,r=!1){const a=Ja(e,"images","resizeBilinear");F(3===a.rank||4===a.rank,(()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${a.rank}.`)),F(2===t.length,(()=>`Error in resizeBilinear: new shape must 2D, but got shape ${t}.`)),F(!1===r||!1===n,(()=>"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false."));let s=a,o=!1;3===a.rank&&(o=!0,s=Bl(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const[]=t,i={images:s},l={alignCorners:n,halfPixelCenters:r,size:t},u=Oa.runKernel(Bn,i,l);return o?Bl(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),Ah=Qa({resizeNearestNeighbor_:function(e,t,n=!1,r=!1){const a=Ja(e,"images","resizeNearestNeighbor");F(3===a.rank||4===a.rank,(()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${a.rank}.`)),F(2===t.length,(()=>`Error in resizeNearestNeighbor: new shape must 2D, but got shape ${t}.`)),F("float32"===a.dtype||"int32"===a.dtype,(()=>"`images` must have `int32` or `float32` as dtype")),F(!1===r||!1===n,(()=>"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false."));let s=a,o=!1;3===a.rank&&(o=!0,s=Bl(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const[]=t,i={images:s},l={alignCorners:n,halfPixelCenters:r,size:t},u=Oa.runKernel(Rn,i,l);return o?Bl(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),Mh=Qa({threshold_:function(e,t="binary",n=!1,r=.5){const a=Ja(e,"image","threshold"),s=a.shape[0]*a.shape[1];let o,i,l,u,c=zi(Nd([r]),255);if(F(3===a.rank,(()=>`Error in threshold: image must be rank 3,but got rank ${a.rank}.`)),F(3===a.shape[2]||1===a.shape[2],(()=>`Error in threshold: image color channel must be equal to 3 or 1but got ${a.shape[2]}.`)),F("int32"===a.dtype||"float32"===a.dtype,(()=>`Error in dtype: image dtype must be int32 or float32,but got dtype ${a.dtype}.`)),F("otsu"===t||"binary"===t,(()=>`Method must be binary or otsu, but was ${t}`)),3===a.shape[2]){[o,i,l]=kd(a,[1,1,1],-1);const e=zi(o,.2989),t=zi(i,.587),n=zi(l,.114);u=Ci(Ci(e,t),n)}else u=e;"otsu"===t&&(c=function(e,t){let n,r,a,s,o,i,l=Nd([-1]),u=Nd([0]),c=Nd([0]);for(let d=0;d<e.size-1;d++){n=Ll(e,0,d+1),r=Ll(e,d+1),o=Pi(Yu(n),t),i=Pi(Yu(r),t);const h=Yu(zi(n,Uc(0,n.size)));a=Pi(h,Yu(n));const p=Xi(r.shape,n.size),f=Ci(Uc(0,r.size),p),m=zi(r,f);s=Pi(Yu(m),Yu(r));const g=tl(a,s),b=tl(a,s),k=zi(o,i);c=zi(zi(k,g),b);const y=Ru(c,u);u=Iu(y,c,u),l=Iu(y,Nd([d]),l)}return l}(Zl(Xs(nd(u),"int32"),ns([]),256),s));const d=n?Hu(u,c):Ru(u,c);return Xs(zi(d,255),"int32")}}),Fh=Qa({transform_:function(e,t,n="nearest",r="constant",a=0,s){const o=Ja(e,"image","transform","float32"),i=Ja(t,"transforms","transform","float32");F(4===o.rank,(()=>`Error in transform: image must be rank 4,but got rank ${o.rank}.`)),F(2===i.rank&&(i.shape[0]===o.shape[0]||1===i.shape[0])&&8===i.shape[1],(()=>"Error in transform: Input transform should be batch x 8 or 1 x 8")),F(null==s||2===s.length,(()=>`Error in transform: outputShape must be [height, width] or null, but got ${s}.`));const l={image:o,transforms:i},u={interpolation:n,fillMode:r,fillValue:a,outputShape:s};return Oa.runKernel(kr,l,u)}}),$h=Qa({bandPart_:function(e,t,n){F(t%1==0,(()=>`bandPart(): numLower must be an integer, got ${t}.`)),F(n%1==0,(()=>`bandPart(): numUpper must be an integer, got ${n}.`));const r=Ja(e,"a","bandPart");F(r.rank>=2,(()=>`bandPart(): Rank must be at least 2, got ${r.rank}.`));const a=r.shape,[s,o]=r.shape.slice(-2);if(!(t<=s))throw new Error(`bandPart(): numLower (${t}) must not be greater than the number of rows (${s}).`);if(!(n<=o))throw new Error(`bandPart(): numUpper (${n}) must not be greater than the number of columns (${o}).`);t<0&&(t=s),n<0&&(n=o);const i=Bl(Uc(0,s,1,"int32"),[-1,1]),l=Uc(0,o,1,"int32"),u=tl(i,l),c=lc(Hu(u,Zi(+t,"int32")),Cu(u,Zi(-n,"int32"))),d=gc([s,o],r.dtype);return Bl(vd(Cd(Bl(r,[-1,s,o])).map((e=>Iu(c,e,d)))),a)}}),Dh=Qa({gramSchmidt_:function(e){let t;if(Array.isArray(e)){t=!1,F(null!=e&&e.length>0,(()=>"Gram-Schmidt process: input must not be null, undefined, or empty"));const n=e[0].shape[0];for(let t=1;t<e.length;++t)F(e[t].shape[0]===n,(()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${e[t].shape[0]} vs. ${n})`))}else t=!0,e=kd(e,e.shape[0],0).map((e=>Id(e,[0])));F(e.length<=e[0].shape[0],(()=>`Gram-Schmidt: Number of vectors (${e.length}) exceeds number of dimensions (${e[0].shape[0]}).`));const n=[],r=e;for(let t=0;t<e.length;++t)n.push(Oa.tidy((()=>{let e=r[t];if(t>0)for(let r=0;r<t;++r){const t=zi(Yu(zi(n[r],e)),n[r]);e=tl(e,t)}return Pi(e,Ld(e,"euclidean"))})));return t?vd(n,0):n}});function _h(e,t=!1){return Oa.tidy((()=>{F(2===e.shape.length,(()=>`qr2d() requires a 2D Tensor, but got a ${e.shape.length}D Tensor.`));const n=e.shape[0],r=e.shape[1];let a=$u(n),s=Qs(e);const o=Td([[1]],[1,1]);let i=Qs(o);const l=n>=r?r:n;for(let e=0;e<l;++e){const t=s,l=i,u=a;[i,s,a]=Oa.tidy((()=>{const t=Ll(s,[e,e],[n-e,1]),l=Ld(t),u=Ll(s,[e,e],[1,1]),c=Iu(Ru(u,0),Td([[-1]]),Td([[1]])),d=tl(u,zi(c,l)),h=Pi(t,d);i=1===h.shape[0]?Qs(o):Wl([o,Ll(h,[1,0],[h.shape[0]-1,h.shape[1]])],0);const p=Vu(Pi(yo(c,d),l)),f=Ll(s,[e,0],[n-e,r]),m=zi(p,i),g=Io(i);if(0===e)s=tl(f,yo(m,yo(g,f)));else{const t=tl(f,yo(m,yo(g,f)));s=Wl([Ll(s,[0,0],[e,r]),t],0)}const b=Io(m),k=Ll(a,[0,e],[n,a.shape[1]-e]);if(0===e)a=tl(k,yo(yo(k,i),b));else{const t=tl(k,yo(yo(k,i),b));a=Wl([Ll(a,[0,0],[n,e]),t],1)}return[i,s,a]})),xi([t,l,u])}return!t&&n>r&&(a=Ll(a,[0,0],[n,r]),s=Ll(s,[0,0],[r,r])),[a,s]}))}const Rh=Qa({qr_:function(e,t=!1){if(F(e.rank>=2,(()=>`qr() requires input tensor to have a rank >= 2, but got rank ${e.rank}`)),2===e.rank)return _h(e,t);{const n=e.shape.slice(0,e.shape.length-2).reduce(((e,t)=>e*t)),r=Cd(Bl(e,[n,e.shape[e.shape.length-2],e.shape[e.shape.length-1]]),0),a=[],s=[];return r.forEach((e=>{const[n,r]=_h(e,t);a.push(n),s.push(r)})),[Bl(vd(a,0),e.shape),Bl(vd(s,0),e.shape)]}}});var Ch;!function(e){e[e.NONE=0]="NONE",e[e.MEAN=1]="MEAN",e[e.SUM=2]="SUM",e[e.SUM_BY_NONZERO_WEIGHTS=3]="SUM_BY_NONZERO_WEIGHTS"}(Ch||(Ch={}));const Bh=Qa({computeWeightedLoss_:function(e,t,n=Ch.SUM_BY_NONZERO_WEIGHTS){const r=Ja(e,"losses","computeWeightedLoss");let a=null;null!=t&&(a=Ja(t,"weights","computeWeightedLoss"));const s=null==a?r:zi(r,a);if(n===Ch.NONE)return s;if(n===Ch.SUM)return Yu(s);if(n===Ch.MEAN){if(null==a)return mc(s);{const e=r.size/a.size,t=Pi(Yu(s),Yu(a));return e>1?Pi(t,Zi(e)):t}}if(n===Ch.SUM_BY_NONZERO_WEIGHTS){if(null==a)return Pi(Yu(s),Zi(r.size));{const e=zi(a,bc(r.shape)),t=Xs(Yu(Nc(e,Zi(0))),"float32");return Pi(Yu(s),t)}}throw Error(`Unknown reduction: ${n}`)}}),Ph=Qa({absoluteDifference_:function(e,t,n,r=Ch.SUM_BY_NONZERO_WEIGHTS){const a=Ja(e,"labels","absoluteDifference"),s=Ja(t,"predictions","absoluteDifference");let o=null;null!=n&&(o=Ja(n,"weights","absoluteDifference")),$(a.shape,s.shape,"Error in absoluteDifference: ");const i=rl(tl(a,s));return Bh(i,o,r)}}),zh=Qa({cosineDistance_:function(e,t,n,r,a=Ch.SUM_BY_NONZERO_WEIGHTS){const s=Ja(e,"labels","cosineDistance"),o=Ja(t,"predictions","cosineDistance");let i=null;null!=r&&(i=Ja(r,"weights","cosineDistance")),$(s.shape,o.shape,"Error in cosineDistance: ");const l=Zi(1),u=tl(l,Yu(zi(s,o),n,!0));return Bh(u,i,a)}}),Wh=Qa({hingeLoss_:function(e,t,n,r=Ch.SUM_BY_NONZERO_WEIGHTS){let a=Ja(e,"labels","hingeLoss");const s=Ja(t,"predictions","hingeLoss");let o=null;null!=n&&(o=Ja(n,"weights","hingeLoss")),$(a.shape,s.shape,"Error in hingeLoss: ");const i=Zi(1);a=tl(zi(Zi(2),a),i);const l=Zc(tl(i,zi(a,s)));return Bh(l,o,r)}}),Oh=Qa({huberLoss_:function(e,t,n,r=1,a=Ch.SUM_BY_NONZERO_WEIGHTS){const s=Ja(e,"labels","huberLoss"),o=Ja(t,"predictions","huberLoss");let i=null;null!=n&&(i=Ja(n,"weights","huberLoss")),$(s.shape,o.shape,"Error in huberLoss: ");const l=Zi(r),u=rl(tl(o,s)),c=wc(u,l),d=tl(u,c),h=Ci(zi(Zi(.5),Oi(c)),zi(l,d));return Bh(h,i,a)}}),Lh=Qa({logLoss_:function(e,t,n,r=1e-7,a=Ch.SUM_BY_NONZERO_WEIGHTS){const s=Ja(e,"labels","logLoss"),o=Ja(t,"predictions","logLoss");let i=null;null!=n&&(i=Ja(n,"weights","logLoss")),$(s.shape,o.shape,"Error in logLoss: ");const l=Zi(1),u=Zi(r),c=Vu(zi(s,qu(Ci(o,u)))),d=zi(tl(l,s),qu(Ci(tl(l,o),u))),h=tl(c,d);return Bh(h,i,a)}}),Hh=Qa({meanSquaredError_:function(e,t,n,r=Ch.SUM_BY_NONZERO_WEIGHTS){const a=Ja(e,"labels","meanSquaredError"),s=Ja(t,"predictions","meanSquaredError");let o=null;null!=n&&(o=Ja(n,"weights","meanSquaredError")),$(a.shape,s.shape,"Error in meanSquaredError: ");const i=wd(a,s);return Bh(i,o,r)}}),Gh=Qa({sigmoidCrossEntropy_:function(e,t,n,r=0,a=Ch.SUM_BY_NONZERO_WEIGHTS){let s=Ja(e,"multiClassLabels","sigmoidCrossEntropy");const o=Ja(t,"logits","sigmoidCrossEntropy");let i=null;if(null!=n&&(i=Ja(n,"weights","sigmoidCrossEntropy")),$(s.shape,o.shape,"Error in sigmoidCrossEntropy: "),r>0){const e=Zi(r),t=Zi(1),n=Zi(.5);s=Ci(zi(s,tl(t,e)),zi(n,e))}const l=function(e,t){const n=Ja(e,"labels","sigmoidCrossEntropyWithLogits"),r=Ja(t,"logits","sigmoidCrossEntropyWithLogits");$(n.shape,r.shape,"Error in sigmoidCrossEntropyWithLogits: ");const a=Zc(r),s=zi(r,n),o=Uu(Tu(Vu(rl(r))));return Ci(tl(a,s),o)}(s,o);return Bh(l,i,a)}}),Kh=Qa({softmaxCrossEntropy_:function(e,t,n,r=0,a=Ch.SUM_BY_NONZERO_WEIGHTS){let s=Ja(e,"onehotLabels","softmaxCrossEntropy");const o=Ja(t,"logits","softmaxCrossEntropy");let i=null;if(null!=n&&(i=Ja(n,"weights","softmaxCrossEntropy")),$(s.shape,o.shape,"Error in softmaxCrossEntropy: "),r>0){const e=Zi(r),t=Zi(1),n=Zi(s.shape[1]);s=Ci(zi(s,tl(t,e)),Pi(e,n))}const l=function(e,t,n=-1){if(-1===n&&(n=t.rank-1),n!==t.rank-1)throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${t.rank} and dim was ${n}`);const r=Vi(((e,t,r)=>{const a=ic(t,[n],!0),s=tl(Xs(t,"float32"),a);r([e,s]);const o=Vu(zi(s,e));return{value:Yu(o,[n]),gradFunc:(e,t)=>{const[r,a]=t,s=nc(e.shape,[n]);return[zi(Bl(e,s),tl(Xs(r,"float32"),Tu(a))),zi(Bl(e,s),tl(Tu(a),Xs(r,"float32")))]}}}));return r(e,t)}(s,o);return Bh(l,i,a)}}),qh=Qa({sparseFillEmptyRows_:function(e,t,n,r){const a=Ja(e,"indices","sparseFillEmptyRows","int32"),s=Ja(t,"values","sparseFillEmptyRows"),o=Ja(n,"denseShape","sparseFillEmptyRows","int32"),i=Ja(r,"defaultValue","sparseFillEmptyRows",s.dtype);if(2!==a.rank)throw new Error(`Indices should be Tensor2D but received shape\n        ${a.shape}`);if(1!==s.rank)throw new Error(`Values should be Tensor1D but received shape ${s.shape}`);if(1!==o.rank)throw new Error(`Dense shape should be Tensor1D but received shape ${o.shape}`);if(0!==i.rank)throw new Error(`Default value should be a scalar but received shape ${i.shape}`);const l={indices:a,values:s,denseShape:o,defaultValue:i},u=Oa.runKernel(nr,l);return{outputIndices:u[0],outputValues:u[1],emptyRowIndicator:u[2],reverseIndexMap:u[3]}}}),Uh=Qa({sparseReshape_:function(e,t,n){const r=Ja(e,"inputIndices","sparseReshape","int32"),a=Ja(t,"inputShape","sparseReshape","int32"),s=Ja(n,"newShape","sparseReshape","int32");if(2!==r.rank)throw new Error(`Input indices should be Tensor2D but received shape\n        ${r.shape}`);if(1!==a.rank)throw new Error(`Input shape should be Tensor1D but received shape ${a.shape}`);if(1!==s.rank)throw new Error(`New shape should be Tensor1D but received shape ${s.shape}`);const o={inputIndices:r,inputShape:a,newShape:s},i=Oa.runKernel(rr,o);return{outputIndices:i[0],outputShape:i[1]}}}),Vh=Qa({sparseSegmentMean_:function(e,t,n){const r=Ja(e,"data","sparseSegmentMean"),a=Ja(t,"indices","sparseSegmentMean","int32"),s=Ja(n,"segmentIds","sparseSegmentMean","int32");if(r.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.rank)throw new Error(`Indices should be Tensor1D but received shape\n          ${a.shape}`);if(1!==s.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n          ${s.shape}`);const o={data:r,indices:a,segmentIds:s};return Oa.runKernel(ar,o)}}),jh=Qa({sparseSegmentSum_:function(e,t,n){const r=Ja(e,"data","sparseSegmentSum"),a=Ja(t,"indices","sparseSegmentSum","int32"),s=Ja(n,"segmentIds","sparseSegmentSum","int32");if(r.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.rank)throw new Error(`Indices should be Tensor1D but received shape\n         ${a.shape}`);if(1!==s.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n         ${s.shape}`);const o={data:r,indices:a,segmentIds:s};return Oa.runKernel(sr,o)}}),Zh=Qa({stringNGrams_:function(e,t,n,r,a,s,o,i){const l=Ja(e,"data","stringNGrams","string");if("string"!==l.dtype)throw new Error("Data must be of datatype string");if(1!==l.shape.length)throw new Error(`Data must be a vector, saw: ${l.shape}`);const u=Ja(t,"dataSplits","stringNGrams");if("int32"!==u.dtype)throw new Error("Data splits must be of datatype int32");const c={separator:n,nGramWidths:r,leftPad:a,rightPad:s,padWidth:o,preserveShortSequences:i},d={data:l,dataSplits:u},h=Oa.runKernel(cr,d,c);return{nGrams:h[0],nGramsSplits:h[1]}}}),Jh=Qa({stringSplit_:function(e,t,n=!0){const r=Ja(e,"input","stringSplit","string"),a=Ja(t,"delimiter","stringSplit","string");if(1!==r.rank)throw new Error(`Input should be Tensor1D but received shape ${r.shape}`);if(0!==a.rank)throw new Error(`Delimiter should be a scalar but received shape ${a.shape}`);const s={skipEmpty:n},o={input:r,delimiter:a},i=Oa.runKernel(dr,o,s);return{indices:i[0],values:i[1],shape:i[2]}}}),Yh=Qa({stringToHashBucketFast_:function(e,t){const n=Ja(e,"input","stringToHashBucketFast","string"),r={numBuckets:t};if(t<=0)throw new Error("Number of buckets must be at least 1");const a={input:n};return Oa.runKernel(hr,a,r)}}),Xh={fft:md,ifft:gd,rfft:yd,irfft:bd},Qh={hammingWindow:oh,hannWindow:ih,frame:lh,stft:uh},ep={flipLeftRight:dh,grayscaleToRGB:hh,resizeNearestNeighbor:Ah,resizeBilinear:Th,rotateWithOffset:ph,cropAndResize:ch,nonMaxSuppression:mh,nonMaxSuppressionAsync:async function(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY){const s=Ja(e,"boxes","nonMaxSuppressionAsync"),o=Ja(t,"scores","nonMaxSuppressionAsync"),i=fh(s,o,n,r,a);n=i.maxOutputSize,r=i.iouThreshold,a=i.scoreThreshold;const l=await Promise.all([s.data(),o.data()]),u=l[0],c=l[1],{selectedIndices:d}=kh(u,c,n,r,a);return s!==e&&s.dispose(),o!==t&&o.dispose(),Nd(d,"int32")},nonMaxSuppressionWithScore:Eh,nonMaxSuppressionWithScoreAsync:async function(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=0){const o=Ja(e,"boxes","nonMaxSuppressionAsync"),i=Ja(t,"scores","nonMaxSuppressionAsync"),l=fh(o,i,n,r,a,s);n=l.maxOutputSize,r=l.iouThreshold,a=l.scoreThreshold,s=l.softNmsSigma;const u=await Promise.all([o.data(),i.data()]),c=u[0],d=u[1],{selectedIndices:h,selectedScores:p}=wh(c,d,n,r,a,s);return o!==e&&o.dispose(),i!==t&&i.dispose(),{selectedIndices:Nd(h,"int32"),selectedScores:Nd(p)}},nonMaxSuppressionPadded:Nh,nonMaxSuppressionPaddedAsync:async function(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=!1){const o=Ja(e,"boxes","nonMaxSuppressionAsync"),i=Ja(t,"scores","nonMaxSuppressionAsync"),l=fh(o,i,n,r,a,null),u=l.maxOutputSize,c=l.iouThreshold,d=l.scoreThreshold,[h,p]=await Promise.all([o.data(),i.data()]),{selectedIndices:f,validOutputs:m}=yh(h,p,u,c,d,s);return o!==e&&o.dispose(),i!==t&&i.dispose(),{selectedIndices:Nd(f,"int32"),validOutputs:Zi(m,"int32")}},threshold:Mh,transform:Fh},tp={bandPart:$h,gramSchmidt:Dh,qr:Rh},np={absoluteDifference:Ph,computeWeightedLoss:Bh,cosineDistance:zh,hingeLoss:Wh,huberLoss:Oh,logLoss:Lh,meanSquaredError:Hh,sigmoidCrossEntropy:Gh,softmaxCrossEntropy:Kh},rp={sparseFillEmptyRows:qh,sparseReshape:Uh,sparseSegmentMean:Vh,sparseSegmentSum:jh},ap={stringNGrams:Zh,stringSplit:Jh,stringToHashBucketFast:Yh},sp={sgd:ul.sgd,momentum:ul.momentum,adadelta:ul.adadelta,adagrad:ul.adagrad,rmsprop:ul.rmsprop,adamax:ul.adamax,adam:ul.adam},op="undefined"!=typeof requestAnimationFrame?requestAnimationFrame:"undefined"!=typeof setImmediate?setImmediate:e=>e();function ip(){return new Promise((e=>op((()=>e()))))}function lp(e,t){const n=e[0].length;e.forEach(((e,t)=>{F(e.length===n,(()=>`Error in concat${n}D: rank of tensors[${t}] must be the same as the rank of the rest (${n})`))})),F(t>=0&&t<n,(()=>`Error in concat${n}D: axis must be between 0 and ${n-1}.`));const r=e[0];e.forEach(((e,a)=>{for(let s=0;s<n;s++)F(s===t||e[s]===r[s],(()=>`Error in concat${n}D: Shape of tensors[${a}] (${e}) does not match the shape of the rest (${r}) along the non-concatenated axis ${a}.`))}))}function up(e,t){const n=e[0].slice();for(let r=1;r<e.length;r++)n[t]+=e[r][t];return n}const cp=30;function dp(e){return e<=cp?e:se(e,Math.floor(Math.sqrt(e)))}function hp(e,t,n){return[n*("number"==typeof e?e:e[0]),t*("number"==typeof e?e:e[1])]}function pp(e,t,n,r=!0){let a=[];if(r)a=a.concat(t.slice(0)),a.push(e[0]/n),a=a.concat(e.slice(1));else{a=a.concat(e[0]);const n=t.length;for(let r=0;r<n;++r)a=a.concat([e[r+1]/t[r],t[r]]);a=a.concat(e.slice(n+1))}return a}function fp(e,t,n=!0){const r=[];if(n){r.push(t);for(let n=t+1;n<e;++n)n<=2*t?(r.push(n),r.push(n-(t+1))):r.push(n)}else{const n=[],a=[];for(let r=1;r<e;++r)r>=2*t+1||r%2==1?a.push(r):n.push(r);r.push(...n),r.push(0),r.push(...a)}return r}function mp(e,t,n,r=!0){const a=[];r?a.push(e[0]/n):a.push(e[0]*n);for(let n=1;n<e.length;++n)n<=t.length?r?a.push(t[n-1]*e[n]):a.push(e[n]/t[n-1]):a.push(e[n]);return a}function gp(e,t){const n=[0];for(let r=0;r<t;++r)n.push(e[r][0]);return n}function bp(e,t,n){const r=e.slice(0,1);for(let a=0;a<n;++a)r.push(e[a+1]-t[a][0]-t[a][1]);return r}const kp=1.7580993408473768,yp=1.0507009873554805,wp=.3275911,Ip=.254829592,vp=-.284496736,xp=1.421413741,Sp=-1.453152027,Ep=1.061405429;function Np(e,t){if(e.length!==t.length)throw new Error(`Cannot merge real and imag arrays of different lengths. real:${e.length}, imag: ${t.length}.`);const n=new Float32Array(2*e.length);for(let r=0;r<n.length;r+=2)n[r]=e[r/2],n[r+1]=t[r/2];return n}function Tp(e){const t=new Float32Array(e.length/2),n=new Float32Array(e.length/2);for(let r=0;r<e.length;r+=2)t[r/2]=e[r],n[r/2]=e[r+1];return{real:t,imag:n}}function Ap(e){const t=Math.ceil(e.length/4),n=new Float32Array(t),r=new Float32Array(t);for(let t=0;t<e.length;t+=4)n[Math.floor(t/4)]=e[t],r[Math.floor(t/4)]=e[t+1];return{real:n,imag:r}}function Mp(e){const t=Math.floor(e.length/4),n=new Float32Array(t),r=new Float32Array(t);for(let t=2;t<e.length;t+=4)n[Math.floor(t/4)]=e[t],r[Math.floor(t/4)]=e[t+1];return{real:n,imag:r}}function Fp(e,t){return{real:e[2*t],imag:e[2*t+1]}}function $p(e,t,n,r){e[2*r]=t,e[2*r+1]=n}function Dp(e,t){const n=new Float32Array(e/2),r=new Float32Array(e/2);for(let a=0;a<Math.ceil(e/2);a++){const s=(t?2:-2)*Math.PI*(a/e);n[a]=Math.cos(s),r[a]=Math.sin(s)}return{real:n,imag:r}}function _p(e,t,n){const r=(n?2:-2)*Math.PI*(e/t);return{real:Math.cos(r),imag:Math.sin(r)}}const Rp=/->/g;function Cp(e,t){const n=((e=e.replace(/\s/g,"")).length-e.replace(Rp,"").length)/"->".length;if(n<1)throw new Error("Equations without an arrow are not supported.");if(n>1)throw new Error('Equation must contain exactly one arrow ("->").');const[r,a]=e.split("->");F(-1===r.indexOf("..."),(()=>'The ellipsis notation ("...") is not supported yet.'));const s=r.split(","),o=s.length;if(t!==o)throw new Error(`Expected ${o} input tensors, received ${t}`);if(o>2)throw new Error("Support for more than 2 input tensors is not implemented yet.");const i=[];for(let e=0;e<a.length;++e){const t=a[e];if(!s.some((e=>-1!==e.indexOf(t))))throw new Error(`Output subscripts contain the label ${t} not present in the input subscripts.`);-1===i.indexOf(t)&&i.push(t)}for(let e=0;e<r.length;++e){const t=r[e];-1===i.indexOf(t)&&","!==t&&i.push(t)}const l=new Array(s.length);for(let e=0;e<o;++e){if(new Set(s[e].split("")).size!==s[e].length)throw new Error(`Found duplicate axes in input component ${s[e]}. Support for duplicate axes in input is not implemented yet.`);l[e]=[];for(let t=0;t<s[e].length;++t)l[e].push(i.indexOf(s[e][t]))}const u=i.length,c=[];for(let e=a.length;e<u;++e)c.push(e);return{allDims:i,summedDims:c,idDims:l}}function Bp(e,t){let n=new Array(e);n.fill(-1);for(let e=0;e<t.length;++e)n[t[e]]=e;const r=[];for(let t=0;t<e;++t)-1===n[t]&&r.push(t);return n=n.filter((e=>-1!==e)),{permutationIndices:n,expandDims:r}}function Pp(e,t,n){const r=new Array(e);for(let e=0;e<n.length;++e){const a=n[e].shape;for(let n=0;n<t[e].length;++n)void 0===r[t[e][n]]?r[t[e][n]]=a[n]:F(r[t[e][n]]===a[n],(()=>`Expected dimension ${r[t[e][n]]} at axis ${n} of input shaped ${JSON.stringify(a)}, but got dimension ${a[n]}`))}}function zp(e,t){const n=e,r=[];let a=0;0===e.length&&n.push(-1),a=e.length+1;for(let e=0;e<a;++e)r.push([]);const s=[];for(let e=0;e<n.length;++e){const a=Op(t,n[e]);for(const t of a)-1===s.indexOf(t)&&(r[e].push(t),s.push(t))}return{path:n,steps:r}}function Wp(e){return e.every(((e,t)=>e===t))}function Op(e,t){const n=[];for(let r=0;r<e.length;++r)0!==e[r].length&&-1===e[r].indexOf(t)&&-1!==t||n.push(r);return n}function Lp(e,t,n=0){let r=[];if("number"==typeof t)F(e.shape[n]%t==0,(()=>"Number of splits must evenly divide the axis.")),r=new Array(t).fill(e.shape[n]/t);else{F(t.reduce(((e,t)=>(-1===t&&(e+=1),e)),0)<=1,(()=>"There should be only one negative value in split array."));const a=t.indexOf(-1);if(-1!==a){const r=t.reduce(((e,t)=>t>0?e+t:e));t[a]=e.shape[n]-r}F(e.shape[n]===t.reduce(((e,t)=>e+t)),(()=>"The sum of sizes must match the size of the axis dimension.")),r=t}return r}function Hp(e){return`Received SparseTensor with denseShape[0] = 0 but\n  indices.shape[0] = ${e}`}function Gp(e,t){return`indices(${e}, 0) is invalid: ${t} < 0`}function Kp(e,t,n){return`indices(${e}, 0) is invalid: ${t} >= ${n}`}function qp(e,t){return`only one output dimension may be -1, not both ${e} and ${t}`}function Up(e,t){return`size ${e} must be non-negative, not ${t}`}function Vp(){return"reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero"}function jp(e,t){return`Input to reshape is a SparseTensor with ${R(e)}\n  dense values, but the requested shape requires a multiple of ${R(t)}. inputShape=${e} outputShape= ${t}`}function Zp(e,t){return`Input to reshape is a tensor with ${R(e)} dense values, but the requested shape has ${R(t)}. inputShape=${e} outputShape=${t}`}function Jp(){return"segment ids must be >= 0"}function Yp(){return"segment ids are not increasing"}function Xp(e,t){return`Segment id ${e} out of range [0, ${t}), possibly because segmentIds input is not sorted.`}function Qp(e,t,n){return`Bad: indices[${e}] == ${t} out of range [0, ${n})`}function ef(e,t){let n,r=!1;for(e<=cp?(n=e,r=!0):n=se(e,Math.floor(Math.sqrt(e)));!r;)n>t||n===e?r=!0:n=se(e,n+1);return n}function tf(e,t,n){const r=[],a=e.length;for(let s=0;s<a;s++)s!==t?r.push(e[s]):r.push(n);return r}function nf(e,t,n,r){const a=t.shape.length,s=e.shape.length;if(0!==r&&(r<-a||r>a))throw new Error(`Expect batchDims in the range of [-${a}, ${a}], but got ${r}`);if(r<0&&(r+=a),r>s)throw new Error(`batchDims (${r}) must be less than rank(x) (\n    ${s}).`);if(n<r)throw new Error(`batchDims (${r}) must be less than or equal to axis (${n}).`);for(let n=0;n<r;++n)if(e.shape[n]!==t.shape[n])throw new Error(`x.shape[${n}]: ${e.shape[n]} should be equal to indices.shape[${n}]: ${t.shape[n]}.`);const o=e.shape[n],i=[];let l=1,u=1,c=1;for(let t=0;t<r;++t)i.push(e.shape[t]),l*=e.shape[t];for(let t=r;t<n;t++)i.push(e.shape[t]),u*=e.shape[t];for(let e=r;e<a;e++)i.push(t.shape[e]);for(let t=n+1;t<s;t++)i.push(e.shape[t]),c*=e.shape[t];return{batchSize:l,sliceSize:c,outerSize:u,dimSize:o,outputShape:i}}function rf(e){try{return e.map((e=>la(e)))}catch(e){throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${e}`)}}function af(e){return e.map((e=>ia(e)))}}}]);